<Projects><Project acronym="A-BINGOS"><Rcn>185648</Rcn><Nid>12022</Nid><HI>Foundation For Research And Technology Hellas, Greece</HI><Name>Accreting binary populations in Nearby Galaxies: Observations and Simulations</Name><PI>Andreas Zezas</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"High-energy observations of our Galaxy offer a good, albeit not complete, picture of the X-ray source populations, in particular the accreting binary sources. Recent ability to study accreting binaries in nearby galaxies has shown that we would be short-sighted if we restricted ourselves to our Galaxy or to a few nearby ones. I propose an ambitious project that involves a comprehensive study of all the galaxies within 10 Mpc for which we can study in detail their X-ray sources and stellar populations. The study will combine data from a unique suite of observatories (Chandra, XMM-Newton, HST, Spitzer) with state-of-the-art theoretical modelling of binary systems. I propose a novel approach that links the accreting binary populations to their parent stellar populations and surpasses any current studies of X-ray binary populations, both in scale and in scope, by: (a) combining methods and results from several different areas of astrophysics (compact objects, binary systems, stellar populations, galaxy evolution); (b) using data from almost the whole electromagnetic spectrum (infrared to X-ray bands); (c) identifying and studying the different sub-populations of accreting binaries; and (d) performing direct comparison between observations and theoretical predictions, over a broad parameter space. The project: (a) will answer the long-standing question of the formation efficiency of accreting binaries in different environments; and (b) will constrain their evolutionary paths. As by-products the project will provide eagerly awaited input to the fields of gravitational-wave sources, &#206;&#179;-ray bursts, and X-ray emitting galaxies at cosmological distances and it will produce a heritage multi-wavelength dataset and library of models for future studies of galaxies and accreting binaries."</Summary><Max_ERC_funding>1,242,000</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ACOPS"><Rcn>111552</Rcn><Nid>10065</Nid><HI>Friedrich-Schiller-Universitat Jena, Germany</HI><Name>Advanced Coherent Ultrafast Laser Pulse Stacking</Name><PI>Jens Limpert</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"An important driver of scientific progress has always been the envisioning of applications far beyond existing technological capabilities. Such thinking creates new challenges for physicists, driven by the groundbreaking nature of the anticipated application. In the case of laser physics, one of these applications is laser wake-field particle acceleration and possible future uses thereof, such as in collider experiments, or for medical applications such as cancer treatment. To accelerate electrons and positrons to TeV-energies, a laser architecture is required that allows for the combination of high efficiency, Petawatt peak powers, and Megawatt average powers. Developing such a laser system would be a challenging task that might take decades of aggressive research, development, and, most important, revolutionary approaches and innovative ideas.
The goal of the ACOPS project is to develop a compact, efficient, scalable, and cost-effective high-average and high-peak power ultra-short pulse laser concept.
The proposed approach to this goal relies on the spatially and temporally separated amplification of ultrashort laser pulses in waveguide structures, followed by coherent combination into a single train of pulses with increased average power and pulse energy. This combination can be realized through the coherent addition of the output beams of spatially separated amplifiers, combined with the pulse stacking of temporally separated pulses in passive enhancement cavities, employing a fast-switching element as cavity dumper.
Therefore, the three main tasks are the development of kW-class high-repetition-rate driving lasers, the investigation of non-steady state pulse enhancement in passive cavities, and the development of a suitable dumping element.
If successful, the proposed concept would undoubtedly provide a tool that would allow researchers to surpass the current limits in high-field physics and accelerator science."</Summary><Max_ERC_funding>1,881,040</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="ACUITY"><Rcn>185678</Rcn><Nid>12314</Nid><HI>Technische Universiteit Eindhoven, Netherlands</HI><Name>Algorithms for coping with uncertainty and intractability</Name><PI>Nikhil Bansal</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"The two biggest challenges in solving practical optimization problems are computational intractability, and the presence
of uncertainty: most problems are either NP-hard, or have incomplete input data which
makes an exact computation impossible.

Recently, there has been a huge progress in our understanding of intractability, based on spectacular algorithmic and lower bound techniques. For several problems, especially those with only local constraints, we can design optimum
approximation algorithms that are provably the best possible.
However, typical optimization problems usually involve complex global constraints and are much less understood. The situation is even worse for coping with uncertainty. Most of the algorithms are based on ad-hoc techniques and there is no deeper understanding of what makes various problems easy or hard.

This proposal describes several new directions, together with concrete intermediate goals, that will break important new ground in the theory of approximation and online algorithms. The particular directions we consider are (i) extend the primal dual method to systematically design online algorithms, (ii) build a structural theory of online problems based on work functions, (iii) develop new tools to use the power of strong convex relaxations and (iv) design new algorithmic approaches based on  non-constructive proof techniques.

The proposed research is at the
cutting edge of algorithm design, and builds upon the recent success of the PI in resolving several longstanding questions in these areas. Any progress is likely to be a significant contribution to theoretical
computer science and combinatorial optimization."</Summary><Max_ERC_funding>1,519,285</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="ALERT"><Rcn>191235</Rcn><Nid>10581</Nid><HI>Stichting Astron, Netherlands Institute For Radio Astronomy, Netherlands</HI><Name>ALERT- The Apertif-LOFAR Exploration of the Radio Transient Sky</Name><PI>Albert Van Leeuwen</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"In our largely unchanging radio Universe, a highly dynamic component was recently discovered: flashes of bright radio emission that last only milliseconds but appear all over the sky. Some of these radio bursts can be traced to intermittently pulsating neutron stars. Other bursts however, apparently originate far outside our Galaxy. Due to great observational challenges, the evolution of the neutron stars is not understood, while more importantly, the nature of the extragalactic bursts remains an outright mystery.

My overall aim is to understand the physics that drives both kinds of brief and luminous bursts.

My primary goal is to identify the highly compact astrophysical explosions powering the extragalactic  bursts. My previous surveys are the state of the art in fast-transient detection; I will now increase by a factor of 10 this exploration volume.  In real-time I will provide arcsec positions, 10,000-fold more accurate than currently possible, to localize such extragalactic bursts for the first time and understand their origin.

My secondary goal is to unravel the unexplained evolution of intermittently pulsating neutron stars (building on e.g., my recent papers in Science, 2013), by doubling their number and modeling their population.

To achieve these goals, I will carry out a highly innovative survey: the Apertif-LOFAR Exploration of the Radio Transient Sky. ALERT is over an order of magnitude more sensitive than all current state-of-the art fast-transient surveys.

Through its novel, extremely wide field-of-view, Westerbork/Apertif will detect many tens of extragalactic bursts. Through real-time triggers to LOFAR I will next provide the precise localisation that is essential for radio, optical and high-energy follow-up to, for the first time, shed light on the physics and objects driving these bursts &#8211; evaporating primordial black holes; explosions in host galaxies; or, the unknown?"</Summary><Max_ERC_funding>1,999,823</Max_ERC_funding><Duration><Start_date> 2014-12-01, </Start_date><End_date> 2019-11-30</End_date></Duration></Project><Project acronym="ALUNIF"><Rcn>111544</Rcn><Nid>11829</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Oxford, United Kingdom</HI><Name>Algorithms and Lower Bounds: A Unified Approach</Name><PI>Rahul Santhanam</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>One of the fundamental goals of theoretical computer science is to
understand the possibilities and limits of efficient computation. This
quest has two dimensions. The
theory of algorithms focuses on finding efficient solutions to
problems, while computational complexity theory aims to understand when
and why problems are hard to solve. These two areas have different
philosophies and use different sets of techniques. However, in recent
years there have been indications of deep and mysterious connections
between them.

In this project, we propose to explore and develop the connections between
algorithmic analysis and complexity lower bounds in a systematic way.
On the one hand, we plan to use complexity lower bound techniques as inspiration
to design new and improved algorithms for Satisfiability and other
NP-complete problems, as well as to analyze existing algorithms better.
On the other hand, we plan to strengthen implications yielding circuit
lower bounds from non-trivial algorithms for Satisfiability, and to derive
new circuit lower bounds using these stronger implications.

This project has potential for massive impact in both the areas of algorithms
and computational complexity. Improved algorithms for Satisfiability could lead
to improved SAT solvers, and the new analytical tools would lead to a better
understanding of existing heuristics. Complexity lower bound questions are
fundamental
but notoriously difficult, and new lower bounds would open the way to
unconditionally secure cryptographic protocols and derandomization of
probabilistic algorithms. More broadly, this project aims to initiate greater
dialogue between the two areas, with an exchange of ideas and techniques
which leads to accelerated progress in both, as well as a deeper understanding
of the nature of efficient computation.</Summary><Max_ERC_funding>1,274,496</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="ASIBIA"><Rcn>185645</Rcn><Nid>12021</Nid><HI>University Of East Anglia, United Kingdom</HI><Name>Arctic sea ice, biogeochemistry and impacts on the atmosphere: Past, present, future</Name><PI>Roland Von Glasow</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>The Arctic Ocean is a vast expanse of sea ice. Most of it is snow covered as are large continental regions for about half of the year. However, Global Change is arguably greatest in the Arctic, where temperatures have risen more than anywhere else in the last few decades. New record lows occurred in snow extent in June 2012 and sea ice extent in September 2012. Many observations show that widespread and sustained change is occurring in the Arctic driving this unique environmental system into a new state. This project focuses on the biogeochemical links between sea ice and snow and the composition and chemistry of the troposphere (the lowest ~10km of the atmosphere). This is an important topic because the concentrations of greenhouse gases and aerosol particles, which scatter sunlight directly and influence cloud properties, play key roles for our climate. Additionally, changes in the composition of the troposphere also affect the so-called oxidation capacity, the capability of the atmosphere to cleanse itself from pollutants.
This project aims to deliver a step change improvement in our quantitative understanding of chemical exchanges between ocean, sea ice, snow and the atmosphere in polar regions, especially the Arctic and of Arctic tropospheric chemistry. Answering these fundamental questions is essential to predict future change in the Arctic and globally. To this end a unique sea ice chamber will be constructed in the laboratory and used to quantify exchange processes in sea ice. Furthermore a hierarchy of numerical models will be used, operating at different spatial and temporal scales and degree of process description from a very detailed 1D to a global Earth System model. This will allow a breakthrough in our understanding of the importance of the changes for the composition and oxidation capacity of the atmosphere and climate and will allow us to calculate adjusted Greenhouse Warming Potentials that include these processes.</Summary><Max_ERC_funding>1,192,911</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2016-09-30</End_date></Duration></Project><Project acronym="AUGURY"><Rcn>185668</Rcn><Nid>12026</Nid><HI>Universite Lyon 1 Claude Bernard, France</HI><Name>Reconstructing Earth&#8217;s mantle convection</Name><PI>Nicolas Coltice</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Knowledge of the state of the Earth mantle and its temporal evolution is fundamental to a variety of disciplines in Earth Sciences, from the internal dynamics to its many expressions in the geological record (postglacial rebound, sea level change, ore deposit, tectonics or geomagnetic reversals). Mantle convection theory is the centerpiece to unravel the present and past state of the mantle. For the past 40 years considerable efforts have been made to improve the quality of numerical models of mantle convection. However, they are still sparsely used to estimate the convective history of the solid Earth, in comparison to ocean or atmospheric models for weather and climate prediction. The main shortcoming is their inability to successfully produce Earth-like seafloor spreading and continental drift self-consistently. Recent convection models have begun to successfully predict these processes (Coltice et al., Science 336, 335-33, 2012). Such breakthrough opens the opportunity to combine high-level data assimilation methodologies and convection models together with advanced tectonic datasets to retrieve Earth's mantle history. The scope of this project is to produce a new generation of tectonic and convection reconstructions, which are key to improve our understanding and knowledge of the evolution of the solid Earth. The development of sustainable high performance numerical models will set new standards for geodynamic data assimilation. The outcome of the AUGURY project will be a new generation of models crucial to a wide variety of disciplines."</Summary><Max_ERC_funding>1,994,000</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="AdOC"><Rcn>185666</Rcn><Nid>10729</Nid><HI>Centre National De La Recherche Scientifique Cnrs, France</HI><Name>Advance Optical Clocks</Name><PI>Sebastien Andr&#233; Marcel Bize</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"The proposed research program has three main objectives. The first and second objectives are to seek extreme precisions in optical atomic spectroscopy and optical clocks, and to use this quest as a mean of exploration in atomic physics. The third objective is to explore new possibilities that stem from extreme precision. These goals will be pursued via three complementary activities: #1: Search for extreme precisions with an Hg optical lattice clock. #2: Explore and exploit the rich Hg system, which is essentially unexplored in the cold and ultra-cold regime. #3: Identify new applications of clocks with extreme precision to Earth science. Clocks can measure directly the gravitational potential via Einstein&#8217;s gravitational redshift, leading to the idea of &#8220;clock-based geodesy&#8221;.
The 2 first activities are experimental and build on an existing setup, where we demonstrated the feasibility of an Hg optical lattice clock. Hg is chosen for its potential to surpass competing systems. We will investigate the unexplored physics of the Hg clock. This includes interactions between Hg atoms, lattice-induced light shifts, and sensitivity to external fields which are specific to the atomic species. Beyond, we will explore the fundamental limits of the optical lattice scheme. We will exploit other remarkable features of Hg associated to the high atomic number and the diversity of stable isotopes. These features enable tests of fundamental physical laws, ultra-precise measurements of isotope shifts, measurement of collisional properties toward evaporative cooling and quantum gases of Hg, investigation of forbidden transitions promising for measuring the nuclear anapole moment of Hg.
The third activity is theoretical and is aimed at initiating collaborations with experts in modelling Earth gravity. With this expertise, we will identify the most promising and realistic approaches for clocks and emerging remote comparison methods to contribute to geodesy, hydrology, oceanography, etc."</Summary><Max_ERC_funding>1,946,432</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="BIGBAYES"><Rcn>192413</Rcn><Nid>13428</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Oxford, United Kingdom</HI><Name>Rich, Structured and Efficient Learning of Big Bayesian Models</Name><PI>Yee Whye Teh</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>As datasets grow ever larger in scale, complexity and variety, there is an increasing need for powerful machine learning and statistical techniques that are capable of learning from such data. Bayesian nonparametrics is a promising approach to data analysis that is increasingly popular in machine learning and statistics.  Bayesian nonparametric models are highly flexible models with infinite-dimensional parameter spaces that can be used to directly parameterise and learn about functions, densities, conditional distributions etc, and  have been successfully applied to regression, survival analysis, language modelling, time series analysis, and visual scene analysis among others.  However, to successfully use Bayesian nonparametric models to analyse the high-dimensional and structured datasets now commonly encountered in the age of Big Data, we will have to overcome a number of challenges.  Namely, we need to develop Bayesian nonparametric models that can learn rich representations from structured data, and we need computational methodologies that can scale effectively to the large and complex models of the future.  We will ground our developments in relevant applications, particularly to natural language processing (learning distributed representations for language modelling and compositional semantics) and genetics (modelling genetic variations arising from population, genealogical and spatial structures).</Summary><Max_ERC_funding>1,918,092</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="BLACARAT"><Rcn>111516</Rcn><Nid>10084</Nid><HI>Paul Scherrer Institut, Switzerland</HI><Name>"Black Carbon in the Atmosphere: Emissions, Aging and Cloud Interactions"</Name><PI>Martin Gysel Beer</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Atmospheric aerosol particles have been shown to impact the earth's climate because they scatter and absorb solar radiation (direct effect) and because they can modify the microphysical properties of clouds by acting as cloud condensation nuclei or ice nuclei (indirect effects). Radiative forcing by anthropogenic aerosols remains poorly quantified, thus leading to considerable uncertainty in our understanding of the earth&#8217;s climate response to the radiative forcing by greenhouse gases. Black carbon (BC), mostly emitted by anthropogenic combustion processes and biomass burning, is an important component of atmospheric aerosols. Estimates show that BC may be the second strongest contributor (after CO2) to global warming. Adverse health effects due to particulate air pollution have also been associated with traffic-related BC particles. These climate and health effects brought BC emission reductions into the political focus of possible mitigation strategies with immediate and multiple benefits for human well-being.

Laboratory experiments aim at the physical and chemical characterisation of BC emissions from diesel engines and biomass burning under controlled conditions. A mobile laboratory equipped with state-of-the-art aerosol sensors will be used to determine the contribution of different BC sources to atmospheric BC loadings, and to investigate the evolution of the relevant BC properties with atmospheric aging during transport from sources to remote areas. The interactions of BC particles with clouds as a function of BC properties will be investigated with in-situ measurements by operating quantitative single particle instruments behind a novel sampling inlet, which makes selective sampling of interstitial, cloud droplet residual or ice crystal residual particles possible. Above experimental studies aim at improving our understanding of BC&#8217;s atmospheric life cycle and will be used in model simulations for quantitatively assessing the atmospheric impacts of BC."</Summary><Max_ERC_funding>1,992,015</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="A-BINGOS"><Rcn>185648</Rcn><Nid>12022</Nid><HI>Foundation For Research And Technology Hellas, Greece</HI><Name>Accreting binary populations in Nearby Galaxies: Observations and Simulations</Name><PI>Andreas Zezas</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"High-energy observations of our Galaxy offer a good, albeit not complete, picture of the X-ray source populations, in particular the accreting binary sources. Recent ability to study accreting binaries in nearby galaxies has shown that we would be short-sighted if we restricted ourselves to our Galaxy or to a few nearby ones. I propose an ambitious project that involves a comprehensive study of all the galaxies within 10 Mpc for which we can study in detail their X-ray sources and stellar populations. The study will combine data from a unique suite of observatories (Chandra, XMM-Newton, HST, Spitzer) with state-of-the-art theoretical modelling of binary systems. I propose a novel approach that links the accreting binary populations to their parent stellar populations and surpasses any current studies of X-ray binary populations, both in scale and in scope, by: (a) combining methods and results from several different areas of astrophysics (compact objects, binary systems, stellar populations, galaxy evolution); (b) using data from almost the whole electromagnetic spectrum (infrared to X-ray bands); (c) identifying and studying the different sub-populations of accreting binaries; and (d) performing direct comparison between observations and theoretical predictions, over a broad parameter space. The project: (a) will answer the long-standing question of the formation efficiency of accreting binaries in different environments; and (b) will constrain their evolutionary paths. As by-products the project will provide eagerly awaited input to the fields of gravitational-wave sources, &#206;&#179;-ray bursts, and X-ray emitting galaxies at cosmological distances and it will produce a heritage multi-wavelength dataset and library of models for future studies of galaxies and accreting binaries."</Summary><Max_ERC_funding>1,242,000</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ACOPS"><Rcn>111552</Rcn><Nid>10065</Nid><HI>Friedrich-Schiller-Universitat Jena, Germany</HI><Name>Advanced Coherent Ultrafast Laser Pulse Stacking</Name><PI>Jens Limpert</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"An important driver of scientific progress has always been the envisioning of applications far beyond existing technological capabilities. Such thinking creates new challenges for physicists, driven by the groundbreaking nature of the anticipated application. In the case of laser physics, one of these applications is laser wake-field particle acceleration and possible future uses thereof, such as in collider experiments, or for medical applications such as cancer treatment. To accelerate electrons and positrons to TeV-energies, a laser architecture is required that allows for the combination of high efficiency, Petawatt peak powers, and Megawatt average powers. Developing such a laser system would be a challenging task that might take decades of aggressive research, development, and, most important, revolutionary approaches and innovative ideas.
The goal of the ACOPS project is to develop a compact, efficient, scalable, and cost-effective high-average and high-peak power ultra-short pulse laser concept.
The proposed approach to this goal relies on the spatially and temporally separated amplification of ultrashort laser pulses in waveguide structures, followed by coherent combination into a single train of pulses with increased average power and pulse energy. This combination can be realized through the coherent addition of the output beams of spatially separated amplifiers, combined with the pulse stacking of temporally separated pulses in passive enhancement cavities, employing a fast-switching element as cavity dumper.
Therefore, the three main tasks are the development of kW-class high-repetition-rate driving lasers, the investigation of non-steady state pulse enhancement in passive cavities, and the development of a suitable dumping element.
If successful, the proposed concept would undoubtedly provide a tool that would allow researchers to surpass the current limits in high-field physics and accelerator science."</Summary><Max_ERC_funding>1,881,040</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="ACUITY"><Rcn>185678</Rcn><Nid>12314</Nid><HI>Technische Universiteit Eindhoven, Netherlands</HI><Name>Algorithms for coping with uncertainty and intractability</Name><PI>Nikhil Bansal</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"The two biggest challenges in solving practical optimization problems are computational intractability, and the presence
of uncertainty: most problems are either NP-hard, or have incomplete input data which
makes an exact computation impossible.

Recently, there has been a huge progress in our understanding of intractability, based on spectacular algorithmic and lower bound techniques. For several problems, especially those with only local constraints, we can design optimum
approximation algorithms that are provably the best possible.
However, typical optimization problems usually involve complex global constraints and are much less understood. The situation is even worse for coping with uncertainty. Most of the algorithms are based on ad-hoc techniques and there is no deeper understanding of what makes various problems easy or hard.

This proposal describes several new directions, together with concrete intermediate goals, that will break important new ground in the theory of approximation and online algorithms. The particular directions we consider are (i) extend the primal dual method to systematically design online algorithms, (ii) build a structural theory of online problems based on work functions, (iii) develop new tools to use the power of strong convex relaxations and (iv) design new algorithmic approaches based on  non-constructive proof techniques.

The proposed research is at the
cutting edge of algorithm design, and builds upon the recent success of the PI in resolving several longstanding questions in these areas. Any progress is likely to be a significant contribution to theoretical
computer science and combinatorial optimization."</Summary><Max_ERC_funding>1,519,285</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="ALERT"><Rcn>191235</Rcn><Nid>10581</Nid><HI>Stichting Astron, Netherlands Institute For Radio Astronomy, Netherlands</HI><Name>ALERT- The Apertif-LOFAR Exploration of the Radio Transient Sky</Name><PI>Albert Van Leeuwen</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"In our largely unchanging radio Universe, a highly dynamic component was recently discovered: flashes of bright radio emission that last only milliseconds but appear all over the sky. Some of these radio bursts can be traced to intermittently pulsating neutron stars. Other bursts however, apparently originate far outside our Galaxy. Due to great observational challenges, the evolution of the neutron stars is not understood, while more importantly, the nature of the extragalactic bursts remains an outright mystery.

My overall aim is to understand the physics that drives both kinds of brief and luminous bursts.

My primary goal is to identify the highly compact astrophysical explosions powering the extragalactic  bursts. My previous surveys are the state of the art in fast-transient detection; I will now increase by a factor of 10 this exploration volume.  In real-time I will provide arcsec positions, 10,000-fold more accurate than currently possible, to localize such extragalactic bursts for the first time and understand their origin.

My secondary goal is to unravel the unexplained evolution of intermittently pulsating neutron stars (building on e.g., my recent papers in Science, 2013), by doubling their number and modeling their population.

To achieve these goals, I will carry out a highly innovative survey: the Apertif-LOFAR Exploration of the Radio Transient Sky. ALERT is over an order of magnitude more sensitive than all current state-of-the art fast-transient surveys.

Through its novel, extremely wide field-of-view, Westerbork/Apertif will detect many tens of extragalactic bursts. Through real-time triggers to LOFAR I will next provide the precise localisation that is essential for radio, optical and high-energy follow-up to, for the first time, shed light on the physics and objects driving these bursts &#226;&#128;&#147; evaporating primordial black holes; explosions in host galaxies; or, the unknown?"</Summary><Max_ERC_funding>1,999,823</Max_ERC_funding><Duration><Start_date> 2014-12-01, </Start_date><End_date> 2019-11-30</End_date></Duration></Project><Project acronym="ALUNIF"><Rcn>111544</Rcn><Nid>11829</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Oxford, United Kingdom</HI><Name>Algorithms and Lower Bounds: A Unified Approach</Name><PI>Rahul Santhanam</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>One of the fundamental goals of theoretical computer science is to
understand the possibilities and limits of efficient computation. This
quest has two dimensions. The
theory of algorithms focuses on finding efficient solutions to
problems, while computational complexity theory aims to understand when
and why problems are hard to solve. These two areas have different
philosophies and use different sets of techniques. However, in recent
years there have been indications of deep and mysterious connections
between them.

In this project, we propose to explore and develop the connections between
algorithmic analysis and complexity lower bounds in a systematic way.
On the one hand, we plan to use complexity lower bound techniques as inspiration
to design new and improved algorithms for Satisfiability and other
NP-complete problems, as well as to analyze existing algorithms better.
On the other hand, we plan to strengthen implications yielding circuit
lower bounds from non-trivial algorithms for Satisfiability, and to derive
new circuit lower bounds using these stronger implications.

This project has potential for massive impact in both the areas of algorithms
and computational complexity. Improved algorithms for Satisfiability could lead
to improved SAT solvers, and the new analytical tools would lead to a better
understanding of existing heuristics. Complexity lower bound questions are
fundamental
but notoriously difficult, and new lower bounds would open the way to
unconditionally secure cryptographic protocols and derandomization of
probabilistic algorithms. More broadly, this project aims to initiate greater
dialogue between the two areas, with an exchange of ideas and techniques
which leads to accelerated progress in both, as well as a deeper understanding
of the nature of efficient computation.</Summary><Max_ERC_funding>1,274,496</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="ASIBIA"><Rcn>185645</Rcn><Nid>12021</Nid><HI>University Of East Anglia, United Kingdom</HI><Name>Arctic sea ice, biogeochemistry and impacts on the atmosphere: Past, present, future</Name><PI>Roland Von Glasow</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>The Arctic Ocean is a vast expanse of sea ice. Most of it is snow covered as are large continental regions for about half of the year. However, Global Change is arguably greatest in the Arctic, where temperatures have risen more than anywhere else in the last few decades. New record lows occurred in snow extent in June 2012 and sea ice extent in September 2012. Many observations show that widespread and sustained change is occurring in the Arctic driving this unique environmental system into a new state. This project focuses on the biogeochemical links between sea ice and snow and the composition and chemistry of the troposphere (the lowest ~10km of the atmosphere). This is an important topic because the concentrations of greenhouse gases and aerosol particles, which scatter sunlight directly and influence cloud properties, play key roles for our climate. Additionally, changes in the composition of the troposphere also affect the so-called oxidation capacity, the capability of the atmosphere to cleanse itself from pollutants.
This project aims to deliver a step change improvement in our quantitative understanding of chemical exchanges between ocean, sea ice, snow and the atmosphere in polar regions, especially the Arctic and of Arctic tropospheric chemistry. Answering these fundamental questions is essential to predict future change in the Arctic and globally. To this end a unique sea ice chamber will be constructed in the laboratory and used to quantify exchange processes in sea ice. Furthermore a hierarchy of numerical models will be used, operating at different spatial and temporal scales and degree of process description from a very detailed 1D to a global Earth System model. This will allow a breakthrough in our understanding of the importance of the changes for the composition and oxidation capacity of the atmosphere and climate and will allow us to calculate adjusted Greenhouse Warming Potentials that include these processes.</Summary><Max_ERC_funding>1,192,911</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2016-09-30</End_date></Duration></Project><Project acronym="AUGURY"><Rcn>185668</Rcn><Nid>12026</Nid><HI>Universite Lyon 1 Claude Bernard, France</HI><Name>Reconstructing Earth&#226;&#128;&#153;s mantle convection</Name><PI>Nicolas Coltice</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Knowledge of the state of the Earth mantle and its temporal evolution is fundamental to a variety of disciplines in Earth Sciences, from the internal dynamics to its many expressions in the geological record (postglacial rebound, sea level change, ore deposit, tectonics or geomagnetic reversals). Mantle convection theory is the centerpiece to unravel the present and past state of the mantle. For the past 40 years considerable efforts have been made to improve the quality of numerical models of mantle convection. However, they are still sparsely used to estimate the convective history of the solid Earth, in comparison to ocean or atmospheric models for weather and climate prediction. The main shortcoming is their inability to successfully produce Earth-like seafloor spreading and continental drift self-consistently. Recent convection models have begun to successfully predict these processes (Coltice et al., Science 336, 335-33, 2012). Such breakthrough opens the opportunity to combine high-level data assimilation methodologies and convection models together with advanced tectonic datasets to retrieve Earth's mantle history. The scope of this project is to produce a new generation of tectonic and convection reconstructions, which are key to improve our understanding and knowledge of the evolution of the solid Earth. The development of sustainable high performance numerical models will set new standards for geodynamic data assimilation. The outcome of the AUGURY project will be a new generation of models crucial to a wide variety of disciplines."</Summary><Max_ERC_funding>1,994,000</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="AdOC"><Rcn>185666</Rcn><Nid>10729</Nid><HI>Centre National De La Recherche Scientifique Cnrs, France</HI><Name>Advance Optical Clocks</Name><PI>Sebastien Andr&#195;&#169; Marcel Bize</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"The proposed research program has three main objectives. The first and second objectives are to seek extreme precisions in optical atomic spectroscopy and optical clocks, and to use this quest as a mean of exploration in atomic physics. The third objective is to explore new possibilities that stem from extreme precision. These goals will be pursued via three complementary activities: #1: Search for extreme precisions with an Hg optical lattice clock. #2: Explore and exploit the rich Hg system, which is essentially unexplored in the cold and ultra-cold regime. #3: Identify new applications of clocks with extreme precision to Earth science. Clocks can measure directly the gravitational potential via Einstein&#226;&#128;&#153;s gravitational redshift, leading to the idea of &#226;&#128;&#156;clock-based geodesy&#226;&#128;&#157;.
The 2 first activities are experimental and build on an existing setup, where we demonstrated the feasibility of an Hg optical lattice clock. Hg is chosen for its potential to surpass competing systems. We will investigate the unexplored physics of the Hg clock. This includes interactions between Hg atoms, lattice-induced light shifts, and sensitivity to external fields which are specific to the atomic species. Beyond, we will explore the fundamental limits of the optical lattice scheme. We will exploit other remarkable features of Hg associated to the high atomic number and the diversity of stable isotopes. These features enable tests of fundamental physical laws, ultra-precise measurements of isotope shifts, measurement of collisional properties toward evaporative cooling and quantum gases of Hg, investigation of forbidden transitions promising for measuring the nuclear anapole moment of Hg.
The third activity is theoretical and is aimed at initiating collaborations with experts in modelling Earth gravity. With this expertise, we will identify the most promising and realistic approaches for clocks and emerging remote comparison methods to contribute to geodesy, hydrology, oceanography, etc."</Summary><Max_ERC_funding>1,946,432</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="BIGBAYES"><Rcn>192413</Rcn><Nid>13428</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Oxford, United Kingdom</HI><Name>Rich, Structured and Efficient Learning of Big Bayesian Models</Name><PI>Yee Whye Teh</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>As datasets grow ever larger in scale, complexity and variety, there is an increasing need for powerful machine learning and statistical techniques that are capable of learning from such data. Bayesian nonparametrics is a promising approach to data analysis that is increasingly popular in machine learning and statistics.  Bayesian nonparametric models are highly flexible models with infinite-dimensional parameter spaces that can be used to directly parameterise and learn about functions, densities, conditional distributions etc, and  have been successfully applied to regression, survival analysis, language modelling, time series analysis, and visual scene analysis among others.  However, to successfully use Bayesian nonparametric models to analyse the high-dimensional and structured datasets now commonly encountered in the age of Big Data, we will have to overcome a number of challenges.  Namely, we need to develop Bayesian nonparametric models that can learn rich representations from structured data, and we need computational methodologies that can scale effectively to the large and complex models of the future.  We will ground our developments in relevant applications, particularly to natural language processing (learning distributed representations for language modelling and compositional semantics) and genetics (modelling genetic variations arising from population, genealogical and spatial structures).</Summary><Max_ERC_funding>1,918,092</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="BLACARAT"><Rcn>111516</Rcn><Nid>10084</Nid><HI>Paul Scherrer Institut, Switzerland</HI><Name>"Black Carbon in the Atmosphere: Emissions, Aging and Cloud Interactions"</Name><PI>Martin Gysel Beer</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Atmospheric aerosol particles have been shown to impact the earth's climate because they scatter and absorb solar radiation (direct effect) and because they can modify the microphysical properties of clouds by acting as cloud condensation nuclei or ice nuclei (indirect effects). Radiative forcing by anthropogenic aerosols remains poorly quantified, thus leading to considerable uncertainty in our understanding of the earth&#226;&#128;&#153;s climate response to the radiative forcing by greenhouse gases. Black carbon (BC), mostly emitted by anthropogenic combustion processes and biomass burning, is an important component of atmospheric aerosols. Estimates show that BC may be the second strongest contributor (after CO2) to global warming. Adverse health effects due to particulate air pollution have also been associated with traffic-related BC particles. These climate and health effects brought BC emission reductions into the political focus of possible mitigation strategies with immediate and multiple benefits for human well-being.

Laboratory experiments aim at the physical and chemical characterisation of BC emissions from diesel engines and biomass burning under controlled conditions. A mobile laboratory equipped with state-of-the-art aerosol sensors will be used to determine the contribution of different BC sources to atmospheric BC loadings, and to investigate the evolution of the relevant BC properties with atmospheric aging during transport from sources to remote areas. The interactions of BC particles with clouds as a function of BC properties will be investigated with in-situ measurements by operating quantitative single particle instruments behind a novel sampling inlet, which makes selective sampling of interstitial, cloud droplet residual or ice crystal residual particles possible. Above experimental studies aim at improving our understanding of BC&#226;&#128;&#153;s atmospheric life cycle and will be used in model simulations for quantitatively assessing the atmospheric impacts of BC."</Summary><Max_ERC_funding>1,992,015</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="BLACK"><Rcn>188648</Rcn><Nid>10643</Nid><HI>Centre National De La Recherche Scientifique, France</HI><Name>The formation and evolution of massive black holes</Name><PI>Marta Volonteri</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"Massive black holes (MBHs) weighing million solar masses and above inhabit the centers of today's galaxies, weighing about a thousandth of the host bulge mass. MBHs also powered quasars known to exist just a few hundred million years after the Big Bang. Owing to observational breakthroughs and remarkable advancements in theoretical models, we do now that MBHs are out there and evolved with their hosts, but we do not know how they got there nor how, and when, the connection between MBHs and hosts was established.
To have a full view of MBH formation and growth we have to look at the global process where galaxies form, as determined by the large-scale structure, on Mpc scales. On the other hand, the region where MBHs dominate the dynamics of gas and stars, and accretion occurs, is merely pc-scale. To study the formation of MBHs and their fuelling we must bridge from Mpc to pc scale in order to follow how galaxies influence MBHs and how in turn MBHs influence galaxies.
BLACK aims to connect the cosmic context to the nuclear region where MBHs reside, and to study MBH formation, feeding and feedback on their hosts through a multi-scale approach following the thread of MBHs from cosmological, to galactic, to nuclear scales. Analytical work guides and tests numerical simulations, allowing us to probe a wide dynamical range.
Our theoretical work will be crucial for planning and interpreting current and future observations. Today and in the near future facilities at wavelengths spanning from radio to X-ray will widen and deepen our view of the Universe, making this an ideal time for this line of research."</Summary><Max_ERC_funding>1,668,385</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="BTVI"><Rcn>185654</Rcn><Nid>10011</Nid><HI>Aarhus Universitet, Denmark</HI><Name>First Biodegradable Biocatalytic VascularTherapeutic Implants</Name><PI>Alexander Zelikin</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"We aim to perform academic development of a novel biomedical opportunity: localized synthesis of drugs within biocatalytic therapeutic vascular implants (BVI) for site-specific drug delivery to target organs and tissues. Primary envisioned targets for therapeutic intervention using BVI are atherosclerosis, viral hepatitis, and hepatocellular carcinoma: three of the most prevalent and debilitating conditions which affect hundreds of millions worldwide and which continue to increase in their importance in the era of increasingly aging population. For hepatic applications, we aim to develop drug eluting beads which are equipped with tools of enzyme-prodrug therapy (EPT) and are administered to the liver via trans-arterial catheter embolization. Therein, the beads perform localized synthesis of drugs and imaging reagents for anticancer combination therapy and theranostics, antiviral and anti-inflammatory agents for the treatment of hepatitis. Further, we conceive vascular therapeutic inserts (VTI) as a novel type of implantable biomaterials for treatment of atherosclerosis and re-endothelialization of vascular stents and grafts. Using EPT, inserts will tame &#226;&#128;&#156;the guardian of cardiovascular grafts&#226;&#128;&#157;, nitric oxide, for which localized, site specific synthesis and delivery spell success of therapeutic intervention and/or aided tissue regeneration. This proposal is positioned on the forefront of biomedical engineering and its success requires excellence in polymer chemistry, materials design, medicinal chemistry, and translational medicine. Each part of this proposal - design of novel types of vascular implants, engineering novel biomaterials, developing innovative fabrication and characterization techniques &#226;&#128;&#147; is of high value for fundamental biomedical sciences. The project is target-oriented and once successful, will be of highest practical value and contribute to increased quality of life of millions of people worldwide."</Summary><Max_ERC_funding>1,996,126</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="BrainMicroFlow"><Rcn>188659</Rcn><Nid>12213</Nid><HI>Centre National De La Recherche Scientifique Cnrs, France</HI><Name>Brain Microcirculation: Numerical simulation for inter-species translation with applications in human health</Name><PI>Sylvie, Jeanine Lejeune &#195;&#169;p Lorthois</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>The cerebral microvascular system is essential to a large variety of physiological processes in the brain, including blood delivery and blood flow regulation as a function of neuronal activity (neuro-vascular coupling). It plays a major role in the associated mechanisms leading to disease (stroke, neurodegenerative diseases, &#226;&#128;&#166;). In the last decade, cutting edge technologies, including two-photon scanning laser microscopy (TPSLM) and optical manipulation of blood flow, have produced huge amounts of anatomic and functional experimental data in normal and Alzheimer Disease (AD) mice. These require accurate, highly quantitative, physiologically informed modeling and analysis for any coherent understanding and for translating results between species.
In this context, our first aim is to develop a general methodological framework for physiologically informed microvascular fluid dynamics modeling, understood in a broad meaning, i.e. blood flow, molecule transport and resulting functional imaging signals or signal surrogates.
Our second aim is to validate this methodological framework by direct comparison of in vivo anatomical and functional TPSLM measurements with the simulation results based on the same anatomical data.
The third objective is to exploit these methodologies in order to identify the logic of the structure/function relationships of brain microcirculation and neurovascular coupling, in human health and disease, with a focus on the role of vascular factors in AD.
Specific hypotheses on how vascular changes in AD affect both vascular function and neurovascular coupling can be experimentally tested in animal models of AD. Crucially, similar anatomical (but not functional) data can be acquired in healthy and AD humans. This will enable us to model how AD-induced vascular alterations could affect human patients. Ultimately, it provides us with new avenues for design and/or evaluation of improved diagnosis/preventive/treatment strategies.</Summary><Max_ERC_funding>1,999,873</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="BubbleBoost"><Rcn>185557</Rcn><Nid>12004</Nid><HI>Centre National De La Recherche Scientifique Cnrs, France</HI><Name>Microfluidic bubbles for novel applications: acoustic laser and ultrasonically controlled swimming microrobots</Name><PI>Philippe, Guy, Marie Marmottant</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>Microfluidic techniques developed since the year 2000 have now matured to provide a unique tool to produce large amounts of microbubbles that are not only finely tuned in size, but that can also be embedded in tiny microfabricated structures.

In the present proposal, we plan to take advantage of these novel microfabrication techniques to develop two innovative acoustic applications. These applications, which were out of reach without current techniques, are based on the use of microbubbles with a huge acoustic resonance. The project is structured in two parts that only differ in the way bubbles are embedded in microfluidic environments:

1) Arrays of bubbles: Acoustic Laser
This first part is the development of an acoustic laser, based on microbubbles trapped in a microfluidic circuit. To obtain the conditions for an acoustic laser, arrays of microbubbles will be designed so that they bubbles pulsate in phase, reemitting their energy coherently. The applications are novel systems for high ultrasonic emission power, or meta-materials that store vibration energy.

2) Mobile &#226;&#128;&#156;armoured&#226;&#128;&#157; bubbles:  swimming micro-robots remotely powered by ultrasound
The second part is the conception of ultrasonically activated microswimming devices, with microbubbles embedded within freely moving objects. Their application is to behave as carriers, such as drug carriers, activated at a distance, or to be active tracers that enhance mixing. Microswimmers are mechanical analogues to RFID devices (where electromagnetic vibration is converted into current), here sound is converted into motion at small scales.

Both parts include the same three complementary steps: step 1 is the 3D microfabrication of the geometry where bubbles are embedded, step 2 is their ultrasonic activation, and then step 3 is the optimisation of their resonance by a study of individual resonators.</Summary><Max_ERC_funding>1,856,542</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="CAUSALPATH"><Rcn>191274</Rcn><Nid>10579</Nid><HI>Panepistimio Kritis, Greece</HI><Name>Next Generation Causal Analysis: Inspired by the Induction of Biological Pathways from Cytometry Data</Name><PI>Ioannis Tsamardinos</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>Discovering the causal mechanisms of a complex system of interacting components is necessary in order to control it. Computational Causal Discovery (CD) is a field that offers the potential to discover causal relations under certain conditions from observational data alone or with a limited number of interventions/manipulations.

An important, challenging biological problem that may take decades of experimental work is the induction of biological cellular pathways; pathways are informal causal models indispensable in biological research and drug design. Recent exciting advances in flow/mass cytometry biotechnology allow the generation of large-sample datasets containing measurements on single cells, thus setting the problem of pathway learning suitable for CD methods.
CAUSALPATH builds upon and further advances recent breakthrough developments in CD methods to enable the induction of biological pathways from cytometry and other omics data. As a testbed problem we focus on the differentiation of human T-cells; these are involved in autoimmune and inflammatory diseases, as well as cancer and thus, are targets of new drug development for a range of chronic diseases. The biological problem acts as our campus for general novel formalisms, practical algorithms, and useful tools development, pointing to fundamental CD problems: presence of feedback cycles, presence of latent confounding variables, CD from time-course data, Integrative Causal Analysis (INCA) of heterogeneous datasets and others.

Three features complement CAUSALPATH&#226;&#128;&#153;s approach: (A) methods development will co-evolve with biological wet-lab experiments periodically testing the algorithmic postulates, (B) Open-source tools will be developed for the non-expert, and (C) Commercial exploitation of the results will be sought out.

CAUSALPATH brings together an interdisciplinary team, committed to this vision. It builds upon the PI&#226;&#128;&#153;s group recent important results on INCA algorithms.</Summary><Max_ERC_funding>1,724,000</Max_ERC_funding><Duration><Start_date> 2015-01-01, </Start_date><End_date> 2019-12-31</End_date></Duration></Project><Project acronym="CAVITYQPD"><Rcn>185609</Rcn><Nid>11374</Nid><HI>Aalto-Korkeakoulusaatio, Finland</HI><Name>Cavity quantum phonon dynamics</Name><PI>Mika Antero Sillanp&#195;&#164;&#195;&#164;</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Large bodies usually follow the classical equations of motion. Deviations from this can be called
macroscopic quantum behavior. These phenomena have been experimentally verified with cavity Quantum
Electro Dynamics (QED), trapped ions, and superconducting Josephson junction systems. Recently, evidence
was obtained that also moving objects can display such behavior. These objects are micromechanical
resonators (MR), which can measure tens of microns in size and are hence quite macroscopic. The degree of
freedom is their vibrations: phonons.

I propose experimental research in order to push quantum mechanics closer to the classical world than ever
before. I will try find quantum behavior in the most classical objects, that is, slowly moving bodies. I will use
MR's, accessed via electrical resonators. Part of it will be in analogy to the previously studied macroscopic
systems, but with photons replaced by phonons. The experiments are done in a cryogenic temperature mostly
in dilution refrigerator. The work will open up new perspectives on how nature works, and can have
technological implications.

The first basic setup is the coupling of MR to microwave cavity resonators. This is a direct analogy to
optomechanics, and can be called circuit optomechanics. The goals will be phonon state transfer via a cavity
bus, construction of squeezed states and of phonon-cavity entanglement. The second setup is to boost the
optomechanical coupling with a Josephson junction system, and reach the single-phonon strong-coupling for
the first time. The third setup is the coupling of MR to a Josephson junction artificial atom. Here we will
access the MR same way as the motion of a trapped ions is coupled to their internal transitions. In this setup,
I am proposing to construct exotic quantum states of motion, and finally entangle and transfer phonons over
mm-distance via cavity-coupled qubits. I believe within the project it is possible to perform rudimentary Bell
measurement with phonons."</Summary><Max_ERC_funding>2,004,283</Max_ERC_funding><Duration><Start_date> 2015-01-01, </Start_date><End_date> 2019-12-31</End_date></Duration></Project><Project acronym="CHRONOS"><Rcn>185535</Rcn><Nid>11965</Nid><HI>Universita Degli Studi Di Perugia, Italy</HI><Name>A geochemical clock to measure timescales of volcanic eruptions</Name><PI>Diego Perugini</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"The eruption of volcanoes appears one of the most unpredictable phenomena on Earth. Yet the situation is rapidly changing. Quantification of the eruptive record constrains what is possible in a given volcanic system. Timing is the hardest part to quantify.
The main process triggering an eruption is the refilling of a sub-volcanic magma chamber by a new magma coming from depth. This process results in magma mixing and provokes a time-dependent diffusion of chemical elements. Understanding the time elapsed from mixing to eruption is fundamental to discerning pre-eruptive behaviour of volcanoes to mitigate the huge impact of volcanic eruptions on society and the environment.
The CHRONOS project proposes a new method that will cut the Gordian knot of the presently intractable problem of volcanic eruption timing using a surgical approach integrating textural, geochemical and experimental data on magma mixing. I will use the compositional heterogeneity frozen in time in the rocks the same way a broken clock at a crime scene is used to determine the time of the incident. CHRONOS will aim to:
1) be the first study to reproduce magma mixing, by performing unique experiments constrained by natural data and using natural melts, under controlled rheological and fluid-dynamics conditions;
2) obtain unprecedented high-quality data on the time dependence of chemical exchanges during magma mixing;
3) derive empirical relationships linking the extent of chemical exchanges and the mixing timescales;
4) determine timescales of volcanic eruptions combining natural and experimental data.
CHRONOS will open a new window on the physico-chemical processes occurring in the days preceding volcanic eruptions providing unprecedented information to build the first inventory of eruption timescales for planet Earth. If these timescales can be linked with geophysical signals occurring prior to eruptions, this inventory will have an immense value, enabling precise prediction of volcanic eruptions."</Summary><Max_ERC_funding>1,993,813</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="CIRQUSS"><Rcn>111475</Rcn><Nid>11831</Nid><HI>Commissariat A L Energie Atomique Et Aux Energies Alternatives, France</HI><Name>Circuit Quantum Electrodynamics with Single Electronic and Nuclear Spins</Name><PI>Patrice Emmanuel Bertet</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Electronic spins are usually detected by their interaction with electromagnetic fields at microwave frequencies. Since this interaction is very weak, only large ensembles of spins can be detected. In circuit quantum electrodynamics (cQED) on the other hand, artificial superconducting atoms are made to interact strongly with microwave fields at the single photon level, and quantum-limited detection of few-photon microwave signals has been developed.

The goal of this project is to apply the concepts and techniques of cQED to the detection and manipulation of electronic and nuclear spins, in order to reach a novel regime in which a single electronic spin strongly interacts with single microwave photons. This will lead to

1)	A considerable enhancement of the sensitivity of spin detection by microwave methods. We plan to detect resonantly single electronic spins in a few milliseconds. This could enable A) to perform electron spin resonance spectroscopy on few-molecule samples B) to measure the magnetization of various nano-objects at millikelvin temperatures, using the spin as a magnetic sensor with nanoscale resolution.

2)	Applications in quantum information science. Strong interaction with microwave fields at the quantum level will enable the generation of entangled states of distant individual electronic and nuclear spins, using superconducting qubits, resonators and microwave photons, as &#226;&#128;&#156;quantum data buses&#226;&#128;&#157; mediating the entanglement. Since spins can have coherence times in the seconds range, this could pave the way towards a scalable implementation of quantum information processing protocols.

These ideas will be primarily implemented with NV centers in diamond, which are electronic spins with properties suitable for the project."</Summary><Max_ERC_funding>1,999,995</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="COMANCHE"><Rcn>185579</Rcn><Nid>12335</Nid><HI>Consiglio Nazionale Delle Ricerche, Italy</HI><Name>Coherent manipulation and control of heat in solid-state nanostructures: the era of coherent caloritronics</Name><PI>Francesco Giazotto</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Electronic nanodevices have demonstrated to be versatile and effective tools for the investigation of exotic quantum phenomena under controlled and adjustable conditions. Yet, these have enabled to give access to the manipulation of charge flow with unprecedented precision. On the other hand, the wisdom dealing with control, measurements, storage, and conversion of heat in nanoscale devices, the so-called &#226;&#128;&#156;caloritronics&#226;&#128;&#157; (from the Latin word &#226;&#128;&#156;calor&#226;&#128;&#157;, i.e., heat),  despite a number of recent advances is still at its infancy. Although coherence often plays a crucial role in determining the functionalities of nanoelectronic devices very little is known of its role in caloritronics. In such a context, coherent control of heat seems at present still very far from reach, and devising methods to phase-coherently manipulate the thermal current would represent a crucial breakthrough which could open the door to unprecedented possibilities in several fields of science.
Here we propose an original approach to set the experimental ground for the investigation and implementation of a new branch of science, the &#226;&#128;&#156;coherent caloritronics&#226;&#128;&#157;, which will take advantage of quantum circuits to phase-coherently manipulate and control the heat current in solid-state nanostructures. To tackle this challenging task our approach will follow three main separate approaches, i.e., the coherent control of heat transported by electrons in Josephson nanocircuits, the coherent manipulation of heat carried by electrons and exchanged between electrons and lattice phonons in superconducting proximity systems,
and finally, the control of the heat exchanged between electrons and photons by coherently tuning the coupling with the electromagnetic environment. We will integrate superconductors with normal-metal or semiconductor electrodes thus exploring new device concepts such as heat transistors, heat diodes, heat splitters, where thermal flux control is achieved thanks to the use of the quantum phase."</Summary><Max_ERC_funding>1,754,897</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="COMBAT"><Rcn>111425</Rcn><Nid>11833</Nid><HI>Bauhaus-Universitaet Weimar, Germany</HI><Name>Computational Modeling and Design of Lithium-Ion Batteries</Name><PI>Timon Rabczuk</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"Lithium-ion batteries (LIBs) are among the most promising solutions for energy storage. Compared with other resources such as bio-fuel, solar cells, fuel cells or lead acid batteries, rechargeable batteries are more portable and allow for quick energy storage and release. The higher power and energy density make batteries suitable as the energy resource for most portable elect. devices including future vehicles. Among the rechargeable batteries, LIBs have the most potential because of their quick charging rate and high power and energy density. However, ageing of LIBs and the related capacity and power fade is a major concern. For the improvement and future development of batteries, computational modeling and design is an important complementary part to experimental testing which is expensive, time-consuming and sometimes unfeasible.

In this project, the PI proposes to develop, implement, verify and validate a computational multifield and multiscale framework to support the design and optimization of new batteries. The computational framework will support the design and optimization of new anode, separator and cathode materials as well as their structure inside the battery. The measurable outcome of this research will be an open-source software package that can be used to support the design and optimization of LIBs.

Within the computational framework, different (mechanical-thermal-electro-chemical) fields will be linked over multiple scales: from fundamental physics to the design of new battery materials. We will quantify uncertainties in order to provide upper and lower bounds of our predictions and use graph-theory, error-estimation and adaptivity to choose the appropriate model and discretization. The computational framework will be verified and validated by comparison to experiments. Finally, multi-objective optimization over multiple scales will provide a new battery prototype that will be manufactured, tested and compared to the computational predictions."</Summary><Max_ERC_funding>1,975,071</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="COMOTION"><Rcn>191795</Rcn><Nid>10743</Nid><HI>Stiftung Deutsches Elektronen-Synchrotron Desy, Germany</HI><Name>Controlling the Motion of Complex Molecules and Particles</Name><PI>Jochen K&#195;&#188;pper</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"The main objective of COMOTION is to enable novel experiments for the investigation of the intrinsic properties of large molecules, including biological samples like proteins, viruses, and small cells
-X-ray free-electron lasers have enabled the observation of near-atomic-resolution structures in diffraction- before-destruction experiments, for instance, of isolated mimiviruses and of proteins from microscopic crystals. The goal to record molecular movies with spatial and temporal atomic-resolution (femtoseconds and picometers) of individual molecules is near.
-The investigation of ultrafast, sub-femtosecond electron dynamics in small molecules is providing first results. Its extension to large molecules promises the unraveling of charge migration and energy transport in complex (bio)molecules.
-Matter-wave experiments of large molecules, with currently up to some hundred atoms, are testing the limits of quantum mechanics, particle-wave duality, and coherence. These metrology experiments also allow the precise measurement of molecular properties.
The principal obstacle for these and similar experiments in molecular sciences is the controlled production of samples of identical molecules in the gas phase. We will develop novel concepts and technologies for the manipulation of complex molecules, ranging from amino acids to proteins, viruses, nano-objects, and small cells: We will implement new methods to inject complex molecules into vacuum, to rapidly cool them, and to manipulate the motion of these cold gas-phase samples using combinations of external electric and electromagnetic fields. These external-field handles enable the spatial separation of molecules according to size, shape, and isomer.
The generated controlled samples are ideally suited for the envisioned precision experiments. We will exploit them to record atomic-resolution molecular movies using the European XFEL, as well as to investigate the limits of quantum mechanics using matter-wave interferometry."</Summary><Max_ERC_funding>1,982,500</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="CORPHO"><Rcn>185623</Rcn><Nid>12014</Nid><HI>Universit&#195;&#169; Paris Diderot-Paris 7, France</HI><Name>Theory of strongly correlated photonic systems</Name><PI>Cristiano Ciuti</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"The physics of complex quantum systems with controllable interactions is emerging as a fundamental topic for a broad community, providing an opportunity to test theories of strongly correlated quantum many-body systems and opening interesting applications such as quantum simulators. Recently, in solid-state structures with effective photon-photon interactions the rich physics of quantum fluids of light has been explored, albeit not yet in the regime of strong photonic correlations. Exciting advances in cavity Quantum Electro-Dynamics (QED) and superconducting circuit QED make strong photon-photon interactions now accessible. A growing interest is focusing on lattices of coupled resonators, implementing Hubbard-like Hamiltonians for photons injected by pump driving fields. Similarly to electronic systems, the physics of large two-dimensional (2D) photonic lattices is a fundamental theoretical challenge in the regime of strong correlations. CORPHO has the ambition to develop novel scalable theoretical methods for 2D lattices of cavities, including spatially inhomogeneous driving and dissipation. The proposed methods are based on a hybrid strategy combining cluster mean-field theory and Wave Function Monte Carlo on a physical &#226;&#128;&#152;Corner&#226;&#128;&#153; of the Hilbert space in order to calculate the steady-state density matrix and the properties of the non-equilibrium phases. We will study 2D lattices with complex unit cells and &#226;&#128;&#152;fractional&#226;&#128;&#153; driving (only a fraction of the sites is pumped), a configuration that, according to recent preliminary studies, is expected to dramatically enhance and enrich quantum correlations.  We will also investigate the interplay between driving and geometric frustration in 2D lattices with polarization-dependent interactions. Finally, the quantum control of strongly correlated photonic systems will be explored, including quantum feedback processes, cooling of thermal fluctuations and switching between multi-stable phases."</Summary><Max_ERC_funding>1,378,440</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="CORRELMAT"><Rcn>189842</Rcn><Nid>11810</Nid><HI>Ecole Polytechnique, France</HI><Name>Predictive electronic structure calculations for materials with strong electronic correlations: long-range Coulomb interactions and many-body screening</Name><PI>Silke Biermann</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Materials with strong electronic Coulomb correlations present unique electronic properties such as exotic magnetism, charge or orbital order, or unconventional optical or transport properties, including superconductivity, thermoelectricity or metal-insulator transitions. The concerted behavior of the electrons in these ``correlated materials"" moreover leads to an extreme sensitivity to external stimuli such as changes in temperature, pressure, or external fields. This tuneability of even fundamental properties is both a harbinger for technological applications and a challenge to currently available theoretical methods: Indeed, these properties are the result of strong electron-electron interactions and subtle quantum correlations, and cannot be understood without a proper description of excited states.
The aim of the present project is to elaborate, implement and test new approaches to investigate the spectral and optical properties of correlated materials ``from first principles"", that is, without adjustable parameters. I will build on the success of state-of-the-art dynamical mean field-based electronic structure techniques, but aim at developing them into truly first-principles methods, where a full treatment of the long-range Coulomb interactions replaces the current practice of purely local Hubbard interaction parameters. My target materials are among the most interesting for modern technologies, such as transition metal oxides (with potential applications ranging from oxide electronics to battery materials) and rare earth compounds used as environmentally-responsible pigments. Establishing first-principles techniques with truly predictive power for these classes of materials will bring us closer to the final goal of tailoring correlated materials with preassigned properties."</Summary><Max_ERC_funding>1,713,600</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="CRYSBEAM"><Rcn>188658</Rcn><Nid>10641</Nid><HI>Istituto Nazionale Di Fisica Nucleare, Italy</HI><Name>Crystal channeling to extract a high energy hadron beam from an accelerator</Name><PI>Gianluca Cavoto</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"A new generation of parasitic beam extraction of high energy particles from an accelerator is proposed in CRYSBEAM. Instead of massive magnetic kickers, bent thin crystals trapping particles within the crystal lattice planes are used. This type of beam manipulation opens new fields of investigation of fundamental interactions between particles and of coherent interactions between particles and matter. An experiment in connection to Ultra High Energy Cosmic Rays study in Earth&#226;&#128;&#153;s high atmosphere can be conducted.
Several TeV energy protons or ions are deflected towards a chosen target by the bent lattice planes only when the lattice planes are parallel to the incoming particles direction.
The three key ingredients of CRYSBEAM are:
- a goniometer based on piezoelectric devices that orients a bent finely-polished low-miscut silicon crystal with a high resolution and repeatability, monitoring its position with synthetic diamond sensors. Novel procedures in crystal manufacturing &amp; testing and cutting-edge mechanical solutions for motion technology in vacuum are developed;
- a silica screen that measures the deflected particles via Cherenkov radiation  emission in micrometric optical waveguides. These are obtained with an ultra-short laser micro-machining technique as for photonic devices used in quantum optics and quantum computing. The screen is a direct beam-imaging detector for a high radiation dose environment;
- a smart absorber, which simulates the Earth&#226;&#128;&#153;s atmosphere, where particles are smashed and secondary showers are initiated. This sets the path to measure hadronic cross sections at an energy relevant for cosmic rays investigation.
The R&amp;D for the various components of such a system are carried out within this project and direct tests at CERN Super Proton Synchrotron to be performed prior to the final installation in the Large Hadron Collider at CERN are proposed. A new concept of particle accelerator operations will be finally set in place."</Summary><Max_ERC_funding>1,989,746</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="CosmoPars"><Rcn>188682</Rcn><Nid>12228</Nid><HI>University Of Sussex, United Kingdom</HI><Name>Precision Cosmological Parameters</Name><PI>Antony Martin Lewis</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>Proposal summary (half page, possibly copy/paste abstract from the administrative form A1)

Observations of the Cosmic Microwave Background (CMB) allow us to see 98% of the way to the big bang, back to a time when the Universe was only a few hundred thousand years old. Other forthcoming data will probe the more local universe in great detail. To test different possible universe models we need accurate theoretical predictions for this data in each model, and new sampling methods to solve the inference problem.

CMB data is most powerful if combined with information from other sources, allowing us to test many possible models of the universes and constrain cosmological parameters. As more models and parameters can be constrained, and higher precision means that more small uncertain corrections need to be consistently modelled, the problem of inference becomes challenging. I propose to develop ground-breaking new sampling methods for testing models with many parameters. To do this I will find novel sampling techniques, make efficient use of qualitatively different properties of different parameters, and develop a new parallelized sampling code that can be run on-demand in the cloud, leveraging the power of potentially vast and cheap cloud computing facilities and freeing up dedicated supercomputers for the problems where they are really needed.

In addition my team will develop new accurate theoretical predictions for confrontation with data, including analysis of new non-linear processes that will be a major source of confusion for dark energy and early universe studies, as well as correlations between different data sets.

I am applying for 70% of my time and two ERC postdocs to tackle these challenges.</Summary><Max_ERC_funding>1,372,496</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="Critical"><Rcn>191993</Rcn><Nid>10717</Nid><HI>The University Of Warwick, United Kingdom</HI><Name>Behaviour near criticality</Name><PI>Martin Hairer</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"One of the main challenges of modern mathematical physics is to understand the behaviour of systems at or near criticality. In a number of cases, one can argue heuristically that this behaviour should be described by a nonlinear stochastic partial differential equation. Some examples of systems of interest are models of phase coexistence near the critical temperature, one-dimensional interface growth models, and models of absorption of a diffusing particle by random impurities. Unfortunately, the equations arising in all of these contexts are mathematically ill-posed. This is to the extent that they defeat not only ""standard"" stochastic PDE techniques (as developed by Da Prato / Zabczyk / R&#195;&#182;ckner / Walsh / Krylov / etc), but also more recent approaches based on Wick renormalisation of nonlinearities (Da Prato / Debussche / etc).

Over the past year or so, I have been developing a theory of regularity structures that allows to give a rigorous mathematical interpretation to such equations, which therefore allows to build the mathematical objects conjectured to describe the abovementioned systems near criticality. The aim of the proposal is to study the convergence of a variety of concrete microscopic models to these limiting objects. The main fundamental mathematical tools to be developed in this endeavour are a discrete analogue to the theory of regularity structures, as well as a number of nonlinear invariance principles.
If successful, the project will yield unique insight in the large-scale behaviour of a number of physically relevant systems in regimes where both nonlinear effects and random fluctuations compete with equal strength."</Summary><Max_ERC_funding>1,526,234</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="DIDYMUS"><Rcn>188661</Rcn><Nid>12214</Nid><HI>Stichting Vu, Netherlands</HI><Name>MICROMACHINED OPTOMECHANICAL DEVICES: looking at cells, tissues, and organs... with a gentle touch</Name><PI>Davide Iannuzzi</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>Every time we grab an object to look at its geometrical details or to feel if it is hard or soft, we are ineluctably confronted with the limits of our senses. Behind its appearances, the object may still hide information that, encrypted in its microscopic features, remains undetected to our macroscopic assessment. In life sciences, those limits are more than just frustrating: they are an obstacle to study and detect life threatening conditions. Many different instruments may overcome those limits, but the vast majority of them rely either on &#226;&#128;&#156;sight&#226;&#128;&#157; (optics) or &#226;&#128;&#156;touch&#226;&#128;&#157; (mechanics) separately. On the contrary, I believe that it is from the combination of those two &#226;&#128;&#156;senses&#226;&#128;&#157; that we have more chances to tackle the future challenges of cell biology, tissue engineering, and medical diagnosis.

Inspired by this tantalizing perspective, and supported by a technology that I have brought from blackboard to market, I have now designed a scientific program to breach into the microscopic scale via an unbeaten path. The program develops along three projects addressing the three most relevant scales in life sciences: cells, tissues, and organs. In the first project, I will design and test a new optomechanical probe to investigate how a prolonged mechanical load on a brain cell of a living animal may trigger alterations in its Central Nervous System. With the second project, I will develop an optomechanical tactile instrument that can assess how subsurface tissues deform in response to a mechanical stroke &#226;&#128;&#147; a study that may change the way physicians look at tissue classification. For the third project, I will deliver an acousto-optical gas trace sensors so compact that can penetrate inside the lungs of an adult patient, where it could be used for early detection of pulmonary life threatening diseases. Each project represents an opportunity to open an entire new field, where optics and micromechanics are combined to extend our senses well beyond their natural limits.</Summary><Max_ERC_funding>1,999,221</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="DNAFOLDIMS"><Rcn>189830</Rcn><Nid>11817</Nid><HI>Institut National De La Sante Et De La Recherche Medicale, France</HI><Name>Advanced mass spectrometry approaches to reveal nucleic acid folding energy landscapes</Name><PI>Val&#195;&#169;rie Gabelica</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"50 years after the discovery of the DNA double helix, the variety of structures that nucleic acids can adopt continues to surprise the scientific community. Specific structures and conformational changes are linked to important functions in cell regulation. Understanding the principles that govern how small molecules such as natural metabolites or synthetic drugs modulate the nucleic acid structures is of prime importance for molecular biology and pharmacology. The field however suffers from the lack of suitable experimental tools to monitor all assemblies and structures formed when a small molecule encounters its targets.

The goal of my project is to develop unique mass spectrometry-based approaches to detect, quantify and characterize all these assemblies and structures. Our team&#226;&#128;&#153;s strength will be to integrate a multidisciplinary approach, from physical and analytical chemistry to molecular biology. We will address the fundamentals of nucleic acid ionization and transfer in the gas phase, develop a unique instrumental setup combining mass spectrometry, ion mobility and circular dichroism ion spectroscopy, and apply these new approaches to biologically important nucleic acids, in order to reveal the mechanisms of ligand-induced conformational changes in important regulatory structures such as G-quadruplex or riboswitches.

This research will also have broader impact, as the approaches and concepts developed here for nucleic acids will contribute fundamental advances in mass spectrometry, and will be transferrable to other supramolecular or biological complexes."</Summary><Max_ERC_funding>2,021,755</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="DOiCV"><Rcn>111548</Rcn><Nid>10069</Nid><HI>Institute Of Science And Technology Austria, Austria</HI><Name>Discrete Optimization in Computer Vision: Theory and Practice</Name><PI>Vladimir Kolmogorov</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>This proposal aims at developing new inference algorithms for graphical models with discrete variables, with a focus on the MAP estimation task. MAP estimation algorithms such as graph cuts have transformed computer vision in the last decade; they are now routinely used and are also utilized in commercial systems.
Topics of this project fall into 3 categories.
Theoretically-oriented: Graph cut techniques come from combinatorial optimization. They can minimize a certain class of functions, namely submodular functions with unary and pairwise terms. Larger classes of functions can be minimized in polynomial time. A complete characterization of such classes has been established. They include k-submodular functions for an integer k _ 1.
I investigate whether such tools from discrete optimization can lead to more efficient inference algorithms for practical problems. I have already found an important application of k-submodular functions for minimizing Potts energy functions that are frequently used in computer vision. The concept of submodularity also recently appeared in the context of the task of computing marginals in graphical models, here discrete optimization tools could be used.
Practically-oriented: Modern techniques such as graph cuts and tree-reweighted message passing give excellent results for some graphical models such as with the Potts energies. However, they fail for more complicated models. I aim to develop new tools for tackling such hard energies. This will include exploring tighter convex relaxations of the problem.
Applications, sequence tagging problems: Recently, we developed new algorithms for inference in pattern-based Conditional Random Fields (CRFs) on a chain. This model can naturally be applied to sequence tagging problems; it generalizes the popular CRF model by giving it more flexibility. I will investigate (i) applications to specific tasks, such as the protein secondary structure prediction, and (ii) ways to extend the model.</Summary><Max_ERC_funding>1,641,585</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="DROUGHT-HEAT"><Rcn>185664</Rcn><Nid>12023</Nid><HI>Eidgenoessische Technische Hochschule Zuerich, Switzerland</HI><Name>Land-Climate Interactions: Constraints for Droughts and Heatwaves in a Changing Climate</Name><PI>Sonia Isabelle Seneviratne</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Land-climate interactions mediated through soil moisture and vegetation play a critical role in the climate system, in particular for the occurrence of extreme events such as droughts and heatwaves. They are, however, poorly constrained in current Earth System Models (ESMs), leading to large uncertainties in climate projections. These uncertainties affect the quality and accuracy of projections of temperature, water availability, and carbon concentrations, as well as that of projected impacts on agriculture, ecosystems, and health.

In the past years, in-situ and remote sensing-based datasets of soil moisture, evapotranspiration, and energy and carbon fluxes have become increasingly available, providing untapped potential for reducing associated uncertainties in current climate models. The DROUGHT-HEAT project aims at innovatively exploiting these new information sources in order to 1) derive observations-based diagnostics to quantify and isolate the role of land-climate interactions in past extreme events (""Diagnostic Atlas""), 2) evaluate and improve current ESMs and constrain climate-change projections using the derived diagnostics, and 3) apply the newly gained knowledge to frontier developments in the attribution of climate extremes to land processes and their mitigation through ""land geoengineering"".

The DROUGHT-HEAT project integrates the newest land observational datasets with the latest stream of ESMs. Novel methodologies will be applied to extract functional relationships from the data, and identify key gaps in the ESMs' representation of underlying processes. These will build on physically-based relationships, machine learning tools, and model calibration. In addition, they will encompass the mapping and merging of derived diagnostics in space and time to reduce ""blank spaces"" in the datasets. The project is unprecedented in its breadth and scope and will allow a major breakthrough in our understanding of the processes leading to heatwaves and droughts."</Summary><Max_ERC_funding>1,952,285</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="DURACELL"><Rcn>185653</Rcn><Nid>11383</Nid><HI>Universit&#195;&#169; Paris Diderot-Paris 7, France</HI><Name>Cell Migration under Mechanical Constraints</Name><PI>Beno&#195;&#174;t Ladoux</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>Control of cell migration is crucial for many biological processes. Cells sense mechanical cues to guide their migration. As opposed to passive materials, living cells actively respond to the mechanical stimuli of their environment through the transduction of mechanical information into biochemical signaling events. These responses, particularly to rigidity, include differentiation, migration and alterations in cell-matrix and cell-cell adhesion and thus occur over a wide range of time and length scales. I propose to address the effect of substrate mechanical properties on cell migration using quantitative in vitro methods based on micro-fabrication and micro-mechanical techniques. My main objectives are to:
1/ Discover specific mechanisms that guide single cells toward stiffer substrates (a process known as durotaxis), investigate the range of stiffness-sensitive responses and determine the molecular mechanisms based on actin dynamics and cell adhesion assembly. 2/ Characterize the emergence of coordinated cell movements and thus how cells move in concert under external mechanical constraints. In addition to cell-substrate interactions, the role of cell-cell junctions is crucial in the transmission of mechanical signals over the cell population. By analyzing tissue dynamics at both mesoscopic and molecular scales, we hope to unravel how epithelial cell sheets mechanically integrate multiple adhesive cues to drive collective cell migration.3/ Elucidate the role of 3D mechanical environments in collective cell migration. In contrast to migration in 2D, cells in 3D must overcome the biophysical resistance of their surrounding milieu. Based on optical and innovative micro-fabrication techniques to modify the stiffness of 3D scaffolds, we will study its influence on cell migration modes and invasion. The goal of this interdisciplinary project is to understand how cells integrate mechanical adhesive signals to adapt their internal organization and ensure tissue integrity</Summary><Max_ERC_funding>1,762,734</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="Darksurvey"><Rcn>185539</Rcn><Nid>13171</Nid><HI>University Of Portsmouth Higher Education Corporation, United Kingdom</HI><Name>Using Galaxy Surveys to Understand the Dark Universe</Name><PI>William Percival</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>Galaxy Surveys are a key resource for observational cosmology, with the potential to provide the answers to many fundamental questions in modern physics. The Darksurvey project will use the Dark Energy Survey (DES) and extended-Baryon Oscillation Spectroscopic Survey (eBOSS) within which Will Percival has key leadership positions, and future projects including MS-DESI to measure the cosmological expansion rate between redshifts 0.5 and 2, testing Dark Energy. Complimentary structure growth measurements will test Einstein's theory of Gravity on the largest scales possible. The large-scale clustering of galaxies will be used to constrain primordial non-Gaussianity, testing and constraining models of inflation. The scale-dependence of the clustering signal will be used to measure the masses of neutrinos through their early Universe effects, and to set constraints on the evolution of galaxies and structure over cosmological time-scales. Parallel development of innovative tests and measurement methods will be undertaken to enable and enhance these results, while joint analysis with CMB and weak-lensing data will be used to perform additional tests, and to break degeneracies present when cosmological models are tested.
This grant will consolidate the world-leading position of the group initiated by Will Percival at the University of Portsmouth, and developed over the last 4 years. Furthermore, it will train and develop a group of scientists within Europe with the key experimental skills required for the ESA Euclid mission.</Summary><Max_ERC_funding>2,151,192</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="Design2Heal"><Rcn>185682</Rcn><Nid>12028</Nid><HI>Universitaetsklinikum Wuerzburg - Klinikum Der Bayerischen Julius-Maximilians-Universitat, Germany</HI><Name>Rational design of scaffold architecture and functionalization to induce healing and tissue regeneration</Name><PI>J&#195;&#188;rgen Groll</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>When materials are implanted into the body they initiate an inflammatory response that is difficult to control. Consequently medical implants are tolerated by the body rather than fully integrated; the material is often sealed off from the body in a fibrotic capsule. Most recent research suggests that morphology is a decisive immunomodulatory trigger and may favor a healing-like reaction of the innate immune system, especially of macrophages.

I have pioneered a single-step method to generate non-woven fibrous scaffolds with surface chemistry control that allows specific cell adhesion. Additionally, my laboratory recently established melt electrospinning writing (MEW) that allows automated scaffold production by solvent-free electrostatic drawing with precise morphology control through rational deposition of polymer filaments in micrometer resolution.

Design2Heal is based on this world-wide unique combination of technologies and proposes to combine form (scaffold morphology) with function (surface chemistry) to generate biomaterials that are designed to heal and improve implant integration. Pioneering and ground breaking research within Design2Heal includes:

&#226;&#128;&#162; A single-step procedure to fabricate MEW scaffolds with controlled surface functionalities for specific bioactivation.

&#226;&#128;&#162; Unraveling the immunomodulatory potential of generic scaffold parameters (diameter, morphology) and surface functionalization (peptides, sugars, glycosaminoglycans) for rationally designed scaffolds in vitro with primary human innate immune cells.

&#226;&#128;&#162; Resolve the immunomodulatory effects of cellular cross-talk and interaction between human immune cells, mesenchymal stem cells and endothelial progenitor cells in defined geometric confinements.

&#226;&#128;&#162; In vivo proof-of-principle in the murine model
In case of success, Design2Heal will be a ground breaking first step towards actively healing implants independently of the affected tissue, with tremendous impact on healthcare worldwide.</Summary><Max_ERC_funding>1,994,200</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="EARTHSEQUENCING"><Rcn>185660</Rcn><Nid>12316</Nid><HI>Universitaet Bremen, Germany</HI><Name>A new approach to sequence Earth history at high resolution over the past 66 million years</Name><PI>Heiko P&#195;&#164;like</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"One major challenge to be addressed by this proposal is to overcome fundamental obstacles to generate a first high-resolution and continuous fully integrated record of geological events, ages and durations
(a &#226;&#128;&#152;sequence of Earth history&#226;&#128;&#153;) for the past 66 million years, anchored to the present, to extract properties of Earth&#226;&#128;&#153;s and solar system orbital motion, and then to apply this time scale to solve first order questions about Earth&#226;&#128;&#153;s climate system and Earth System sensitivity. The project will bridge the long-standing &#226;&#128;&#152;Eocene tuning gap&#226;&#128;&#153;, primarily using spectacular new data recovered during Integrated Ocean Drilling Expedition 342 and integrated with a new consistent and integrated approach with existing data that currently only provide time sequences floating in time, not anchored to the present. The proposal will extract astronomical parameters (tidal dissipation, dynamical ellipticity) and verify astronomical models to provide long term amplitude modulation patterns of Earth&#226;&#128;&#153;s orbital variations (obliquity and short eccentricity) beyond 40 million years before present.  It will also search for the fingerprint of chaotic transitions in the solar system that will allow astronomical models to be tested. The improved geologic time scale will then be applied, exploited, and combined with modern Earth System Models of Intermediate Complexity to quantify Earth System sensitivity to orbital forcing during a world of elevated carbon-dioxide concentrations during the &#226;&#128;&#152;greenhouse&#226;&#128;&#153; Paleogene. Using novel new pattern matching and recognition algorithms as well as time series analysis methods, the full record of Earth history will be fully integrated and analysed with a consistent and documented workflow. This development will have the ground-breaking potential to take &#226;&#128;&#152;Earth sequencing&#226;&#128;&#153; to the next level."</Summary><Max_ERC_funding>1,998,343</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ENLIGHTENED"><Rcn>185625</Rcn><Nid>12016</Nid><HI>Commissariat A L Energie Atomique Et Aux Energies Alternatives, France</HI><Name>Nanophotonic Nanomechanical Mass Spectrometry for Biology and Health</Name><PI>S&#195;&#169;bastien Claude Hentz</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"&#194;&#171; Mass Spectrometry has become a routine analytical tool in modern biological research, and has gained in recent years a foothold in the realm of clinical diagnostic and screening. However, it is still costly, complex and because its principle relies on ionization, it is incapable of analyzing biomolecules with masses greater than a few MDa. Averaging more than 100 million particles per measurement, it is also incapable of characterizing the diversity of such heavy entities. ENLIGHTENED aims at demonstrating a breakthrough concept based on Photonic Nano-Mechanical Mass Spectrometry, able to perform analysis of bioparticles of high biomedical significance, of ultra-high mass, never so far characterized, with single-molecule sensitivity and unprecedented resolution. The long-term vision beyond the current proposal is to provide the biologists with a tool which will be transformative for fundamental knowledge, and to make possible cheap, handheld devices for personalized medicine.
ENLIGHTENED proposes to use photons to shed light on unexplored species at the individual level, which is of high biomedical significance and will expand our understanding of simple life forms.&#226;&#128;&#157;"</Summary><Max_ERC_funding>1,999,090</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="ERCC"><Rcn>188657</Rcn><Nid>10642</Nid><HI>Ruhr-Universitaet Bochum, Germany</HI><Name>Efficient Resource Constrained Cryptography</Name><PI>Eike Kiltz</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"Traditionally, cryptographic protocols were run on servers or personal computers which have large and easily scalable computational resources. For these applications there exist a large variety of well-established cryptographic systems. Right now, we are in the midst of the shift toward ubiquitous computing on resource constrained devices (RCDs): small devices with severe constraints in terms of computing power, code size, and network capacities. RCDs are used virtually everywhere: smart phones, bank cards, electronic ID-cards, medical implants, cars, RFIDs as bar code replacement, etc. Due to their computational constraints, many current cryptographic security solutions are no longer applicable to RCDs. Existing solutions are often &#226;&#128;&#156;ad-hoc&#226;&#128;&#157; and do not come with a formal security treatment.

The central objective of the ERCC project is to initiate an overarching formal treatment of cryptographic solutions for RCDs, particularly focusing on efficiency. The main conceptual novelty is to follow the concept of provable security. We intend to design new cryptographic protocols that have a mathematical proof of security (assuming the hardness of some mathematical problem) and are still competitive with constructions currently used on RCDs. While we certainly cannot hope that all our new provably secure constructions will be superior to existing ad-hoc constructions, recent preliminary research
results give rise to optimism. Concretely, we will base our new protocols on hard problems in ideal and structures lattices and we will study weaker (yet still realistic) security models for RCDs allowing for efficient instantiations."</Summary><Max_ERC_funding>1,874,960</Max_ERC_funding><Duration><Start_date> 2014-11-01, </Start_date><End_date> 2019-10-31</End_date></Duration></Project><Project acronym="ESTYMA"><Rcn>111547</Rcn><Nid>10073</Nid><HI>The University Of Warwick, United Kingdom</HI><Name>Excited state quantum dynamics in molecular aggregates: a unified description from biology to devices</Name><PI>Alessandro Troisi</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"The coherent dynamics of excitons in systems of biological interest and in organic materials can now be studied with advanced experimental techniques, including two dimensional electronic spectroscopy, with time resolution of few femtoseconds. The theory of open quantum systems, that should support the interpretation of these new experiments, has been developed in different contexts over the past 60 years but seems now very inadequate for the problems of current interest.  First of all, the systems under investigation are extremely complex and the most common approach, based on the development of phenomenological models, is often not very informative.  Many different models yield results in agreement with the experiments and there is no systematic way to derive these models or to select the best model among many.  Secondly, the quantum dynamics of excitons is so fast that one cannot assume that the dynamics of environment is much faster than the dynamics of the system, an assumption crucial for most theories.  A remedy to the current limitation is proposed here through the following research objectives.
(1) A general and automatic protocol will be developed to generate simple treatable models of the system from an accurate atomistic description of the same system based on computational chemistry methods.
(2) A professionally-written software will be developed to study the quantum dynamics of model Hamiltonians for excitons in molecular aggregates. This software will incorporate different methodologies and will be designed to be usable also by non-specialists in the theory of quantum open systems (e.g. spectroscopists, computational chemists).
(3) A broad number of problems will be studied with this methodology including (i) exciton dynamics in light harvesting complexes and artificial proteins and (ii) exciton dynamics in molecular aggregates of relevance for organic electronics devices."</Summary><Max_ERC_funding>1,512,873</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ETASECS"><Rcn>185663</Rcn><Nid>12027</Nid><HI>Technion - Israel Institute Of Technology, Israel</HI><Name>Extremely Thin Absorbers for Solar Energy Conversion and Storage</Name><PI>Avner Rothschild</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>ETASECS aims at making a breakthrough in the development of photoelectrochemical (PEC) cells for solar-powered water splitting that can be readily integrated with PV cells to provide storage capacity in the form of hydrogen. It builds upon our recent invention for resonant light trapping in ultrathin films of iron oxide (a-Fe2O3), which enables overcoming the deleterious trade-off between light absorption and charge carrier collection efficiency. Although we recently broke the water photo-oxidation record by any a-Fe2O3 photoanode reported to date, the losses are still high and there is plenty of room for further improvements that will lead to a remakable enhancement in the performance of our photoanodes, reaching quantum efficiency level similar to state-of-the-art PV cells. ETASECS aims at reaching this ambitious goal, which is essential for demonstrating the competitiveness of PEC+PV tandem systems for solar energy conversion and storage. Towards this end WP1 will combine theory, modelling and simulations, state-of-the-art experimental methods and advanced diagnostic techniques in order to identify and quantify the different losses in our devices. This work will guide the optimization work in WP2 that will suppress the losses at the photoanode and insure optimal electrical and optical coupling of the PEC and PV cells. We will also explore advanced photon management schemes that will go beyond our current light trapping scheme by combining synergic optical and nanophotonics effects. WP3 will integrate the PEC and PV cells and test their properties and performance. WP4 will disseminate our progress and achievements in professional and public forums. The innovations that will emerge from this frontier research will be further pursued in proof of concept follow up investigations that will demonstrate the feasibility of this technology. Success along these lines holds exciting promises for ground breaking progress towards large scale deployment of solar energy.</Summary><Max_ERC_funding>2,150,000</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="EXONMR"><Rcn>185545</Rcn><Nid>12353</Nid><HI>The University Court Of The University Of St Andrews, United Kingdom</HI><Name>"Exploiting 17O NMR Spectroscopy: Atomic-Scale Structure, Disorder and Dynamics in Solids"</Name><PI>Sharon Elizabeth Marie Ashbrook</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"The fundamental importance of oxide-based systems in technology, energy materials, geochemistry and catalysis, and the presence of oxygen in many biomaterials, should have resulted in oxygen nuclear magnetic resonance (NMR) spectroscopy emerging as a vital tool for materials characterization. NMR offers an element-specific, atomic-scale probe of the local environment, providing a potentially powerful probe of local structure, disorder and dynamics in solids. However, despite the almost ubiquitous presence of oxygen in inorganic solids, oxygen NMR studies have been relatively scarce in comparison to other nuclei, owing primarily to the low natural abundance of the  NMR-active isotope, 17O (0.037%). Hence, isotopic enrichment is necessary, often at considerable cost and effort. Furthermore, the presence of anisotropic quadrupolar broadening (and the need for complex high-resolution experiments) has also limited the development and application of 17O NMR to date. Here, we propose to develop an internationally-leading research programme to exploit the largely untapped potential of 17O spectroscopy. This wide-ranging programme will involve (i) the exploration of novel synthetic approaches for cost-efficient isotopic enrichment, (ii) the development of new solid-state NMR methodology, specific for 17O, (iii) the application of state-of-the-art first-principles calculations of 17O NMR parameters and (iv) the application of these methods to three different areas of investigation: high-pressure silicate minerals, microporous materials and ceramics for waste encapsulation. The ultimate long-term aim is to change the way in which solid-state chemists characterise materials; so that solid-state NMR (and 17O NMR in particular) is viewed as a necessary and important step in the refinement of a detailed structural model."</Summary><Max_ERC_funding>1,902,188</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="EXQUISITE"><Rcn>185601</Rcn><Nid>10746</Nid><HI>Technische Universitaet Berlin, Germany</HI><Name>External Quantum Control of Photonic Semiconductor Nanostructures</Name><PI>Stephan Erich Reitzenstein</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>In this project, we will control photonic nanostructures by external feedback, optical injection and synchronization. This will allow us to study nonlinear dynamics in quantum systems and to externally manipulate and stabilize light-matter interaction in the regime of quantum electrodynamics (cQED). We will experimentally and theoretically address a) optical injection and feedback control of quantum dot (QD)&#226;&#128;&#147;microlasers, b) quantum control cQED systems via delayed single photon feedback, and c) mutually coupled and synchronized chaotic microcavity systems. In a) we will advance the concepts of time-delayed coupling in standard semiconductor laser diodes to few photon states, where quantum fluctuations contribute to or even dominate over the usual classical dynamics. Feedback-coupling in microlasers will allow us to explore the limits of a classical description of chaotic laser dynamics via the Lang-Kobayashi rate equations and to develop an advanced model taking cQED- and QD-specific effects into account. This subject will be complemented by the study of optical injection of coherent light and non-classical light into microlasers to influence and study mode-locking, chaos and stimulated emission down to the quantum level. Single photon feedback in b) will be applied to stabilize coherent coupling of light and matter and to act against decoherence which constitutes a major bottleneck for application of semiconductor nanostructures in quantum information technology. In c) the mutual coupling of microlasers will be used to study synchronization of chaotic quantum devices at the single photon limit and to explore the underlying physics of isochronal synchronization. Our work will have important impact at an interdisciplinary level on the development of nonlinear dynamical systems towards the quantum limit and the understanding of fundamental light-matter interaction in the presence of time delayed single photon feedback.</Summary><Max_ERC_funding>1,999,800</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="EXTREME"><Rcn>111546</Rcn><Nid>10070</Nid><HI>Eberhard Karls Universitaet Tuebingen, Germany</HI><Name>EXtreme Tectonics and Rapid Erosion in Mountain Environments</Name><PI>Todd Alan Ehlers</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Tectonic plate corners are hotspots for high rates of continental deformation and erosion, and associated with human-relevant hazards including poorly understood earthquakes, destructive landslides, and extreme climate. A better understanding of continental deformation can mitigate these hazards. However, the coupling between climate and tectonic interactions at plate corners is a key unknown and the focus of this study. My recent work, published in international journals including Science and Nature, quantifies mountain building and climate change and provides a baseline for an innovative study of plate corner dynamics.
This proposal challenges the geoscience &#226;&#128;&#152;tectonic aneurysm&#226;&#128;&#153; paradigm that rapid deformation and erosion at plate corners is initiated from the &#226;&#128;&#156;top down&#226;&#128;&#157; by localized precipitation, and erosion. Rather, I hypothesize that these processes are: 1) initiated from the &#226;&#128;&#156;bottom up&#226;&#128;&#157; by the 3D geometry of the subducting plate; and 2) require a threshold rate of both &#226;&#128;&#156;bottom up&#226;&#128;&#157; deformation and surface erosion to initiate a feedback between climate and tectonics.
I propose, for the first time, a holistic modeling and data collection approach that quantifies the temporal and spatial evolution of all aspects of plate corner evolution, including: 3D thermomechanical modeling of plate corner deformation and uplift for different plate geometries; Atmospheric modeling to quantify the climate response to evolving topography, a topic spearheaded by my research group; And surface process modeling to close the loop and couple the atmospheric and mechanical models. Model predictions will be vetted against observed deformation and erosion histories from existing and new cosmogenic isotope and thermochronometer data from end-member locations including the Himalaya, Alaskan, Olympic, and Andean plate corners. EXTREME will produce a globally integrated atmospheric and solid Earth understanding of continental deformation, a task only possible at the scale of an ERC grant."</Summary><Max_ERC_funding>1,999,956</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ExoLights"><Rcn>185651</Rcn><Nid>12319</Nid><HI>University College London, United Kingdom</HI><Name>Decoding Lights from Exotic Worlds</Name><PI>Giovanna Tinetti</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>It is now accepted that exoplanets are ubiquitous. However little is known about those planets we have detected beyond the fact they exist and their location. For a minority, we know their weight, size and orbital parameters. For less than twenty, we have some clues about their atmospheric temperature and composition. How do we progress from here?
We are still far from a hypothetical Hertzsprung&#226;&#128;&#147;Russell diagram for planets and we do not even know whether there ever will be such classification for planets. The planetary parameters mass, radius and temperature alone do not explain the diversity revealed by current observations. The chemical composition of these planets is needed to trace back their formation history and evolution, as was the case for the Solar System.
Pioneering results were obtained through transit spectroscopy with Hubble, Spitzer and ground-based facilities, enabling the detection of ionic, atomic and molecular species and of the planet&#226;&#128;&#153;s thermal structure. With the arrival of improved or dedicated instruments in the coming decade, planetary science will expand beyond the narrow boundaries of our Solar System to encompass our whole Galaxy.
In the next five years, ExoLights will address the following fundamental questions:
&#226;&#128;&#147; Why are exoplanets as they are?
&#226;&#128;&#147; What are the causes for the observed diversity?
&#226;&#128;&#147; Can their formation history be traced back from their current composition and evolution?
New spectroscopic observations of a select sample of exoplanets&#226;&#128;&#153; atmospheres (~ 20 out of the 150 observable today) will be analysed with state-of-the art statistical techniques and interpreted through a comprehensive set of spectral retrieval models, developed by the PI and her team. This programme, together with the homogeneous re-analysis of archive observations of a larger sample of exoplanets, will allow us to use the chemical composition as a powerful diagnostic of the history, formation mechanisms and evolution of gaseous and rocky exoplanets.</Summary><Max_ERC_funding>2,080,502</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="FOREFRONT"><Rcn>188672</Rcn><Nid>12221</Nid><HI>Universite Libre De Bruxelles, Belgium</HI><Name>Frontiers of Extended Formulations</Name><PI>Samuel Fiorini</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"Linear programming has proved to be an invaluable tool both in theory and practice. Semidefinite programming  surpasses linear programming in terms of expressivity while remaining tractable. This project proposal investigates the modeling power of linear and semidefinite programming, in the context of combinatorial optimization. Within the emerging framework of extended formulations (EFs), I seek a decisive answer to the following question: Which problems can be modeled by a linear or semidefinite program, when the number of constraints and variables are limited? EFs are based on the idea that one should choose the ""right"" variables to model a problem. By extending the set of variables of a problem by a few carefully chosen variables, the number of constraints can in some cases dramatically decrease, making the problem easier to solve. Despite previous high-quality research, the theory of EFs is still on square one. This project proposal aims at (i) transforming our current zero-dimensional state of knowledge to a truly three-dimensional state of knowledge by pushing the boundaries of EFs in three directions (models, types and problems); (ii) using EFs as a lens on complexity by proving strong consequences of important conjectures such as P != NP, and leveraging strong connections to geometry to make progress on the log-rank conjecture. The proposed  methodology is: (i) experiment-aided; (ii) interdisciplinary; (iii) constructive."</Summary><Max_ERC_funding>1,455,479</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="FORSIED"><Rcn>185593</Rcn><Nid>11378</Nid><HI>Universiteit Gent, Belgium</HI><Name>Formalizing Subjective Interestingness in Exploratory Data Mining</Name><PI>Tijl De Bie</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"The rate at which research labs, enterprises and governments accumulate data is high and fast increasing. Often, these data are collected for no specific purpose, or they turn out to be useful for unanticipated purposes: Companies constantly look for new ways to monetize their customer databases; Governments mine various databases to detect tax fraud; Security agencies mine and cross-associate numerous heterogeneous information streams from publicly accessible and classified databases to understand and detect security threats. The objective in such Exploratory Data Mining (EDM) tasks is typically ill-defined, i.e. it is unclear how to formalize how interesting a pattern extracted from the data is. As a result, EDM is often a slow process of trial and error.

During this fellowship we aim to develop the mathematical principles of what makes a pattern interesting in a very subjective sense. Crucial in this endeavour will be research into automatic mechanisms to model and duly consider the prior beliefs and expectations of the user for whom the EDM patterns are intended, thus relieving the users of the complex task to attempt to formalize themselves what makes a pattern interesting to them.

This project will represent a radical change in how EDM research is done. Currently, researchers typically imagine a specific purpose for the patterns, try to formalize interestingness of such patterns given that purpose, and design an algorithm to mine them. However, given the variety of users, this strategy has led to a multitude of algorithms. As a result, users need to be data mining experts to understand which algorithm applies to their situation. To resolve this, we will develop a theoretically solid framework for the design of EDM systems that model the user's beliefs and expectations as much as the data itself, so as to maximize the amount of useful information transmitted to the user. This will ultimately bring the power of EDM within reach of the non-expert."</Summary><Max_ERC_funding>1,549,315</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="GALACTICNUCLEUS"><Rcn>191264</Rcn><Nid>11235</Nid><HI>Agencia Estatal Consejo Superior Deinvestigaciones Cientificas, Spain</HI><Name>The Fingerprint of a Galactic Nucleus: A Multi-Wavelength, High-Angular Resolution, Near-Infrared Study of the Centre of the Milky Way</Name><PI>Rainer Sch&#195;&#182;del</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>Galactic stellar nuclei are very common in all types of galaxies and are marked by the presence of nuclear star clusters, the densest and most massive star clusters in the present-day Universe. Their formation is still an unresolved puzzle. The centre of the Milky Way contains a massive black hole and a stellar nucleus and is orders of magnitude closer than any comparable target. It is the only galactic nucleus and the most extreme astrophysical environment that we can examine on scales of milli-parsecs. It is therefore a crucial laboratory for studying galactic nuclei and their role in the context of galaxy evolution. Yet, suitable data that would allow us to examine the stellar component of the Galactic Centre exist for less than 1% of its projected area. Moreover, the well-explored regions are extraordinary, like the central parsec around the massive black hole, and therefore probably not representative for the overall environment. Fundamental questions on the stellar population, structure and assembly history of the Galactic Centre remain therefore unanswered. This project aims at addressing the open questions by obtaining accurate, high-angular resolution, multi-wavelength near-infrared photometry for an area of several 100 pc^2, a more than ten-fold increase compared to the current state of affairs. The Galactic Centre presents unique observational challenges because of a combination of high extinction and extreme stellar crowding. It is therefore not adequately covered by existing or upcoming imaging surveys. I present a project that is specifically tailored to overcome these observational challenges. In particular, I have developed a key technique to obtain the necessary sensitive, high-angular resolution images with a stable point spread function over large, crowded fields. It works with a range of existing ground-based instruments and will serve to complement existing data to provide a global and detailed picture of the stellar nucleus of the Milky Way.</Summary><Max_ERC_funding>1,547,657</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="GCGXC"><Rcn>188653</Rcn><Nid>12231</Nid><HI>The University Court Of The University Of St Andrews, United Kingdom</HI><Name>GenoChemetics: Gene eXpression enabling selective Chemical functionalisation of natural products</Name><PI>Rebecca Jane Miriam Goss</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>"We aim to consolidate a trans-disciplinary research programme in which synthetic biology is harnessed to enable synthetic chemistry. We will utilise this approach to expeditiously access series of previously intractable natural product analogues.

There is an urgent need for the discovery and development of new drugs and in particular new antibiotics. More than 13 million lives worldwide are currently claimed each year due to infectious diseases. Natural products provide an unparalleled starting point for drug discovery, with over 60% of anticancer agents and over 70% of antibiotics entering clinical trials in the last three decades being based on such compounds.  In order to gain a full understanding as to how a drug works and in order to be able to generate compounds with improved biological activity and physicochemical properties the generation of analogues is essential. In recent years pharmaceutical industries have shied away from natural products due to the perceived synthetic intractability of libraries of natural product analogues and the misperception that it is not possible to carry out thorough structure activity relationship (SAR) assessment on such compounds. As a result of largely abandoning natural products, industries&#226;&#128;&#153; drug discovery pipelines are beginning to run dry; this is a particular concern when faced with the need to combat the ever-increasing problem of drug resistance and infectious disease.

We aim to challenge the misperception that natural products are not &#226;&#128;&#156;med chemable&#226;&#128;&#157; We are developing a new approach to natural product analogue synthesis. By introducing a gene from a foreign organism to complement existing natural product biosynthetic machinery we are able to introduce a chemically orthogonal, reactive and selectably chemically functionalisable handle into the natural product (the antithesis of a protecting group) - this reactive handle will enable us to carry out chemical modifications only at the site at which it is located."</Summary><Max_ERC_funding>1,981,272</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="GEOMETRICSTRUCTURES"><Rcn>111377</Rcn><Nid>11835</Nid><HI>Ruprecht-Karls-Universit&#195;&#164;t Heidelberg, Germany</HI><Name>Deformation Spaces of Geometric Structures</Name><PI>Anna Wienhard</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"Moduli spaces of flat bundles and representation varieties play a prominent role in various areas of mathematics. Historically such spaces first arose in the study of systems of analytic differential equations. Closely related, and in fact locally homeomorphic, are deformation spaces of locally homogeneous geometric structures. Such deformation spaces often arise as solutions to basic geometric problems, and their global properties provide powerful topological invariants, in particular for three- and four-dimensional manifolds.
Due to the ubiquity of these spaces, methods and viewpoints from various areas of mathematics such as dynamical systems, algebraic geometry, gauge theory, representation theory, partial differential equations, number theory and complex analysis can be combined, and their interplay gives rise to the richness of this subject. In recent year there has also been an increasing interaction with theoretical physics, which has been fruitful for both sides.
In recent years the deformation theory of geometric structures has received revived attention due to new developments, which involve in a deeper way the connections to Lie theory and gauge theory. Unexpectedly, many new examples of deformation spaces of geometric structures appeared. Two such developments are Higher Teichmueller theory and Anosov representations of hyperbolic groups, which generalize classical Teichmueller theory and the theory of quasi-Fuchsian representations to the context of Lie groups of higher rank.
The goal of the proposal is to understand the fine structure and internal geometry of deformation spaces of geometric structures, and to further develop the structure theory of discrete subgroups in higher rank Lie groups. Of particular interest are deformation spaces with appear in the connection with higher Teichmueller theory, because they are expected to be of similar mathematical significance as classical Teichmueller space."</Summary><Max_ERC_funding>1,570,327</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="GETEMO"><Rcn>189839</Rcn><Nid>11813</Nid><HI>Westfaelische Wilhelms-Universitaet Muenster, Germany</HI><Name>Geometry, Groups and Model Theory</Name><PI>Emmanuel, Fran&#195;&#167;ois, Jean Breuillard</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>Our proposed research lies at the interface of Geometry, Group Theory, Number Theory and Combinatorics. In recent years, striking results were obtained in those disciplines with the help of a surprise newcomer at the border between mathematics and logic: Model Theory. Bringing its unique point of view and its powerful formalism, Model Theory made a resounding entry into several different fields of mathematics. Here shedding new light on a classical phenomenon, there solving a long-standing open problem via a completely new method.

Recent examples of concrete mathematical problems where Model Theory interacted in a fruitful manner abound: the local version of Hilbert's 5th problem by Goldbring and van den Dries, Szemeredi's theorems in combinatorics and graph theory, the Andr&#195;&#169;-Oort conjecture in diophantine geometry (Pila, Wilkie, Zannier), etc. In this vein, and building on Hrushovski's model-theoretic work, Green, Tao and myself recently settled a conjecture of Lindenstrauss pertaining to the structure of approximate groups.

Our plan in this project is to put these methods into further use, to collaborate with model theorists, and to start looking through this prism at a small collection of familiar problems coming from combinatorics, group theory, analysis and spectral geometry of metric spaces, or from arithmetic geometry. Among them: extend our study of approximate groups to the general setting of locally compact groups, obtain uniform estimates on the spectrum of Cayley graphs of large finite groups, prove an analogue for character varieties of the Pink-Zilber conjectures in relation with rigidity theory for discrete subgroups of Lie groups, and clarify the links between uniform spectral gaps and height lower bounds in diophantine geometry with a view towards Lehmer's conjecture.</Summary><Max_ERC_funding>1,284,000</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="GLYCOSURF"><Rcn>185563</Rcn><Nid>12343</Nid><HI>The University Of Birmingham, United Kingdom</HI><Name>Surface-Based Molecular Imprinting for Glycoprotein Recognition</Name><PI>Paula Maria Da Silva Mendes</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"There is now overwhelming evidence that glycosylation changes during the development and progression of various malignancies. Altered glycosylation has been implicated in cancer, immune deficiencies, neurodegenerative diseases, hereditary disorders and cardiovascular diseases. Currently, antibodies are playing a central role in enabling the detection of glycoprotein biomarkers using a variety of immunodiagnostic tests. Nonetheless, antibodies do have their own set of drawbacks that limit the commercialization of antibody sensing technology. They suffer from poor stability, need special handling and require a complicated, costly production procedure. More importantly, they lack specificity because they bind only to a small site on the biomarker and are not able to discriminate, for instance, among different glycosylated proteins. The current antibody diagnostic technology has well recognized limitations regarding their accuracy and timeliness of diagnose of disease. This project will focus on research into the means of developing a generic, robust, reliable and cost-effective alternative to monoclonal antibody technology. The project aims to exploit concepts and tools from nanochemistry, supramolecular chemistry and molecular imprinting to provide highly innovative synthetic recognition platforms with high sensitivity and specificity for glycoproteins. Such novel type of platforms will make a profound and significant impact in the broad fields of biosensors and protein separation devices with applications in many areas such as biomedical diagnostics, pharmaceutical industry, defense and environmental monitoring. The proposed technology may open an untraveled path in the successful diagnosis, prognosis and monitoring of therapeutic treatment for major diseases such as cancer, immune deficiencies, neurodegenerative diseases, hereditary disorders and cardiovascular diseases."</Summary><Max_ERC_funding>1,894,046</Max_ERC_funding><Duration><Start_date> 2014-12-01, </Start_date><End_date> 2019-11-30</End_date></Duration></Project><Project acronym="GaugeGravSym"><Rcn>185580</Rcn><Nid>12011</Nid><HI>Eidgenoessische Technische Hochschule Zuerich, Switzerland</HI><Name>Extended Symmetries in Gauge and Gravity Theories</Name><PI>Niklas Frederik Beisert</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>In the recent couple of years, we have achieved an incredibly deep understanding of N=4 maximally supersymmetric gauge theory and the AdS/CFT correspondence which relates this model to string theory. The main reason for this progress consists in the apparent exact integrability of the models in the planar limit. Integrability is a hidden symmetry which allows to establish very efficient tools for performing calculations. Remarkably, these tools not only conveniently compute observables at very high orders in the coupling constant, both at weak and at strong coupling, but they also make quantitative predictions at finite coupling strength. A similar amount of progress is due to the development of novel on-shell techniques which allow to construct scattering amplitudes at several loop orders. They become especially powerful when combined with the extended symmetries related to integrability.

The aim of the project is to put the recent rapid progress in integrability and scattering amplitudes on a solid foundation. By enhancing the encountered symmetries and applications towards more realistic gauge and gravity theories we hope to obtain new tools for QFT in general as well as new clues for the problem of quantum gravity.

More concretely, we will work out a precise formulation for the algebra underlying integrability. This is a crucial step towards proving integrability in AdS/CFT and to justify and develop efficient methods. Furthermore, we plan to develop applications of integrability away from the planar limit and for non-integrable gauge theories. Finally, we will extend these methods and considerations to gravity models. We will also take a fresh look at alternative models with a view to solving the puzzle of quantum gravity.

We plan to address these important objectives with the common framework of extended symmetries and powerful calculational techniques for scattering amplitudes.</Summary><Max_ERC_funding>1,660,804</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="HAPDEGMT"><Rcn>111545</Rcn><Nid>10072</Nid><HI>Agencia Estatal Consejo Superior Deinvestigaciones Cientificas, Spain</HI><Name>Harmonic Analysis, Partial Differential Equations and Geometric Measure Theory</Name><PI>Jose Maria Martell Berrocal</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>The origin of Harmonic Analysis goes back to the study of the heat diffusion, modeled by a differential equation, and the claim made by Fourier that every periodic function can be represented as a series of sines and cosines. In this statement we can find the motivation to many of the advances that have been made in this field. Partial Differential Equations model many phenomena from the natural, economic and social sciences. Existence, uniqueness, convergence to the boundary data, regularity of solutions, a priori estimates, etc.,  can be studied for a given PDE.  Often, Harmonic Analysis plays an important role in such problems and, when the scenarios are not very friendly, Harmonic Analysis turns out to be fundamental. Not very friendly scenarios are those where one lacks of smoothness either in the coefficients of the PDE and/or in the domains where the PDE is solved. Some of these problems lead to obtain the boundedness of certain singular integral operators and this drives one to the classical and modern Calder&#195;&#179;n-Zygmund theory, the paradigm of Harmonic Analysis. When studying the behavior of the solutions of the given PDE near the boundary, one needs to understand the geometrical features of the domains and then Geometric Measure Theory jumps into the picture.

This ambitious project lies between the interface of three areas: Harmonic Analysis, PDE and Geometric Measure theory. It seeks  deep results motivated by elliptic  PDE using techniques from Harmonic Analysis and Geometric Measure Theory.This project is built upon results obtained by the applicant in these three areas. Some of them are very recent and have gone significantly beyond the state of the art. The methods to be used have been shown to be very robust and therefore they might be useful towards its applicability in other regimes. Crucial to this project is the use of Harmonic Analysis where the applicant has already obtained important contributions.</Summary><Max_ERC_funding>1,429,790</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="HEART"><Rcn>189824</Rcn><Nid>11821</Nid><HI>Christian-Albrechts-Universitaet  Zu Kiel, Germany</HI><Name>"The Highly Efficient And Reliable smart Transformer (HEART), a new Heart for the Electric Distribution System"</Name><PI>Marco Liserre</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"In the last 10 years, power electronics has moved significantly towards the electric grid, making it more flexible and decentralized. Still important challenges remain. One of the most thrilling is re-inventing the distribution transformer after more than 125 years since its first use in the electrification of a city. In fact, actual distribution transformers can no longer fulfill the requirements of a modern electric grid highly dominated by distributed sources and new sizable loads, like heat pumps and electric vehicles.
This project proposes the invention of a novel &#226;&#128;&#156;Smart Transformer&#226;&#128;&#157; (ST), based on a modular architecture of units made by power electronics converters, that will be able to manage the energy and the information flows among sources and loads in the distribution area with the goal of decoupling it from the rest of the bulk power system. Actual proposals of Smart Transformers cannot compete in terms of cost, efficiency and reliability with traditional transformers.
This project has decided to take this challenge with a paradigm shift in how to approach it and a new set of methodologies. The breakthrough results of this research will be obtained taking the following high-risk high-gain bet: significantly influence the efficiency and the reliability of the Smart Transformer by routing the energy flows among its power converter units. A new understanding of how the energy flows are managed by the modular connection of power converter units will guide the design of new architectures for the ST allowing different routes for the energy. Graph theory will be used to find optimal paths for the energy flows with the goal of maximizing efficiency and reliability. The energy flows will be managed by relying on information coming from the electric distribution system sensors (requirements) and from the power module sensors (constraints).
The holy grail of this research is to provide a new durable heart to the electric distribution system."</Summary><Max_ERC_funding>1,996,720</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="HELENA"><Rcn>191297</Rcn><Nid>10578</Nid><HI>Technische Universiteit Delft, Netherlands</HI><Name>Heavy-Element Nanowires</Name><PI>Erik Petrus Antonius Maria Bakkers</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>"Nanowires are a powerful and versatile platform for a broad range of applications. Among all semiconductors, the heavy-elements materials exhibit the highest electron mobilities, strongest spin-orbit coupling and best thermoelectric properties. Nonetheless, heavy-element nanowires have been unexplored. With this proposal we unite the unique advantages of design freedom of nanowires with the special properties of heavy-element semiconductors. We specifically reveal the potential of heavy-element nanowires in the areas of thermoelectrics, and topological insulators. Using our strong track record in this area, we will pioneer the synthesis of this new class of materials and study their intrinsic materials properties. Starting point are nanowires of InSb and PbTe grown using the vapor-liquid-solid mechanism. Our aims are 1) to obtain highest-possible electron mobilities for these bottom-up fabricated materials by investigating new materials combinations of different semiconductor classes to effectively passivate the nanowire surface and we will eliminate impurities; 2) to investigate and optimize thermoelectric properties by developing advanced superlattice and core/shell nanowire structures where electronic and phononic transport is decoupled; and 3) to fabricate high-quality planar nanowire networks, which enable four-point electronic transport measurements and allow precisely determining carrier concentration and mobility. Besides the fundamentally interesting materials science, the heavy-element nanowires will have major impact on the fields of renewable energy, new (quasi) particles and quantum information processing. Recently, the first signatures of Majorana fermions have been observed in our InSb nanowires. With the proposed nanowire networks the special properties of this recently discovered particle can be tested for the first time."</Summary><Max_ERC_funding>2,698,447</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="HICCUP"><Rcn>185554</Rcn><Nid>11371</Nid><HI>European Organization For Nuclear Research, Switzerland</HI><Name>High Impact Cross-section Calculations for Unprecedented Precision</Name><PI>Giulia Zanderighi</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"The first runs of the Large Hadron Collider (LHC) experiment just finished. The LHC was successful in discovering a particle compatible with the Higgs boson of the Standard Model (SM). However expectations to discover New Physics have not been met so far.

In order to establish whether the new resonance is the SM Higgs boson, or not, precise measurements of its properties are mandatory. These require accurate predictions for cross-sections involving the Higgs boson, as well as for SM backgrounds, that need to be subtracted accurately. Furthermore, since so far New Physics has been elusive, it will be even more important to extend the range of these searches as much as possible. This requires a solid control of SM backgrounds.

This project aims at pushing the frontier of precision QCD calculations to reach an unprecedented precision for collider
processes. The project is divided into two main parts.

In the first part the PI will formulate a general procedure to merge different calculations at next-to-leading order (NLO) level. This will lead to the construction of an event generator for two-to-one and two-to-two scattering processes at next-to-next-to-leading order (NNLO), including parton shower corrections, essentially upgrading the POWHEG NLO generator to the NNLO level. Depending on the process considered, a significant reduction of the theoretical errors, by a factor 2-4, will be achieved.

The second part focuses on extending the accuracy of resummed predictions for important QCD observables from next-to-leading logarithmic to next-to-next-to-leading logarithmic level, again achieving a substantial reduction of the theoretical error. The observables considered include, besides event-shapes and jet-rates, also jet-veto predictions in Higgs + 1 or 2 jet events.

Besides the groundbreaking impact on present LHC physics measurements, these results will also be essential to match the high accuracy of measurements at a future linear collider."</Summary><Max_ERC_funding>1,514,798</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="HIGEOM"><Rcn>185633</Rcn><Nid>12325</Nid><HI>Universita Degli Studi Di Pavia, Italy</HI><Name>Highly accurate Isogeometric Method</Name><PI>Giancarlo Sangalli</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"Partial Differential Equations (PDEs) are widely used  in science and engineering simulations, often in tight connection with  Computer Aided Design (CAD). The Finite Element Method (FEM) is one of  the most popular technique for the discretization of PDEs. The IsoGeometric Method (IGM), proposed in 2005 by T.J.R. Hughes et al.,  aims at improving the interoperability between CAD and FEMs. This is achieved by adopting the CAD mathematical primitives, i.e. Splines and Non-Uniform Rational B-Splines (NURBS), both for geometry  and unknown fields representation. The IGM has gained an incredible momentum especially in the engineering community. The use of high-degree, highly smooth NURBS is extremely successful and the IGM outperforms the FEM in most academic benchmarks.

However, we are far from having a satisfactory mathematical understanding of the IGM and, even more importantly, from exploiting its full potential. Until now, the IGM theory and practice have been deeply influenced by finite element analysis. For example, the IGM is implemented resorting to a FEM code design,  which is  very inefficient for high-degree and high-smoothness NURBS. This has made possible a fast spreading of the IGM, but also limited it to quadratic or cubic NURBS  in complex simulations.

The use of higher degree IGM for real-world applications asks for new tools allowing for the efficient construction and solution of the linear system, time integration, flexible local mesh refinement,  and so on. These questions need to be approached beyond the FEM framework. This is possible  only on solid mathematical grounds,  on a new theory of splines and NURBS able to comply with the needs of the IGM.

This project will provide the crucial knowledge and will re-design  the IGM to make it a superior, highly accurate and stable methodology, having a significant impact in the field of numerical simulation of PDEs, particularly when accuracy is essential both in geometry and fields representation."</Summary><Max_ERC_funding>928,188</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="HIPS"><Rcn>188662</Rcn><Nid>10640</Nid><HI>Bar Ilan University, Israel</HI><Name>High-Performance Secure Computation with Applications to Privacy and Cloud Security</Name><PI>Yehuda Lindell</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"Secure two-party and multiparty computation has long stood at the center of the foundations of theoretical cryptography. However, in the last five years there has been blistering progress on the question of efficient secure computation. We are close to the stage that secure computation can be applied to real-world privacy and security problems. There is thus considerable interest in secure computation solutions from governments, military and security organisations, and industry. However, in order to answer the needs of secure computation in practice, there is still a need to make secure computation protocols much faster.

Until now, research in efficient cryptographic protocols has typically been in two different directions. The first direction, and the major one, is to construct more efficient protocols and prove them secure, where efficiency is measured by the amount of communication sent, the number of heavy cryptographic operations carried out (e.g., exponentiations), and so on. The second direction is to take the state-of-the-art protocols and implement them while optimising the implementation based on systems concerns. This latter direction has proven to improve the efficiency of existing protocols significantly, but is limited since it remains within the constraints of existing cryptographic approaches.

We propose a synergetic approach towards achieving high-performance secure computation. We will design new protocols while combining research from cryptography, algorithms and systems. In this way, issues like load balancing, memory management, cache-awareness, bandwidth bottlenecks, utilisation of parallel computing resources, and more, will be built into the cryptographic protocol and not considered merely as an afterthought. If successful, HIPS will enable the application of the beautiful theory of secure computation to the problems of privacy in the digital era, cloud security and more."</Summary><Max_ERC_funding>1,999,175</Max_ERC_funding><Duration><Start_date> 2014-10-01, </Start_date><End_date> 2019-09-30</End_date></Duration></Project><Project acronym="HeteroIce"><Rcn>185619</Rcn><Nid>10730</Nid><HI>University College London, United Kingdom</HI><Name>Towards a molecular-level understanding of heterogeneous ice nucleation</Name><PI>Angelos Michaelides</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>Ice formation is one of the most common phase transitions on Earth. It is relevant to an enormous variety of phenomena such as weathering, cloud formation, airline safety, agriculture, and energy. However, despite having been studied since antiquity, our molecular level understanding of ice formation is largely incomplete. In particular, almost all ice formation in nature is aided by impurities or the surfaces of foreign materials, yet how surfaces act to facilitate ice formation (heterogeneous ice nucleation) is unclear. Given the ubiquity of ice nucleation, this is arguably one of the biggest unsolved problems in the physical sciences.

Experiment provides insight into crystal nucleation and growth, but most nucleation events happen too quickly and involve too few particles to be rationalised purely by experiment. As a result, computer simulations play an important role and I believe we are now on the verge of using simulation to bring about major breakthroughs in understanding ice formation. Specifically, in this project we aim to perform the first full-on attack on heterogeneous ice nucleation so as to elucidate how the physiochemical properties of materials control their ability to nucleate ice. We will focus on nucleation on solid inorganic substrates and our approach will be to couple systematic studies on model systems with in-depth explorations of more realistic (and experimentally realisable) surfaces. We will improve existing computer simulation methods and develop new ones for accurate large- scale simulations of phase transitions in complex heterogeneous environments. In so doing we will help to make simulations of ice nucleation more routine, enabling us to establish what makes a good ice nucleating agent. The results from this multi-disciplinary project will not only shed light on an important everyday process but may also help to improve climate models and develop improved cloud seeding materials, or inhibitor coatings for industrial purposes.</Summary><Max_ERC_funding>1,915,083</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="HoloQosmos"><Rcn>191232</Rcn><Nid>11904</Nid><HI>Katholieke Universiteit Leuven, Belgium</HI><Name>Holographic Quantum Cosmology</Name><PI>Thomas Hertog</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>The current theory of cosmic inflation is largely based on classical physics. This undermines its predictivity in a world that is fundamentally quantum mechanical. With this project we will develop a novel approach towards a quantum theory of inflation. We will do this by introducing holographic techniques in cosmology. The notion of holography is the most profound conceptual breakthrough that has emerged form fundamental high-energy physics in recent years. It postulates that (quantum) gravitational systems such as the universe as a whole have a precise `holographic&#226;&#128;&#153; description in terms of quantum field theories defined on their boundary. Our aim is to develop a holographic framework for quantum cosmology. We will then apply this to three areas of theoretical cosmology where a quantum approach is of critical importance. First, we will put forward a holographic description of inflation that clarifies its microphysical origin and is rigorously predictive. Using this we will derive the distinct observational signatures of novel, truly holographic models of the early universe where inflation has no description in terms of classical cosmic evolution. Second, we will apply holographic cosmology to improve our understanding of eternal inflation. This is a phase deep into inflation where quantum effects dominate the evolution and affect the universe&#226;&#128;&#153;s global structure. Finally we will work towards generalizing our holographic models of the primordial universe to include the radiation, matter and vacuum eras. The resulting unification of cosmic history in terms of a single holographic boundary theory may lead to intriguing predictions of correlations between early and late time observables, tying together the universe&#226;&#128;&#153;s origin with its ultimate fate. Our project has the potential to revolutionize our perspective on cosmology and to further deepen the fruitful interaction between cosmology and high-energy physics.</Summary><Max_ERC_funding>1,995,900</Max_ERC_funding><Duration><Start_date> 2014-08-01, </Start_date><End_date> 2019-07-31</End_date></Duration></Project><Project acronym="HydroSync"><Rcn>188656</Rcn><Nid>12212</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Cambridge, United Kingdom</HI><Name>Hydrodynamic Synchronisation in Model and Biological Systems</Name><PI>Pietro Cicuta</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>Cilia and flagella beating in synchronised patterns give rise to metachronal waves, beautiful examples of emergent behaviour in biology. These collective dynamical states are essential in life, transporting nutrients and clearing pathogens; they arise from the mechanical interaction of individual cilia mediated by the viscous fluid.
Severe pathologies are associated with cilia malfunction in humans. The current analysis of ciliated tissues in the clinic is focused purely on the frequency of beating: this is insufficient to discriminate between different pathologies. Much more information is present in the cilia dynamics video data that is recorded from patients; it is not being extracted because the correct theoretical framework for analysis is not in place.
We will develop our current work on actively driven colloidal systems to selectively test aspects of the biological scenarios, and start a new line of investigation in our lab, with cell culture experiments to validate these findings; we will understand the onset of collective dynamics (new physics), and how cilia waves are robust against fluctuations in cilia beat frequency, spatial arrangement and fluid rheology. New video analysis tools will be developed based on this full understanding of mechanical synchronisation, enabling the collective dynamics to be related back to the behaviour of individual cilia and to the physical properties of the fluid.
The team will be of two Post-docs, responsible for the two parts of the project: model and biological systems. A PhD student will contribute to the biological experiments, which present multiple lines of investigation, and will develop the video-analysis code to obtain the full degree of information from biological experiments.
The new analysis tool that results from this project will be deployed in the clinical setting through an established collaboration; enabling diagnosis of airway disorders represents a broad impact on physiology and clinical practice.</Summary><Max_ERC_funding>1,261,572</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2018-04-30</End_date></Duration></Project><Project acronym="I-SURF"><Rcn>185555</Rcn><Nid>12347</Nid><HI>Universitat Konstanz, Germany</HI><Name>Inorganic surfactants with multifunctional heads</Name><PI>Sebastian Polarz</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>"Surfactants are molecules of enormous scientific and technological importance, which are widely used as detergents, emulsifiers or for the preparation of diverse nanostructures. Fascinating abilities regarding the formation of self-organized structures, like micelles or liquid crystals, originate from their amphiphilic architecture, which comprises a polar head group linked to a hydrophobic chain. While almost all known surfactants are organic, a new family of surfactants is now emerging, which combine amphiphilic properties with the advanced functionality of transition metal building blocks. The current project aims at the synthesis of unique inorganic surfactants (I-SURFs), which contain multinuclear, charged metal-oxo entities as heads, and their exploration with regard to additional redox, catalytic or magnetic functionalities. A particular challenge is the creation of smart surfactant systems that can be controlled via external stimuli. While thermotropic liquid crystals and their adjustment in electric fields (enabling LCDs) have been studied in depth, very limited research concerns the control of self-assembled amphiphilic structures by use of magnetic fields. It is obvious that exposure to a magnetic field has inherent advantages over electric fields for controlling structures in water. I-SURFs with single-molecule magnets as heads will be thus prepared and studied. Another groundbreaking task is the creation of I-SURFs with additional catalytic activities. Since catalytic heads can be positioned via self-organization, for instance on the surface of micellar aggregates, catalytic relay systems can be assembled with a second catalytic species in proximity to the first. Thus, cooperative effects in catalytic tandem reactions will ultimately be observed. These examples show that frontier research on I-SURFs is of outstanding relevance for supramolecular science and will certainly pave the way toward new technological applications with great benefits to society."</Summary><Max_ERC_funding>1,863,546</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="INTENSE"><Rcn>192414</Rcn><Nid>13453</Nid><HI>University Of Newcastle Upon Tyne, United Kingdom</HI><Name>INTENSE: INTElligent use of climate models for adaptatioN to non-Stationary climate Extremes</Name><PI>Hayley Jane Fowler</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"The research proposed here will use a novel and fully-integrated data-modelling approach to provide a step-change in our understanding of the nature and drivers of global precipitation extremes and change on societally relevant timescales. Extreme precipitation is increasing globally and theoretical considerations suggest this will continue with global warming, but opportunistic datasets indicate that sub-daily precipitation extremes will intensify more than is anticipated. Determining the precise response of precipitation extremes is hampered by coarse climate models which cannot adequately resolve cloud-scale processes and a lack of sub-daily observations. INTENSE will comprehensively analyse the response of precipitation extremes to global warming by constructing the first global sub-daily precipitation dataset, enabling substantial advances in observing current and past changes. Together with other new observational datasets and high-resolution climate modelling, this will quantify the nature and drivers of global precipitation extremes and their response to natural variability and forcing across multiple timescales. Specifically the project will examine the influence of local thermodynamics and large-scale circulation modes on observed precipitation extremes using new statistical methods which recognise the non-stationary nature of precipitation, and use these to identify climate model deficiencies in the representation of precipitation extremes. The recurrence of extreme hydrological events is notoriously hard to predict, yet successful climate adaptation will need reliable information which better quantifies projected changes. INTENSE will provide a new synergy between data, models and theory to tackle the problem using a process-based framework; isolating the precursors for extreme precipitation and intelligently using detailed modelling as a tool to understand how these extremes will respond to a warming world and the implications for adaptation strategy."</Summary><Max_ERC_funding>1,986,801</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="INTERFERE"><Rcn>185674</Rcn><Nid>10724</Nid><HI>Vrije Universiteit Brussel, Belgium</HI><Name>Sparse Signal Coding for Interference-based Imaging Modalities</Name><PI>Peter Schelkens</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"Since its invention in 1948 by Dennis Gabor holography has held the promise to empower full parallax 3D visualisation. Though the trajectory has been significantly longer than expected, recent developments in photonics, microelectronics and computer engineering have led to the prospective to realize within a decade dynamic full parallax holography with acceptable rendering quality and viewing angle. Unfortunately projections &#226;&#128;&#147; based on the current state-of-the-art and expected evolution in the underlying &#226;&#128;&#156;hardware&#226;&#128;&#157; technologies &#226;&#128;&#147; still predict exascale computing power and terabytes-per-second data rates.
Since dynamic digital holography requires huge amounts of pixels to be sensed, transmitted and represented, sparse signal representations hold a great promise reducing the computational complexity and bandwidth usage. INTERFERE will design a generic source coding methodology and architecture to facilitate the exploitation of sparse signal representations for dynamic, full parallax, large viewing angle digital holography and more generic, interference-based modalities, with the ambition to reduce the signal processing tailbacks while exploiting simultaneously human visual system characteristics.
Realizing these research objectives &#226;&#128;&#147; with a strong focus on advanced signal representations, associated source coding methodologies and visual quality modelling &#226;&#128;&#147; will provide a breakthrough with respect to the complexity reduction and thus realisation of full-parallax, wide viewing angle dynamic digital holography and benefit the earlier mentioned adjacent scientific fields. Intermediate results or components will have serendipic effects on other scientific disciplines and open new horizons for markets such as &#226;&#128;&#147; but not limited to &#226;&#128;&#147; medical imaging, biophotonics, life sciences, public safety, digital holographic microscopy, holographic biomedical sensors, data storage and metrology, illustrating the high-gain potential of INTERFERE."</Summary><Max_ERC_funding>1,992,615</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="IONOLOGY"><Rcn>111488</Rcn><Nid>10089</Nid><HI>Weizmann Institute Of Science, Israel</HI><Name>Quantum Metrology with Trapped Ions</Name><PI>Roee Ozeri</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>We propose a quantum algorithmic approach to metrology and its implementation using trapped-ion qubits. Active decoherence suppression methods such as decoherence-free subspaces, Quantum error-correction codes and dynamic decoupling will be used to reduce the effect of noise while amplifying a measured signal, thus improving on the measurement signal-to-noise ratio. An ion trap architecture that best suits this approach will be designed and realized. Several metrology protocols will be demonstrated. Finally, we propose to apply these methods in actual precision measurements, including the detection of magnetic interaction between ions at large distances, optical frequency metrology, the measurement of parity violation in atomic transitions, and the detection of correlations in an ultra-cold gas of neutral atoms. The implications of scaling-up to large numbers of probe-qubits will be investigated as well.</Summary><Max_ERC_funding>1,999,882</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="IONPAIRSATCATALYSIS"><Rcn>185540</Rcn><Nid>11508</Nid><HI>Universitaet Regensburg, Germany</HI><Name>Design Principles of Ion Pairs in Organocatalysis &#226;&#128;&#147; Elucidation of Structures, Intermediates and Stereoselection Modes as well as Assessment of Individual Interaction Contributions</Name><PI>Ruth Maria Gschwind</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>Ions are nearly omnipresent in chemistry and biochemistry. By providing the highest intermolecular interaction energies, ionic interactions have an extreme impact on molecular structures, which are the key to molecular functions. Experimentally determined structures of small contact ion pairs in solution are very rare and sometimes lacking in complete research fields. In addition, despite the amazing progress in theoretical and supramolecular chemistry, the subtle interplay of interactions in small organic ion pairs remains largely unknown. As a result design principles for small organic ion pairs in solution are not available. To solve this general problem there is an urgent and actual need of the synthetic community, because ion-pairing catalysis is the actual hot topic in asymmetric catalysis. There, new catalysts have to be screened with high effort in a black box mode and reviews state that structural and mechanistic studies will be an essential part of the further progress in the field. In previous projects spread over the fields of organometallic, bioorganic, supramolecular and medicinal chemistry as well as transition metal catalysis and organocatalysis, we gained special NMR expertise in the structure elucidation of ion pairs and reaction intermediates as well as the assessment of intermolecular interactions. Now in this project, nearly all of these various techniques and approaches will be combined in a new and so far unprecedented way and complemented by techniques used for protein ligand interactions and extreme low temperature measurements. With this unique combination, NMR approaches will be developed and applied to elucidate the structures of catalytically active ion pairs and their intermediates in solution and to dissect their intermolecular interactions. The resulting detailed design concept for small ion pairs in solution will revolutionize not only ion-pairing catalysis but all scientific fields working with organic ion pairs in solution.</Summary><Max_ERC_funding>1,994,685</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="ISOCORE"><Rcn>192409</Rcn><Nid>13459</Nid><HI>Westfaelische Wilhelms-Universitaet Muenster, Germany</HI><Name>New isotope tracers for core formation in terrestrial planets</Name><PI>Thorsten Kleine</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"This proposal aims to develop new isotopic tools designed to constrain the core formation process in the Earth. We will use isotopic fractionations imparted by metal-silicate equilibration during core formation to obtain new and firm constraints on (i) the physical and chemical processes during formation of the Earth's core; and (ii) on the origin of volatile elements and the volatile accretion history of the Earth. The underlying concept of our  approach is to compare observed mantle-core isotopic fractionations (determined on natural samples) to the experimentally-determined isotope fractionation between liquid metal (core analogue) and liquid silicate (mantle analogue). Since the magnitude of isotope fractionation is strongly temperature-dependent, this comparison will enable us to evaluate core formation temperatures. I propose to use the stable isotope systematics of W, Mo and Cr to assess as to whether core formation temperatures for the Earth, Moon, Mars and asteroids are different, as would be expected if metal segregation in the Earth involved metal-silicate equilibration in a deep magma ocean. If instead all bodies have similar core formation temperatures, then formation of the Earth's core most probably involved some disequilibrium induced by direct core mergers during accretion from differentiated bodies. The second major theme of the proposed research uses Ge and Sb stable isotopes to trace the origins of Earth's volatiles. The combined investigation of Ge and Sb isotope fractionations in natural samples and metal-silicate equilibration experiments will enable us to determine as to whether Ge and Sb, and with them other volatile elements, show an isotope signature resulting from core formation. Identifying such a signature would provide the unequivocal evidence that volatile elements were delivered to the Earth during core formation and not subsequently, after the core had formed."</Summary><Max_ERC_funding>1,940,040</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="InanoMOF"><Rcn>185614</Rcn><Nid>12330</Nid><HI>Fundacio Institut Catala De Nanociencia I Nanotecnologia, Spain</HI><Name>Multifunctional micro- and nanostructures assembled from nanoscale metal-organic frameworks and inorganic nanoparticles</Name><PI>Daniel Maspoch Comamala</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>In InanoMOF, we aim to develop frontier Supramolecular and Nanochemistry methodologies for the synthesis of a novel class of structures via controlled assembly of nanoscale metal-organic frameworks (nanoMOFs) and inorganic nanoparticles (INPs). These methods will embody the premise that &#226;&#128;&#156;controlled object-by-object nano-assembly is a ground-breaking approach to explore for producing systems of higher complexity with advanced functions&#226;&#128;&#157;. The resulting hybrid nanoMOF@INPs will marry the unique properties of INPs (magnetism of iron oxide NPs and optics of Au NPs) to the functional porosity of MOFs.

The first part of InanoMOF encompasses the design, synthesis-assembly and characterisation of nanoMOF@INPs - advanced MOF-based sorbents that incorporate the functionality of the INPs used: magnetically controlled movement, in vivo detectability, enhanced biocompatibility and porosity, pollutant removal, or controlled sorption/delivery. The second part of InanoMOF entails studying the physicochemical properties of the synthesised nanoMOF@INPs and ascertaining their utility as drug-delivery/theranostic systems and as magnetic sorbents for pollutant removal. Specifically, we will study their stability in working media and determine their capacities for drug or pollutant sorption/delivery capacities. As proof-of-concept, we will study their toxicity in vitro and in vivo; enhancement of their in vitro therapeutic efficacy; and their capacity to remove pollutants (in real water and gasoline/diesel fuel samples) via magnetic assistance.

In InanoMOF we will endeavour to establish the synthetic bases for controlling the spatial ordering of nanoMOF crystals, whether alone or combined with other nanomaterials (e.g. INPs, graphene, etc.). We are confident that our work will ultimately enable researchers to create MOF-based composites having cooperative and synergistic properties and functions for myriad applications (e.g. heterogeneous catalysis, sensing and separation).</Summary><Max_ERC_funding>1,942,665</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="LBCAD"><Rcn>192410</Rcn><Nid>13452</Nid><HI>Univerzita Karlova V Praze, Czech Republic</HI><Name>Lower bounds for combinatorial algorithms and dynamic problems</Name><PI>Michal Koucky</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"This project aims to establish the time complexity of algorithms for two classes of problems. The first class consists of problems related to Boolean matrix multiplication and matrix multiplication over various semirings. This class contains problems such as computing transitive closure of a graph and determining the minimum distance between all-pairs of nodes in a graph. Known combinatorial algorithms for these problems run in slightly sub-cubic time. By combinatorial algorithms we mean algorithms that do not rely on the fast matrix multiplication over rings. Our goal is to show that the known combinatorial algorithms for these problems are essentially optimal. This requires designing a model of combinatorial algorithms and proving almost cubic lower bounds in it.

The other class of problems that we will focus on contains dynamic data structure problems such as dynamic graph reachability and related problems. Known algorithms for these problems exhibit trade-off between the query time and the update time, where at least one of them is always polynomial. Our goal is to show that indeed any algorithm for these problems must have update time or query time at least polynomial.

The two classes of problems are closely associated with so called 3SUM problem which serves as a benchmark for uncomputability in sub-quadratic time. Our goal is to deepen and extend the known connections between 3SUM, the other two classes and problems like formula satisfiability (SAT)."</Summary><Max_ERC_funding>900,200</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="LifeInverse"><Rcn>185581</Rcn><Nid>12003</Nid><HI>Westfaelische Wilhelms-Universitaet Muenster, Germany</HI><Name>Variational Methods for Dynamic Inverse Problems in the Life Sciences</Name><PI>Martin Burger</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>This project will develop novel techniques for solving inverse problems in life sciences, in particular related to dynamic imaging. Major challenges in this area are efficient four- dimensional image reconstruction under low SNR conditions and further the quantification of image series as obtained from molecular imaging or life microscopy techniques. We will tackle both of them in a rather unified framework as inverse problems for time-dependent (systems of) partial differential equations.
In the solution of these inverse problems we will investigate novel approaches for the following aspects specific to the above-mentioned problems in the life sciences:

1. Solution of inverse problems for PDEs in complex time-varying geometries
2. Development of appropriate variational regularization models for dynamic images, including noise and motion models
3. Improved forward and inverse modelling of cellular and intracellular dynamics leading to novel inverse problems for nonlinear partial differential equations
4. Construction and implementation of efficient iterative solution methods for the arising 4D inverse problems and their variational formulation

All tasks will be driven by concrete applications in biology and medicine and their success will be evaluated in applications to real problems and data. This is based on interdisciplinary work related to electrocardiology and developmental biology. The overall development of methods will however be carried out in a flexible and modular way, so that they become accessible for larger problem classes.</Summary><Max_ERC_funding>966,400</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="LiveSoft"><Rcn>189853</Rcn><Nid>11802</Nid><HI>Technische Universitat Darmstadt, Germany</HI><Name>Lightweight Verification of Software</Name><PI>Patrick Thomas Eugster</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>As illustrated through the advent of cloud computing, cyberphysical systems, or the Internet of Things, more and more applications are inherently distributed. At the same time, programming distributed systems is notoriously hard. Programmers have to deal with asynchrony and have to cater for partial failures -- the possibility that certain communication(s), processes, or hosts fail while others remain operational. These failures can have drastic consequences such as the missing to react to critical events or inconsistent states respectively. Limitations on existing hardware infrastructure necessitate subtle assumptions on system and failure models though to achieve efficient yet complex algorithmic solutions, whose implementation is prone to delicate defects.


Existing techniques for engineering reliable distributed systems software require much effort (e.g., program annotations in the form of invariants) thus discouraging many developers from their use; other techniques require developers to explicitly run specific tools (e.g., model checkers) which are thus easily left out and still can not achieve complete validation.

LiveSoft investigates static techniques to verify a subset of relevant and failure-prone aspects of distributed software --- interaction between components --- in a way which is lightweight and can be integrated with compilation. Our techniques will be able to sieve out many important defects upfront by pushing software reliability into the software design process. To that end LiveSoft proposes protocol types which leverage experiences with session types yet focus on fault-tolerant distributed systems by emphasizing asynchrony, failure handling and recovery, protocol composition, security, and parameterization. A main challenge is to support different system and failure models including emerging hardware trends such as hardware transactional memory and non-volatile memory rather than hardwiring speicific notions of (a)synchrony and failures.</Summary><Max_ERC_funding>1,999,320</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="MASSLIP"><Rcn>185677</Rcn><Nid>12030</Nid><HI>Imperial College Of Science Technology And Medicine, United Kingdom</HI><Name>Systems Medical Diagnostics by In-vivo Ambient Mass Spectrometric Profiling of Tissue Lipidome</Name><PI>Zoltan Takats</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"The objective of the proposal is the development of ambient mass spectrometric methods for the characterisation of mucosal metabolome and lipidome. While recent advent of ambient MS provided new means for in-situ and imaging analyses and led to the development of real-time, in-vivo MS characterisation of tissues, there are no methods available for minimally invasive testing of mucosal surfaces including the associated microflora. Human mucosa-associated microbiome (with special emphasis on the gastrointestinal microbiota) has been recently demonstrated to play a key role in the pathogenesis of localised (cancer, chronic inflammatory disease) and systemic (hypertension, diabetes, obesity) conditions. While the microbiota interacts with the host mostly via production of a variety of metabolites, currently there is no method available for the in-situ metabolic profiling of mucosa. The envisioned methods will presumably fill this gap, by providing a technique for the diagnosis of a wide range of diseases ranging from acute infections through cancer to dysbiotic conditions of the microflora leading to chronic illnesses.
In the current proposal we put forward the development of different ambient ionisation setups utilising Jet Desorption Ionisation, Sonic Spray Ionisation and Rapid Evaporation Ionisation MS covering a broad range of invasiveness. We plan to combine the methods with standard endoscopic tools and develop the concept of &#194;&#180;chemically aware&#194;&#180; or intelligent endoscopic device capable of the unambiguous identification of pathological conditions of the mucosa. Since the metabolic profile-based identification approach requires large authentic datasets, we plan to create both histopathological and bacterial spectral databases with histological and 16SrRNA-based validation. The proposal also comprises the development of novel multivariate statistical analysis workflows and data fusion algorithms allowing rapid and accurate identification using multimodal MS datasets."</Summary><Max_ERC_funding>1,997,663</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="MHETSCALE"><Rcn>185662</Rcn><Nid>11236</Nid><HI>Agencia Estatal Consejo Superior Deinvestigaciones Cientificas, Spain</HI><Name>Mixing in Heterogeneous Media Across Spatial and Temporal Scales: From Local Non-Equilibrium to Anomalous Chemical Transport and Dynamic Uncertainty</Name><PI>Marco Dentz</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>Transport, mixing and reaction of solutes and particles in natural media are of central importance in many fields of science and engineering, ranging from contaminant dispersion in geophysical flows to diffusion in living cells. Transport in these intrinsically heterogeneous media is characterized by early and late solute and particle arrivals, tailed spatial distributions, and scale effects in measured parameters. These behaviors cannot be explained by available models based on Fick&#226;&#128;&#153;s law and are called anomalous despite their ubiquity. The origin of such phenomena lies in heterogeneity-induced mixing processes that lead to fluctuations in chemical concentration, or, in other words, to physical non-equilibrium. Current transport formulations based on the advection-dispersion-reaction equation or phenomenological non-equilibrium models lack the relation to the heterogeneity controls, fail to describe mixing and concentration variability and thus are not suited for the quantification of chemical reactions. The main objective of this proposal is to establish a global predictive framework that quantifies mixing across scales, anomalous transport and reaction, and dynamic uncertainty for heterogeneous media. We propose an integrated approach that links the interrelated phenomena of mixing, anomalous transport and chemical reaction. In short, the idea consists in quantifying microscale heterogeneity-induced mixing in terms of the flow kinematics and heterogeneity structure and linking it to transport through its relation to Lagrangian particle dynamics. These dynamics will be quantified stochastically by a novel generalized continuous time random walk approach and used to model chemical reactions under physical non-equilibrium in order to obtain a new solid approach for simulating reactive and conservative transport through natural media.</Summary><Max_ERC_funding>1,904,186</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="MINERVA"><Rcn>185644</Rcn><Nid>12018</Nid><HI>Koc University, Turkey</HI><Name>Communication Theoretical Foundations of Nervous System Towards BIO-inspired Nanonetworks and ICT-inspired Neuro-treatment</Name><PI>Ozgur B. Akan</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>&#226;&#128;&#156;There&#226;&#128;&#153;s Plenty of Room at the Bottom&#226;&#128;&#157;, stated by Nobel laureate Richard Feynman, describes the possibility of manipulating individual atoms and molecules to realise nanomachines. Emerging nanoscale applications mandate enabling nanomachines to communicate and form nanonetworks to overcome the limitations of a single one. Thus, our aim is to find the answer to the profound question, i.e., &#226;&#128;&#156;is the room down there sufficient for a communication network?&#226;&#128;&#157; Thanks to natural evolution, the affirmative answer is right inside us. Human body is a large- scale communication network of molecular nanonetworks composed of billions of nanomachines, i.e., cells, which use molecules to encode, transmit and receive information. Any communication failure that is beyond the recovery capabilities of this network leads to diseases. In this project, first, (1) we will investigate the communication theoretical foundations of nanoscale neuro-spike communication channels between neurons. Second, (2) we will study multi-terminal, i.e., multiple-access, relay, broadcast, neuro-spike channels and nervous nanonetwork in terms of communication theoretical metrics. Third, (3) we will validate our channel and nanonetwork models with physiological data, and develop a nervous nanonetwork simulator (N4Sim). Finally, (4) we will develop the first nanoscale bio-inspired communication system for ICT-inspired neuro-treatment for spinal cord injury, i.e., nanoscale artificial synapse, which will mimic neuron behaviour by realising both electrical and nanoscale molecular communications.The MINERVA project will pave the way for the realisation of emerging nanonetwork applications with significant societal impact, e.g., intra-body networks for health monitoring, drug delivery, chemical and biological attack prevention systems. The project will help develop the future ICT-inspired treatment techniques for communication related neural disorders.</Summary><Max_ERC_funding>1,757,039</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="MINT"><Rcn>192404</Rcn><Nid>13466</Nid><HI>Centre National De La Recherche Scientifique, France</HI><Name>Emerging electronic states and devices based on Mott insulator interfaces</Name><PI>Manuel Alain Bibes</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Transition metal oxides possess a broad range of functionalities (superconductivity, magnetism, ferroelectricity, multiferroicity) stemming from the interplay between structural effects and electronic correlations. Recent work has revealed exciting physics at their interfaces, including two-dimensional (2D) conductivity and superconductivity in the electron gas that forms at the interface between two band insulators, LaAlO3 and SrTiO3. However, to date, no interfacial system has truly shown electronic properties that are absent from the phase diagram of both bulk constituents. I argue that to fully embrace the immense potential of oxide interfaces and unveil unprecedented electronic phases, combining insulators with stronger electronic correlations is mandatory.

At the crossroad between strongly-correlated electron physics, microelectronics and spintronics, the MINT project will pioneer routes toward a new realm of solid-state physics. MINT will harness electronic and magnetic instabilities in correlated oxides to craft new electronic phases controllable by external stimuli. These phases will be generated by the synergic action of strain engineering, interfacial charge/orbital/spin reconstruction and octahedra connectivity control, using rare-earth titanate RTiO3 Mott-Hubbard insulators as templates.

Emerging states that are foreseen include 2D electron gases with ferroic order, superconductivity at relatively high temperature, topological states and new forms of multiferroicity and magnetoelectric coupling. The discovery of any of these new states would represent a major breakthrough in oxide electronics. They will open possibilities for innovative devices yielding giant electroresistance without ferroelectrics, and new schemes to control spin currents by electric fields.

At full term, MINT will establish whether oxide interfaces will live up to their expectations and start in the coming decades a technological revolution comparable to that of silicon."</Summary><Max_ERC_funding>1,998,026</Max_ERC_funding><Duration><Start_date> 2014-10-01, </Start_date><End_date> 2019-09-30</End_date></Duration></Project><Project acronym="MOTMELSUM"><Rcn>185607</Rcn><Nid>11993</Nid><HI>Centre National De La Recherche Scientifique, France</HI><Name>Motivic Mellin transforms and exponential sums through non-archimedean geometry</Name><PI>Raf Cluckers</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"We aim to create a new and powerful theory of motivic integration which incorporates Mellin transforms. The absence of motivic Mellin transforms is a major drawback of the existing theories. Classical Mellin transforms are in essence Fourier transforms on the multiplicative group of local fields. We aim to apply this theory to study new motivic Poisson summation formulas, new transfer principles, and applications of these. All of this has so far only been studied in the presence of additive characters, and remains completely open for multiplicative characters. Understanding all this at a motivic level yields a uniform understanding when the local field varies and will require an approach using non-archimedean geometry. We will open up possibilities for applications via new transfer principles and will give access to motivic Poisson formulas of other groups than the additive group. For these applications it is important that Fubini Theorems are present at the level of the motivic integrals, which we aim to develop. We will overcome the major obstacle of the totally different nature of the dual group of the multiplicative group by a proposed sequence of germs of ideas by the author. The importance of our work on motivic Fourier transforms on the additive group is already widely recognized, and this proposal will complement it by exploring the new territory of motivic multiplicative characters. A final topic is the study of the highly non-understood exponential sums modulo powers of primes, in relation with Igusa's foundational work. We will try to discover a deeper understanding of the uniform behavior of these sums when the prime number varies. These sums are linked to geometrical concepts like the log-canonical threshold, and also to Poisson summation, after the work by Igusa. We will aim to prove a highly generalized form of Igusa's conjecture on exponential sums."</Summary><Max_ERC_funding>912,000</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="MSMath"><Rcn>188649</Rcn><Nid>12204</Nid><HI>Ecole Nationale Des Ponts Et Chaussees, France</HI><Name>Molecular Simulation: modeling, algorithms and mathematical analysis</Name><PI>Tony Gilbert Lelievre</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>Many models for materials rely on a microscopic description. In a classical regime and for a fixed temperature, atoms are described by particles that interact through a force field and evolve according to Newton&#226;&#128;&#153;s equations of motion, with additional stochastic terms to model thermostating. This simulation technique is called molecular dynamics. Applications are ubiquitous, ranging from biology to materials science.

The direct numerical simulation of these models is extremely computationally expensive, since the typical timescale at the microscopic level is orders of magnitude smaller than the macroscopic timescales of interest. Many algorithms used by practitioners have not yet been investigated by applied mathematicians. The aim of this proposal is to further develop the mathematical analysis of these methods and to build new and more efficient algorithms, validated by precise error estimates.

The underlying theoretical questions are related to the mathematical definition and quantification of metastability for stochastic processes. Metastability refers to the fact that the stochastic process remains trapped in some regions of the configuration space for very long times. Using naive simulations, transitions between these states are very rarely observed, whereas these transition events are actually those which matter at the macroscopic level. Metastability is one of the major bottlenecks in making molecular simulations predictive for real life test cases.

The main challenges motivating this proposal are: the design of efficient techniques to sample high-dimensional multimodal measures, the development and analysis of algorithms to sample metastable dynamics and the construction of coarse-graining techniques for high-dimensional problems.

This project relies on strong collaborations with practitioners (biologists and physicists) in order to propose common benchmarks, to identify the methodological bottlenecks and to apply new algorithms to real life test cases.</Summary><Max_ERC_funding>1,773,600</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="MULTISCOPE"><Rcn>185556</Rcn><Nid>11381</Nid><HI>Julius-Maximilians Universitaet Wuerzburg, Germany</HI><Name>Multidimensional Ultrafast Time-Interferometric Spectroscopy of Coherent Phenomena in all Environments</Name><PI>Tobias Manuel Brixner</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"We propose to develop and apply novel methods of nonlinear spectroscopy to investigate the significance and consequences of coherent effects for a variety of photophysical and photochemical molecular processes. We will use coherent two-dimensional (2D) spectroscopy as an ideal tool to study electronic coherences.

Quantum mechanics as described by the Schr&#195;&#182;dinger equation is fully coherent: The phase of a wavefunction evolves deterministically in the time-dependent case. However, observations are restricted to reduced &#226;&#128;&#156;systems&#226;&#128;&#157; coupled to an &#226;&#128;&#156;environment.&#226;&#128;&#157; The resulting transition from coherent to incoherent behavior on an ultrafast timescale has many yet unexplored consequences, e.g. for transport in photosynthesis, photovoltaics or other molecular &#226;&#128;&#156;nanomaterials.&#226;&#128;&#157;

In contrast to conventional 2D spectroscopy, we will not measure the coherently emitted field within a four-wave mixing process but rather implement a range of incoherent observables (ion mass spectra, fluorescence, and photoelectrons). Yet we can still extract all the desired information using &#226;&#128;&#156;phase cycling&#226;&#128;&#157; with collinear pulse sequences from a femtosecond pulse shaper. This opens up a new range of interdisciplinary experiments and will allow for the first time a direct nonlinear-spectroscopic comparison of molecular systems in all states of matter. Specifically, we will realize 2D spectroscopy in molecular beams, liquids, low-temperature solids, and on surfaces including heterogeneous and nanostructured samples. Tuning the external couplings will help elucidating the role of the environment in electronic (de)coherence phenomena.

Furthermore, we will combine 2D spectroscopy with subdiffraction spatial resolution using photoemission electron microscopy (PEEM). This enables us to map transport in molecular aggregates and other heterogeneous nanosystems in time and space on a nanometer length scale. Thus we access the intersection between the domains of electronics and nanophotonics."</Summary><Max_ERC_funding>2,669,124</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="MicroDegrade"><Rcn>192411</Rcn><Nid>13463</Nid><HI>Helmholtz Zentrum Muenchen, Deutsches Forschungszentrum Fuer Gesundheit Und Umwelt (Gmbh), Germany</HI><Name>Identifying and Overcoming Bottlenecks of Micropollutant Degradation at Low Concentrations</Name><PI>Martin Elsner</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"MicroDegrade aims to reveal bottlenecks of degradation, and to identify superior bioremediation strategies for a most notorious environmental pollution of our time: chemical micropollutants at low (sub-ug/L) concentrations. Finding out why micropollutants occur in ground and surface water despite the presence of bacterial degraders has become an elusive goal for microbiologists, environmental scientists and geochemists. Competing paradigms claim that either (i) mass transfer limitations (bioavailability, cell uptake) or (ii) physiological limitations (enzyme down-regulation) prevent complete biodegradation at contaminant threshold concentrations. To design strategies for remediation, insight is warranted which bottlenecks of degradation prevail. ""Do molecules - once inside an organism - get out into solution again? Or is mass transfer so limiting that organisms are desperate for supply?"" Pillaring on our recent advances with compound-specific isotope analysis at sub-ug/L concentrations, MicroDegrade will be able to provide a revolutionary angle on this dilemma.  Isotope fractionation will give the first direct answers to these questions for degradation of two prominent pollutants at low bacterial growth and low concentrations - 2,6-dichlorobenzamide (BAM), a highly recalcitrant, ubiquitous pesticide metabolite with Aminbacter MSH1; and toluene, an abundant groundwater pollutant with Geobacter metallireducens. The approach pillars on three consecutive aims: (1) investigate if, and at what concentrations mass transfer becomes limiting in chemostat cultures; (2) understand analogous limitations in concentrations gradients of an aquifer model; (3) derive superior bioremediation strategies. The objectives of MicroDegrade have the potential to change our view on drivers behind thresholds values and bottlenecks of degradation, to offer a new angle on competitive strategies of microorganisms at low concentrations, and to identify superior future bioremediation strategies."</Summary><Max_ERC_funding>1,962,630</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="N2RED"><Rcn>191266</Rcn><Nid>11261</Nid><HI>Max-Planck-Gesellschaft Zur Forderung Der Wissenschaften Ev, Germany</HI><Name>Spectroscopic Studies of N2 Reduction: From Biological to Heterogeneous Catalysis</Name><PI>Serena Debeer</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"The conversion of dinitrogen (N2) to ammonia (NH3) is of fundamental biological and economic importance. The catalytic conversion is achieved either industrially, using heterogeneous catalysts or biologically, by the nitrogenase enzyme. However, in both cases, the mechanistic details of the process are not fully understood. In order to design advance catalysts that will be essential for a sustainable energy economy, an in-depth understanding of both the biological and chemical mechanisms is required. The goal of this proposal is to develop advanced spectroscopic tools, which will allow for a detailed description of the atomic level processes in the both the biological and the heterogeneous systems. This will include the development of valence to core resonant X-ray emission spectroscopy as a unique probe of transition metal ligation in complex media. High-resolution X-ray absorption, X-ray emission, X-ray magnetic circular dichroism, and nuclear resonant vibrational spectroscopy will be utilized and their chemical information content fully developed. These experiments will be correlated to advanced quantum chemical calculations to obtain a detailed picture of the electronic structure of the catalytic systems. The results should provide a clear understanding of the electronic factors that govern N-N bond cleavage. The proposed research will bring together the fields of biochemistry and heterogeneous catalysis, by utilizing inorganic, physical and theoretical chemistry to advance our fundamental understanding of N2 cleavage. The proposed developments will provide a powerful set of novel tools for the elucidation of transition metal catalyzed homogenous and heterogeneous reaction mechanisms. The long-term goal is to pave the way for rationally designed catalytic systems, based on fundamental mechanistic knowledge."</Summary><Max_ERC_funding>1,989,600</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="NANODYNAMITE"><Rcn>185618</Rcn><Nid>10731</Nid><HI>Universitat Wien, Austria</HI><Name>Quantifying Aerosol Nanoparticle Dynamics by High Time Resolution Experiments</Name><PI>Paul Martin Winkler</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"The formation of aerosol nanoparticles by vapour nucleation and condensational growth is currently considered the dominant source of cloud condensation nuclei on global scale, hence impacting radiative properties of the atmosphere and precipitation patterns of clouds. Despite considerable experimental and theoretical efforts, the mechanisms of the gas-to-particle conversion are still poorly understood, and so are the parameterizations of this process in climate models. Improving the situation critically depends on the continuous development of experimental techniques. For the quantitative characterization of nanoparticle dynamics especially time resolution deserves more attention. I am thus proposing to design instruments that will improve time resolution by up to five orders of magnitude. Specifically, I am planning the design of a fast-scanning electrical mobility based nanoparticle spectrometer delivering size distributions from 1 nm upwards at 1 Hz, for number concentrations as low as 100 cm-3. Secondly, in a new approach to the study of secondary organic aerosol formation I am planning to apply small angle x-ray scattering providing direct information on particle size and number at sub-millisecond time-resolution. Thirdly, the study of fundamental growth kinetics by Mie scattering at short wavelengths will constitute an important part of my research. And finally, an application oriented research task will deal with the design and construction of a nucleation based trace-gas removal system capable of generating liquid water from plain ambient air.
The research on phase transition processes constitutes a vital link between molecular scale interactions and macroscopically relevant outcome. The current proposal aims at identifying and quantifying nanoparticle formation mechanisms by new experimental approaches. Thereby it will be possible to reliably predict and utilize macroscopic effects caused by aerosol mechanisms on the nano-scale."</Summary><Max_ERC_funding>1,810,698</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="NANOHEDONISM"><Rcn>185559</Rcn><Nid>11541</Nid><HI>Universidad De Zaragoza, Spain</HI><Name>A Photo-triggered On-demand Drug Delivery System for Chronic Pain</Name><PI>Manuel Arruebo Gordo</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"Nerve pain affects millions of people, and can be personally devastating for people who experience it. Current methods for pain management (e.g. local injection of pain killers) are inadequate because of the short duration of action. Even sustained release treatments, such as drug-loaded liposomes, provide only one week of analgesia producing a continuous extended nerve blockade without allowing for changes in daily physical activity or level of pain relief. More importantly, such systems cannot be turned off until they run their course.

In this proposal, a locally-injected or implanted near infrared (NIR)-sensitive drug reservoir that can be triggered by a simple handheld laser device applied externally is described. The device enables drug release with consistent response over multiple on/off cycles. Such a device, implanted (or eventually injected) on a nerve or near the neuraxis, could have substantial clinical impact in the treatment of chronic (or prolonged perioperative) pain.

This system will consist of an impermeable ethylcellulose membrane embedded with temperature-sensitive polymer nanoparticles and NIR-active gold nanoparticles. The membrane will be engineered such that the nanoparticles form a disordered but interconnected network throughout. The gold nanoparticle concentration will be adjusted so that light-induced heating of the nanoparticles produces sufficient heat to collapse the polymer, thus opening the porous network. Those nanostructured materials which compose the device will be produced in a continuous manner by using microfluidic reactors to avoid the characteristic disadvantages when using conventional discontinuous (batch) reactors. Nanoparticle-synthesis protocols will be supported by computational fluid dynamics.

The specific aims will be geared toward engineering a NIR-triggered drug release device and optimizing for a variety of drug types, then demonstrating its biocompatibility and therapeutic effectiveness in vivo."</Summary><Max_ERC_funding>1,570,091</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="NANOPRS"><Rcn>111553</Rcn><Nid>11827</Nid><HI>University Of Bristol, United Kingdom</HI><Name>Nano-Particle-Resolved Studies</Name><PI>Christopher Patrick (Paddy) Royall</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Amorphous materials may be classified into three types &#226;&#128;&#147; thermodynamically stable liquids, metastable (supercooled) liquids and solid glasses. The second type represents the meeting point of many of the great challenges of statistical physics and materials science. What is the mechanism of dynamical arrest, by which structural relaxation become progressively inhibited upon cooling from a liquid to a glass? Can we develop physical pictures of the sequence of fluctuations associated with irreversible relaxation in metastable liquids? How do crystals emerge from these fluctuations?

Here we take a structural approach coupled with novel experiments and computer simulations to tackle two specific questions. Firstly, it has long been believed that there should be some structural mechanism underpinning the glass transition, where deeply supercooled liquids continuously transform into solid glasses. Secondly, the fate of the supercooled liquid &#226;&#128;&#147; whether it crystallises on accessible timescales &#226;&#128;&#147; should also be related to the local atomic arrangements in the liquid. Tackling the first will lead to insight into the nature of the glass transition - it is not known whether or not there is a true thermodynamic transition to a glass. As for crystallisation, predicted nucleation rates vary wildly with those obtained experimentally in the only system in which both have been compared, little is known beyond trial and error of means by which crystallisation in mixtures can be controlled. In short, our understanding of the fate of supercooled liquids is lacking in a variety of ways. Understanding the glass transition and nucleation is of fundamental importance, and both have important applications for example in metallic glasses and phase change materials. The former are prized for their superior mechanical properties such as extreme toughness while latter underpin emergent technologies such as optical data storage and phase change memory."</Summary><Max_ERC_funding>2,336,887</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="NAUTILUS"><Rcn>185576</Rcn><Nid>12337</Nid><HI>Johann Wolfgang Goethe Universitaet Frankfurt Am Main, Germany</HI><Name>Neutron cAptUres consTraIning steLlar nUcleosynthesiS</Name><PI>Rene Reifarth</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"NAUTILUS will investigate the nucleosynthesis of the chemical elements during the evolution of stars, which is the basis for understanding the chemical history of the Universe. The vast majority of the elements heavier than iron are produced by neutron capture reactions. The precise knowledge of the involved neutron capture cross sections for certain isotopes sets tight limits for stellar parameters and puts strong constraints on the age of the Universe.

Accurate measurements of the key nuclear reactions in the mass region around the radioactive 85Kr will lead to the improvements needed to characterize the production processes of the elements in stars. The respective high-accuracy abundance patterns in single stars can then be interpreted as diagnostic tools for the deep stellar interior and the isobaric 87Sr/87Rb chronometer constraints the history of the Universe.

The neutron capture cross section of radioactive isotopes for neutron energies in the keV region will be measured by a time-of-flight (TOF) experiment. NAUTILUS will provide a unique facility realizing the TOF technique with an ultra-short flight path at the FRANZ setup at Goethe University Frankfurt am Main, Germany. A highly optimized spherical photon calorimeter will be built and installed at an ultra-short flight path.

NAUTILUS opens new horizons in the area of neutron-induced reaction research, as smallest samples like of 85Kr - which will be produced as an isotopically pure radioactive sample - will become measureable in reasonable times.

Future applications include the study of neutron capture cross sections important for next generation nuclear reactors: For the first time the high neutron fluxes needed to study the mass region of interest in the keV energy range will be available."</Summary><Max_ERC_funding>1,871,596</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="NLL"><Rcn>185665</Rcn><Nid>11372</Nid><HI>Bilkent &#195;&#156;niversitesi, Turkey</HI><Name>Nonlinear Laser Lithography</Name><PI>Fatih &#195;&#182;mer &#196;&#176;lday</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"Control of matter via light has always fascinated humankind; not surprisingly, laser patterning of materials is as old as the history of the laser. However, this approach has suffered to date from a stubborn lack of long-range order. We have recently discovered a method for regulating self-organised formation of metal-oxide nanostructures at high speed via non-local feedback, thereby achieving unprecedented levels of uniformity over indefinitely large areas by simply scanning the laser beam over the surface.

Here, we propose to develop hitherto unimaginable levels of control over matter through laser light. The total optical field at any point is determined by the incident laser field and scattered light from the surrounding surface, in a mathematical form similar to that of a hologram. Thus, it is only logical to control the self-organised pattern through the laser field using, e.g., a spatial light modulator. A simple wavefront tilt should change the periodicity of the nanostructures, but much more exciting possibilities include creation of patterns without translational symmetry, i.e., quasicrystals, or patterns evolving non-trivially under scanning, akin to cellular automata. Our initial results were obtained in ambient atmosphere, where oxygen is the dominant reactant, forming oxides. We further propose to control the chemistry by using a plasma jet to sputter a chosen reactive species onto the surface, which is activated by the laser. While we will focus on the basic mechanisms with atomic nitrogen as test reactant to generate compounds such as TiN and SiN, in principle, this approach paves the way to synthesis of an endless list of materials.

By bringing these ideas together, the foundations of revolutionary advances, straddling the boundaries of science fiction, can be laid: laser-controlled self-assembly of plethora of 2D patterns, crystals, and quasicrystals alike, eventually assembled layer by layer into the third dimension -- a 3D material synthesiser."</Summary><Max_ERC_funding>1,999,920</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="NMST"><Rcn>188673</Rcn><Nid>11263</Nid><HI>Bcam - Basque Center For Applied Mathematics Asociacion, Spain</HI><Name>New methods and interacions in Singularity Theory and beyond</Name><PI>Javier Jose Fernandez De Bobadilla De Olazabal</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"This project is centred in Singularity Theory and its interactions and applications to Complex and Algebraic Geometry, Differential/symplectic/Contact Topology, Hodge Theory and Algebraic Topology. This subject is still at the core of various developments (Mori's Theory, Symplectic and Contact Geometry, algebro-geometric Donaldson-Thomas Theory, Hodge Theory and D-modules,...) In the present project we propose several directions of development in singularity theory, designed in order to approach the solution of several classical conjectures, and explore new interactions with the latest developments in nearby areas. New problems and conjectures are formulated, which are interesting bottlenecks whose solution would open new development perspectives in the theory, and whose study will need significantly new ideas. We have taken care of finding feasible starting points and interesting classes of singularities where the initial development is less steep.  And to find links among the seemingly difernt techniques and problems which we propose.
We deal with the following specific topics: vanishing cohomology of isolated and non-isolated singularities.  Rational homotopy generalisations of Hodge Theory and rational vanishing homotopy. Applications to Equisingularity questions. Disentanglement theory and its relation with vanishing homology and homotopy. Symplectic and contact geometry of milnor fibrations. A vast programme in topological equisingularity including a multifaceted attack to L&#195;&#170;-Ramanujan problem. Generalisations of McKay correspondence. Banagl Intersection spaces. Topological and analytic invariants of normal surface singularities. Arc spaces and Nash correspondence. Compactified Jacobians."</Summary><Max_ERC_funding>1,140,601</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="NOFEAR"><Rcn>188651</Rcn><Nid>12206</Nid><HI>The University Of Manchester, United Kingdom</HI><Name>New Outlook on seismic faults: From EARthquake nucleation to arrest</Name><PI>Giulio Di Toro</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"With an average toll of 80.000 deaths per year over the last decade, earthquakes remain one of the most dreadful geohazards. The advancement of earthquake risk assessment and forecasting methods (probability estimates that a mainshock may occur in terms of hypocentre location, magnitude and time) calls for a sound physical basis. The nucleation, propagation and arrest of an earthquake rupture results from the interplay of stress perturbations, micro- to macro-scale friction- and rupture-related processes and fault zone geometrical complexity. Most of the information about these parameters is out of reach of seismic waves and geophysical analysis. Here we aim at enhancing our knowledge of earthquake physics (from nucleation to arrest) by means of a multidisciplinary approach that includes:

1) experiments to investigate earthquake nucleation by reproducing crustal (pressure, temperature, presence of fluids, stress perturbations, etc.) deformation conditions with the most powerful earthquake simulator installed worldwide (SHIVA);

2) experiments to investigate rupture propagation on simulated faults using natural rocks and small-scale analogue models;

3) field studies of exhumed seismogenic sources to quantify the geometrical complexity of natural fault zones;

4) advanced numerical simulation techniques that will integrate the above information and allow up-scaling to natural faults. The numerical models will produce physically-based earthquake simulations that will be compared with high-resolution seismic data.

By reproducing crustal deformation conditions (stress, temperature, fluid pressures, etc.) in the laboratory and by monitoring acoustic emissions, gases, electromagnetic waves, etc., produced by the rock samples during deformation, a by-product of our research will be the systematic investigation of precursory phenomena (seismic, chemical, and electromagnetic) associated to earthquake nucleation processes."</Summary><Max_ERC_funding>1,963,800</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="NONSPHEREFLOW"><Rcn>185574</Rcn><Nid>12008</Nid><HI>Technische Universiteit Delft, Netherlands</HI><Name>Multiscale modelling of gas-fluidized flows of non-spherical particles</Name><PI>Johannes Tiemen Padding</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>Many important products are made using fluidized bed reactors, where solid particles are suspended by a gas flow. This promotes highly efficient gas-particle contact, resulting in high heat transfer, high chemical reaction rates and high product yields. Multiscale modelling has proven to be indispensable in the design and optimisation of fluidized bed reactors. Most coarse-grained models assume that the solid particles are of spherical shape because this simplifies the treatment of gas-solid drag and particle collisions. However, many particles used in fluidized bed (bio)reactors are non-spherical. This means that anisotropic collisions, anisotropic gas-solid drag, effects of local particle alignment, and alignment by nearby internal and external walls all need to be taken into account.
I propose to pioneer a multiscale simulation methodology, backed up by validating in-house experiments, for prediction of structure formation in gas-solid flows of inelastic non-spherical particles. As a first step we focus on elongated particles. The multiscale approach consists of: 1) fully resolved simulations to obtain closures for translational and rotational gas drag tensors in crowded environments and near external and internal walls, 2) Discrete Particle Model simulations to validate the drag closures with matching experiments and to obtain statistics of angular and linear velocity changes due to inter-particle collisions between groups of particles, 3) a novel Lagrangian method based on stochastic multi-particle collisions. The collision propagation rules make maximum use of conservation laws and local symmetries of the particle configuration, orientation and deformation rates. The coarse-grained model is amenable to a parcel approach and can be coupled with heat and mass transfer models, allowing for simulation of industrial scale reactors with non-spherical particles.</Summary><Max_ERC_funding>1,983,012</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="NSHOCK"><Rcn>185669</Rcn><Nid>10727</Nid><HI>Politecnico Di Milano, Italy</HI><Name>Non classical rarefaction shock-waves in molecularly complex vapours</Name><PI>Alberto Guardone</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>The expansion of a dilute gas through a gasdynamics convergent-divergent nozzle can occur in three different regimes, depending on the inlet and discharge conditions and on the gas: via a fully subsonic expansion, via a subsonic-supersonic or via a subsonic-supersonic-subsonic expansion embedding a compression shock wave within the divergent portion of the nozzle. I devised an exact solution procedure for computing nozzle flows of real gases, which allowed me to discover that in molecularly complex fluids eighteen additional different flow configurations are possible, each including multiple compression classical shocks as well as non classical rarefaction ones. Modern thermodynamic models indicate that these exotic regimes can possibly occur in nozzle flows of molecularly complex fluids such as hydrocarbons, siloxanes or perfluorocarbons operating close to the liquid-vapour saturation curve and critical point. The experimental observation of one only of these eighteen flow configurations would be sufficient to prove for the first time that non classical gasdynamics phenomena are indeed possible in the vapour region of a fluid with high molecular complexity
To this purpose, a modification to the blow-down wind tunnel for dense gases at Politecnico di Milano is proposed to use mixtures of siloxane fluids. Measurements are complemented by numerical simulations of the expected flow field and by state-of-the-art uncertainty quantification techniques. The distinctive feature of the proposed experiment is the adoption of mixture of siloxanes as working fluids. Mixtures of siloxanes are well known to exhibit an higher stability limit than their pure components, due to the redistribution process occurring at high temperature.
The increased understanding of real-gas dynamics will enable to improve the design of Organic Rankine Cycle Engines, to be used in  small scale energy production from biomasses, binary geothermal systems and concentrating solar thermal power plants.</Summary><Max_ERC_funding>1,485,600</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="NanoQuaNt"><Rcn>189836</Rcn><Nid>11814</Nid><HI>Technische Universitaet Wien, Austria</HI><Name>Nanofiber Quantum Networks</Name><PI>Arno Rauschenbeutel</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>We propose to establish nanofiber-based atom-light interfaces as quantum-enabled fiber-optical components for quantum information processing and communication (QIPC). The key ingredient of this interface is a nanofiber-based optical dipole trap which stores laser-cooled atoms in the evanescent field surrounding the nanofiber. In this evanescently coupled atom-waveguide-system, even a few hundred atoms are already optically dense for near-resonant photons propagating through the nanofiber. In combination with the proven good coherence properties of nanofiber-trapped atoms, these highly efficient light-matter interfaces are thus perfectly suited for the implementation of practical QIPC devices. More specifically, the first goal of this project is to realize quantum memories which allow one to directly store and retrieve the quantum state of fiber-guided photons. The efficiency of the retrieval process will highly benefit from the fact that conservation of energy and momentum stabilizes the emission of the stored light into the nanofiber-guided mode. Furthermore, nanofiber-coupled atomic ensembles can provide a strong optical non-linearity which, due to the waveguide-geometry, scales with the square root of the length of the sample and can be much larger than for freely propagating light beams. The second goal of this project is to explore and to maximize this non-linearity until it prevails down to the single photon level. This single-photon non-linearity would enable optical quantum switches and photon-photon quantum gates which are essential for implementing deterministic optical quantum computation. The final goal is then to interconnect these components in order to demonstrate three different fiber-optical quantum network applications: highly efficient photon counting using fiber-coupled quantum memories, highly efficient heralded entanglement of two fiber-coupled quantum memories, and a non-linear interaction between two single-photon pulses.</Summary><Max_ERC_funding>1,993,526</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="NanoSpin"><Rcn>111549</Rcn><Nid>10071</Nid><HI>Freie Universitaet Berlin, Germany</HI><Name>Nanoscale spin interactions and dynamics on superconducting surfaces</Name><PI>Katharina Jennifer Franke</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>The latest concepts for quantum computing and data storage envision the use of single spins, which can be addressed and manipulated reliably. One of the main limitations towards this challenging goal is the ultra-short lifetime of excited spin states due to the interaction with the contacting leads. Another limitation is that coherence between individual spins is quickly lost. Already the measurement process for resolving coherent electron-spin interactions at the single atom level is highly challenging and has not been achieved so far.
Within our proposal, we will construct a low-temperature scanning tunneling microscope with a radio-frequency current detection system and a microwave source close to the tip. With this unique machine, we will be able to carry out state-of-the-art STM experiments combined with atomic-scale precision of measuring electron-spin resonance signals. With the approach of measuring in the frequency domain, we increase our energy resolution beyond the thermal energy level broadening into the &#194;&#181;eV range and can thus investigate magnetic coupling, hyperfine interactions and spin coherence properties, which are not accessible in conventional STM experiments. We will also be able to probe the timescales of spin-lattice and spin-spin relaxations by pump-probe excitation schemes.
We will use this machine for resolving magnetic properties of single atoms and atomic-size nanostructures on superconducting substrates. These substrates exhibit two peculiarities, which are of crucial importance for quantum information processing. The spin lifetimes are orders of magnitudes larger than on normal metal surfaces. Furthermore, the long coherence length of Cooper pairs mediates coherent coupling of the spin states of paramagnetic atoms. We will manipulate the spin states by the intrinsic Josephson current as well as with external microwave radiation. Our model systems on superconductors will provide crucial steps towards quantum spin processing.</Summary><Max_ERC_funding>1,999,469</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="NanoSurfs"><Rcn>111426</Rcn><Nid>10094</Nid><HI>Technische Universitaet Muenchen, Germany</HI><Name>Nanostructured Surfaces: Molecular Functionality on advanced sp2-bonded substrates</Name><PI>Wilhelm Auw&#195;&#164;rter</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>Inspired by the diverse functionalities of complex molecular building blocks evidenced in manifold life processes as transport of respiratory gases, metabolism or light harvesting, we aim for a comprehensive characterization and control of molecular properties in surface-based model systems. To fully exploit and tune molecular functionality on substrates, a paradigm shift away from conventional metal supports, which might drastically affect adsorbates, is mandatory. We propose to apply nanostructured boron nitride (BN) monolayers and sp2-heterostructures as templates for molecular units and architectures. As indicated by the fascinating nanomesh interface and the electronically corrugated atomically thin BN sheet on Cu we recently reported, inert, temperature stable and insulating BN has a huge potential as advanced substrate supporting molecular functionality, self-ordering and intercalation.
By combining the inherent functionality of organic or bio-molecular building blocks with the unusual electronic and structural characteristics of  advanced sp2-bonded substrates grown by chemical vapour deposition, we aim to achieve desired properties, including electronic, magnetic and conformational switching, tunable reactivity, or tailored electronic band gaps. Special emphasis will be put on economic substrates as thin films or foils, which open perspectives for scalable processing.
With this proposal, we wish to establish research at the interface of surface science, supramolecular chemistry and materials engineering, yielding new insight into physicochemical processes at the single-molecule level, but also offering pathways to molecular sensors, switches, catalysts and devices, thus making a viable contribution to the on-going quest for innovation in nanotechnology. State-of-the-art scanning probe microscopy, a proposed new apparatus for the growth and handling of sp2-sheets and complementary X-ray based techniques will be used to tackle this ambitious project.</Summary><Max_ERC_funding>1,983,841</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="Naturale CG"><Rcn>185628</Rcn><Nid>12327</Nid><HI>Imperial College Of Science Technology And Medicine, United Kingdom</HI><Name>Engineering Bio-inspired Materials for Biosensing and Regenerative Medicine</Name><PI>Molly Stevens</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>In Naturale CG I propose transformative bioengineering approaches that will overcome severe limitations in current materials in two main areas, namely 1) Biosensing and 2) Regenerative Medicine. A key focus is on understanding and engineering the biomaterial interface using innovative designs and state of the art materials characterisation methods. Firstly I aim to transform the way that we can currently detect disease through innovations in the design and development of nanomaterials-based biosensors that could be used to detect a number of diseases with global implications, such as cancer, malaria, heart failure and tuberculosis. These innovations in biosensor design will involve both building on our existing highly successful work on plasmonic biosensors and also involve the design and development of completely new polymersome and fluorescent based biosensors. Another key aim of Naturale CG is to design first in kind biosensors for the facile detection of microRNAs. Secondly, the goal of regenerating failing organs before the body as a whole is ready to surrender, is now timelier than ever and one in which the design of new bio-inspired materials can play an important role. In Naturale CG I will build on my previous research in the design of 3-dimensional tissue engineering scaffolds and address an important new direction in the engineering of new bio-inspired conducting polymers as tissue engineering materials to promote cardiac tissue regeneration. First-in-field biomaterials-based innovations generated from this programme could enable far more effective regeneration of functional myocardial tissue which has been notoriously difficult to achieve thus far. Whilst I will lead this grant and the research within it, the proposed innovations are truly multidisciplinary in nature and will be accelerated towards clinical translation through the numerous clinical, scientific and industrial collaborations that I have established.</Summary><Max_ERC_funding>1,999,460</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="NearFieldAtto"><Rcn>111428</Rcn><Nid>11832</Nid><HI>Friedrich-Alexander-Universitaet Erlangen Nuernberg, Germany</HI><Name>Attosecond physics at nanoscale metal tips- strong field physics in the near-field optics regime</Name><PI>Jens Peter Hommelhoff</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>Electron dynamics in metals and nanostructures take place on attosecond timescales. Until today, these extremely fast processes are little understood let alone utilized. With NearFieldAtto, strong-field driven phenomena at nanoscale metal structures will be explored to elucidate collective electron dynamics and to induce optical-field-driven currents -- on attosecond timescales. We will investigate the near-field of a nanotip, resulting from the collective dynamics, both in amplitude and phase. Conversely, we will use the tip as a nanometric sensor to map out the electric field inside the focus of a pulsed laser beam and will directly measure the local phase. In two-tip and molecular junctions, we will explore the ultrafast steering of electronic currents by optical fields, both over a nanometric gap and inside a molecule, taking advantage of the large near-field enhancement the systems offer.

My group has recently shown that attosecond physics phenomena can be observed at solids, namely at nanoscale tips [Kr&#195;&#188;ger et al., Nature 2011]. Hence, in NearFieldAtto we will employ techniques well known from attosecond physics with isolated objects, like gas-phase atoms and molecules, to steer laser-emitted electrons with the electric field of few-cycle laser pulses. We will use these electrons as nanometric probes to investigate optical properties of the solid state system and compare the results with those of isolated objects in gas-phase measurements. With two tips facing each other, we will realize a nanometric junction over which we will steer electrons with the optical field. A molecule placed between two tips will enable the investigation of a novel, ultrafast switching mechanism.

NearFieldAtto will bring attosecond physics a leap forward as compared to the state-of-the-art, will introduce strong-field physics into (quantum-)plasmonics, and will open the door towards lightwave or petahertz nano-electronics in metallic and molecular nano-systems.</Summary><Max_ERC_funding>2,012,733</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="Neuro-Plasmonics"><Rcn>111602</Rcn><Nid>10054</Nid><HI>Fondazione Istituto Italiano Di Tecnologia, Italy</HI><Name>Neuro-Plasmonics</Name><PI>Francesco De Angelis</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>Research neuronal signaling is the subject of a very large community, but progresses face a dense multi-scale dynamics involving signaling at the molecular, cellular and large neuronal network levels. Whereas the brain capabilities are most likely emerging from large neuronal networks, available electrophysiological methods limit our access to single cells and typically provides only a fragmented observation, on limited spatial/temporal scales. Therefore, broadening the spectrum of scales for observing neuronal signaling within large neuronal networks is a major challenge that can revolutionize our capability of studying the brain and its physio-pathological functions, as well as of deriving bio-inspired concepts to implement artificial system based on neuronal circuits. We propose the development of an innovative electro-plasmonic multifunctional platform that by combining different methodologies emerging from distant fields of Science and Technology will provide a radically new path for real time neurointerfacing at different scale levels:
1. The molecular scale: 3D plasmonic nanoantennas will give access to information at molecular level by means of enhanced spectroscopies with particular regard of time resolved Raman scattering.
2. The single-neuron scale within neuronal networks: by both in-cell and extra-cell couplings with 3D nanostructures which work at the same time as plasmonic antennas and CMOS 3D nanoelectrodes.
3. The scale of large neuronal networks: by CMOS high-density electrode arrays for spatially and temporally resolving neuronal signaling form thousands of measuring sites.
This is achieved by exploiting an innovative nanofabrication method able to realize 3D nanostructures which can work at the same time as plasmonic nanoantennas and as nanoelectrodes. These structures will be integrated on CMOS multi-electrode arrays designed to manage multiscale measurements from the molecular level up to network level on several thousand of measurement sites.</Summary><Max_ERC_funding>1,388,000</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2018-03-31</End_date></Duration></Project><Project acronym="NoRaChem"><Rcn>185649</Rcn><Nid>11385</Nid><HI>Institut National De La Recherche Agronomique, France</HI><Name>Novel radical chemistry for complex peptide synthesis and engineering</Name><PI>Olivier Berteau</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>"Natural products are a constant source of inspiration in chemistry and have played a key role in the development of medicine. Recently, thanks to the progress in genomics and metagenomics, it has appeared that the biosynthetic potential of microorganisms and the complexity of the reactions catalyzed have been largely underestimated. Notably, enzymes using radical-based chemistry have been shown to be present in a very-large amount of biosynthetic pathways and to be widely distributed among all living organisms. The highly reactive radical species they generate give access to chemistries not accessible otherwise and allow them to catalyze unique and diverse reactions. Among them, the so-called ""radical SAM enzymes"" have attracted considerable attention in recent years. While, initially hypothesized to be a family with several hundreds of members, recent genomic analyses have revealed that there are several tens of thousands of radical SAM enzymes catalyzing more than sixty distinct biochemical processes.

Very recently, an ever increasing number of radical SAM enzymes has been discovered in the biosynthetic pathways of natural compounds. In several cases, it has been shown that, instead of involving non-ribosomal or polyketide synthases, microorganisms use radical SAM enzymes to extensively modify ribosomally synthesized peptides producing highly complex bioactive molecules. In the present project, we propose to develop a multidisciplinary approach to investigate promising radical SAM enzymes catalyzing peptide modifications and elucidate their unique mechanisms which, in many cases, have no counterparts in biochemistry and synthetic chemistry. Based on the unique and highly conserved radical SAM domain and the mechanistic insights gained, we will develop novel radical SAM enzymes as catalysts for the synthesis of new chemicals with original structures and properties using a synthetic biology approach."</Summary><Max_ERC_funding>1,984,218</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="NuMass"><Rcn>111579</Rcn><Nid>11822</Nid><HI>University Of Durham, United Kingdom</HI><Name>Neutrinos: a different portal to new physics Beyond the Standard Model</Name><PI>Silvia Pascoli</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>In the past fifteen years, neutrino physics has revolutionised our understanding of particle physics. The discovery of neutrino oscillations implies that neutrinos have masses and mix: this is the only particle physics evidence of new physics beyond the Standard Model to date. Their origin remains a major challenge.

The NuMass project will focus on new physics at low energy scales, below the one reachable at the LHC. This approach is opposite to widely studied Standard Model extensions, which invoke new physics at scales so high that they will never be tested directly, and orthogonal to TeV models accessible at the LHC. The NuMass idea is that new particles in Nature could be hidden away not because they are too heavy but because, although light, they interact too weakly with ordinary matter. Neutrinos are by far the least understood of the standard fermions: if new particles are indeed at low scales, below the electroweak one, a likely scenario is that they couple more strongly to neutrinos than to other standard particles, e.g. quarks. Therefore, neutrinos are a unique portal into low energy physics.

The NuMass project will adopt a unique approach combining particle theory, phenomenology and cosmology. It will propose low energy extensions of the Standard Model and embed them in a consistent theory. It will study their signatures in experiments and their impact in the Early Universe. It will exploit the wide experimental programme, e.g. T2K, MicroBooNE, NOvA, GERDA, which will provide new data in the near future, to constrain the properties of the models.

The NuMass ultimate goal is to unveil a new theory of particles and interactions at low energy: its success would be groundbreaking as it would open a completely new perspective on the fundamental laws of Nature. New theoretical challenges would arise to explain why the new sector is light, and new experimental ones to test the new particles and interactions, leading to new directions in particle physics.</Summary><Max_ERC_funding>1,702,663</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="O2SENSE"><Rcn>189838</Rcn><Nid>10801</Nid><HI>University Of Bath, United Kingdom</HI><Name>Oxygen Sensing with Multimodality Imaging Probes</Name><PI>Sofia Ioana Pascu</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"This programme will employ physical sciences and biomedicine techniques to develop a revolutionary approach to early cancer diagnosis and post-treatment monitoring aiming to address shortcomings in our current technology in oxygen sensing and imaging of hypoxic prostate tumours.

This proposal represents a gearing process towards the biomedical implementation of metal complexes and functionalised nanoparticles as novel synthetic platform systems for personalised diagnosis and treatment of diseases such as cancer and which can also be extended to neurodegenerative disorders. The work programme is a meeting point for interdisciplinary science that goes well beyond  state of the art. New chemical sensing devices will outstrip and supersede existing biopsy and imaging techniques used in diagnosis and treatment of diseases such as cancers.

The key advances of this programme will be:

(a) &#226;&#128;&#152;smart&#226;&#128;&#153; all-in-one multimodal imaging probes, whose sensitivities to levels of oxygen in cells (pO2) will be tunable to respond to various levels of hypoxia in tumors as desired. Our ultra-sensitive probes will be effective at low O2 concentrations and respond to reduced levels of hypoxia and under anoxia. This will surpass the mainstay in cancer diagnosis and therapy and provide increased selectivity for a wider range of tumours.

(b) new probes suitable for interlocked Positron Emission Tomography (PET), Single Photon Emission Tomography (SPECT), and optical imaging methodologies  Simultaneous in vitro and in vivo diagnostic information from radioimaging techniques (PET, SPECT) and optical imaging will provide in depth understanding of biological processes and lead to personalised medicine.

(c) new imaging tools for the first time will monitor the cellular biolocalisation of these probes by multiphoton optical imaging in nearIR regimes. These will drive the development of time-gated microscopy and multi-photon imaging with sensitivity for various levels of tumour hypoxia."</Summary><Max_ERC_funding>1,886,876</Max_ERC_funding><Duration><Start_date> 2014-09-01, </Start_date><End_date> 2019-08-31</End_date></Duration></Project><Project acronym="OutflowMagn"><Rcn>111406</Rcn><Nid>10097</Nid><HI>Chalmers Tekniska Hoegskola Ab, Sweden</HI><Name>Magnetic fields and the outflows during the formation and evolution of stars</Name><PI>Wouter Henricus Theodorus Vlemmings</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>The outflows of young and old stars play a crucial role in the cycle of matter in galaxies.  Stars and planetary systems are formed through complex physical processes during the collapse of gas clouds with outflows a required ingredient. At the end of a stars life, stellar outflows are the main source of heavy elements that are essential for the formation of stars, planets and life. Magnetic fields are one of the key factors governing the in particular the often observed collimated outflow. They might also be a key ingredient in driving stellar mass loss and are potentially essential for stabilizing accretion disks of, in particular, massive proto-stars. Only polarization observations at different spatial scales are able to measure the strength and structure of magnetic fields during the launching of outflows from young and old stars. Because stars in these evolutionary phases are highly obscured by dusty envelopes, their magnetic fields are best probed through observations of molecules and dust at submillimeter and radio wavelengths. In addition to its role, the origin of the magnetic field in these stellar phases is also still unknown and to determine it multi-wavelength observations are essential. The proposed research group will use state of the art submillimeter and radio instruments, integrated with self-consistent radiative transfer and magneto-hydrodynamic models, to examine the role and origin of magnetic fields during star formation and in the outflows from evolved stars. The group will search for planets around evolved stars to answer the elusive question on the origin of their magnetic field and determine the connection between the galactic magnetic field and that responsible for the formation of jets and potentially disks around young proto-stars. This fundamental new work, for which a dedicated research group is essential, will reveal the importance of magnetism during star formation as well as in driving and shaping the mass loss of evolved stars.</Summary><Max_ERC_funding>2,000,000</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="PALEOGENIE"><Rcn>111603</Rcn><Nid>10055</Nid><HI>University Of Bristol, United Kingdom</HI><Name>PAst Links in the Evolution of Ocean&#226;&#128;&#153;s Global ENvIronment and Ecology</Name><PI>Andrew John Ridgwell</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>"Species do not live in isolation, but adapt and ultimately, evolve, in relationship with other species as well as with their chemical and physical environment. In the marine environment, this interaction is intimately two-way &#226;&#128;&#147; the surface biogeochemical environment modulates the makeup of the pelagic ecosystem, yet at the same time, the ecosystem assemblage, by setting the strength of the biological pump and ultimately, in regulating the carbon and nutrient inventory of the ocean and atmospheric pCO2, influences the surface geochemical environment. Feedbacks, both negative and positive, must therefore exist between plankton ecology and global biogeochemical cycles. This has implications for understanding the geological record and particularly the response and recovery of marine ecosystems following major environmental perturbation, but also complicates making projections of future ocean changes.
The proposed project &#226;&#128;&#147; PALEOGENiE &#226;&#128;&#147; will directly address these challenges via the development of a unique coupled model of past plankton ecology and global biogeochemical cycles. The geological record of planktic ecosystems &#226;&#128;&#147; nannofossils &#226;&#128;&#147; will be collated and analyzed across a spectrum of geological events for which evidence of major changes in climate and massive carbon release together with the response of planktic ecosystems are recorded: the Paleocene-Eocene Thermal Maximum, the end Cretaceous, and Ocean Anoxic Event 2. Both model and data will then be brought together in a unique attempt to better understanding the micropaleontological record of how sensitive marine ecosystems are to global change as well as how they recover. If successful, PALEOGENiE may help constrain the potential for adaptation as well as rates of evolutionary change, and ultimately could lead to meaningful insights and guidance for the next generation of Earth system models we need to better constrain the future response of marine ecosystems to continued fossil fuel combustion."</Summary><Max_ERC_funding>1,930,472</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="PHOENiCS"><Rcn>189857</Rcn><Nid>11799</Nid><HI>The Chancellor, Masters And Scholars Of The University Of Cambridge, United Kingdom</HI><Name>Photon-Spin Entanglement in Hybrid Cluster State Architectures</Name><PI>Mete Atature</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>The last decade has witnessed quantum mechanics and information science merge for the debut of experimental quantum information processing. Despite the number of promising physical systems as candidates for quantum bits, scalability via a brute force approach faces serious technical obstacles. Developing distributed quantum networks is possibly the answer to the stringent demand of controllable interaction between high quality qubits. In these systems, the requirements are on the stationary qubits &#226;&#128;&#147; they need to be both isolated and accessible. The requirements on the flying qubits are that they need to be of reproducibly high quality, identical, and also they need to be able to interface well with the stationary qubits. We propose to realize an operational distributed solid-state quantum network relying on confined spins in quantum dots as qubits connected via a shared optical interconnection net used via single photons as flying qubits. Key milestones include high fidelity distant spin entanglement generation, implementation of spin entanglement purification, and formation of spin-photon hybrid cluster states in order to perform  one-way quantum computation protocols with incorporated memory. Significant efforts will be devoted in tandem for the grand challenge of efficient in/out coupling of light in these systems with initial investigations suggest efficiencies approaching unity can be achieved within the proposed timeline.</Summary><Max_ERC_funding>1,739,499</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="POTENT"><Rcn>189831</Rcn><Nid>11908</Nid><HI>Fondazione Istituto Italiano Di Tecnologia, Italy</HI><Name>Engineering Discoidal Polymeric Nanoconstructs for the Multi-Physics Treatment of Brain Tumors</Name><PI>Paolo Decuzzi</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"Despite significant advances in chemotherapy, the effective treatment of malignant masses via systemically injectable agents are still limited by insufficient accumulation at the biological target (</Summary><Max_ERC_funding>2,390,000</Max_ERC_funding><Duration><Start_date /></Duration></Project><Project /><Project acronym="PRIME"><Rcn>111348</Rcn><Nid>10099</Nid><HI>Technion - Israel Institute Of Technology, Israel</HI><Name>Programming with Millions of Examples</Name><PI>Eran Yahav</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"The goal of this proposal is to make programming easier and more productive. We propose to develop novel program synthesis techniques, generating procedural code from declarative specifications.
Existing techniques apply synthesis at such a fine grain that they can never hope to generate code of the richness and complexity required by application-level programmers. In contrast, we aim to develop synthesis algorithms that leverage the collective programming knowledge captured in millions of open-source projects.
By using existing code fragments as components for synthesis, we enable synthesis to work at a higher-level of abstraction and synthesize realistic programs. Our approach represents a conceptual leap as it reduces the problem of generating code to the problem of checking whether existing code (or a combination of existing code fragments) is an appropriate solution. In some cases, this reduces the problem of synthesis to a problem of semantic code search. In other cases, it reduces the problem of synthesis over fine-grained components to synthesis as composition of coarse-grained components. The key problems are how to specify the desired behavior, how to find useful code fragments in the vast existing body of software, and the how to use synthesis to modify and assemble these fragments to form a program.

Our approach combines insights and techniques from research on program analysis, program synthesis, software engineering, and machine learning. The outcome of the project will be new research directions."</Summary><Max_ERC_funding>1,500,000</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="ProtCage"><Rcn>185643</Rcn><Nid>12322</Nid><HI>Universiteit Twente, Netherlands</HI><Name>Chemistry in the Confinement of Protein Cages</Name><PI>Jeroen Johannes Lambertus Maria Cornelissen</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>Protein cages appear to be common structures in biology, found in viruses but also in organelle-like containers discovered in bacteria. In this proposed program I aim to study chemical processes in nano-sized protein cages as mimics of bacterial organelles and to increase the general understanding of chemistry in confinement.
Towards this goal we will investigate the controlled in vivo loading of bacterial protein cages, i.e. encapsulins, with proteins and enzymes. This will allow us to study in detail the chemical conversions that take place inside such capsules and it will increase understanding about the reasons why certain processes inside these simple organisms are encased in the protein organelles.
Completely artificial protein organelles will be constructed by in vitro processes using the well-studied Cowpea Chlorotic Mottle virus cage. By employing DNA technology, cages will be loaded with a single enzyme, a sequence of enzymes or molecular probes. By obtaining this high level of control, we can not only study chemical conversions on the inside, but it will also allow us to monitor the physiochemical properties, such as internal pH, polarity and porosity of the protein mantle by encasing the relevant probes or host/guest systems.
In the ultimate stage of the proposed project the formed artificial organelles will be brought into cells in order to interact with the cell metabolism. CCMV has to be introduced by surface modification, while encapsulins can be formed inside these cells; albeit with different cargo. Such experiments have, to my knowledge, not been carried out and introducing new reactions inside these organisms can lead to new potentially interesting products or interfere with cell vitality. The latter can be of importance for the controlled disruption of bacterial cells.</Summary><Max_ERC_funding>1,994,400</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="QITBOX"><Rcn>111554</Rcn><Nid>11826</Nid><HI>Fundacio Institut De Ciencies Fotoniques, Spain</HI><Name>Quantum Information Theory with black BOXes</Name><PI>Antonio Ac&#195;&#173;n</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"With QITBOX we aim to develop a novel device-independent framework for quantum information processing. In this framework, devices are seen as black boxes that only receive inputs and produce outputs. Our main objective is to understand what can and cannot be done for information processing using only the observed correlations among the devices. We will structure our effort along three main research lines: (i) Characterization of quantum correlations: the general objective will be to characterize those correlations that are possible among quantum devices; (ii) Protocols based on correlations: the general objective will be to understand how quantum correlations can be exploited in order to construct relevant information protocols and (iii) Applications to physical setups: here the previous results to concrete physical setups will be applied, such as the quantum-optical realizations of the protocols or the study of the non-local properties of many-body systems. The expected results of QITBOX are: (i) Novel methods for the characterization of quantum correlations, (ii) Improved or novel device-independent protocols, (iii) Proposals for feasible experimental implementations of these protocols and (iv) Novel methods for the study of many-body systems based on correlations. QITBOX is a highly-interdisciplinary project with implications in Physics, Mathematics, Computer Science and Engineering. The execution of the planned research work will provide a unifying framework for a Quantum Information Theory with black BOXes (hence the acronym). Such a framework will bring quantum information processing to an unprecedented level of abstraction, in which information protocols and primitives are defined without any reference to the internal physical working of the devices. This, in turn, will lead to much more robust practical implementations of quantum information protocols, closing the mismatch between theoretical requirements and experimental realisations."</Summary><Max_ERC_funding>1,487,505</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="QPROGRESS"><Rcn>185587</Rcn><Nid>11988</Nid><HI>Stichting Centrum Voor Wiskunde En Informatica, Netherlands</HI><Name>"Progress in quantum computing: Algorithms, communication, and applications"</Name><PI>Ronald De Wolf</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"Quantum computing combines computer science, physics and mathematics to fundamentally speed up computation using effects from quantum physics. Starting in the early 1980s with Feynman and Deutsch, and gaining momentum in the 1990s with the algorithms of Shor and Grover, this very interdisciplinary area has potentially far reaching consequences. While a large-scale quantum computer has not been built yet, experimenters are getting more optimistic: a recent prediction is that it will take another 10-15 years.

However, the tasks where such a quantum computer would be able to significantly outperform classical computers are still quite limited, which lends urgency to finding new applications. This proposal will find more such tasks, and produce new insights into the strengths and weaknesses of quantum computing. It is divided into three workpackages:

1. Algorithms &amp; complexity. Find new quantum algorithms that are more efficient than the best classical algorithms, for example for matrix multiplication and graph problems. Extend our knowledge of the ultimate limitations of quantum algorithms, and possible parallelization (which has barely been studied so far).

2. Quantum communication. Communication complexity analyzes the amount of communication needed to solve distributed computational tasks, where separate parties each hold part of the input. Find new
distributed problems where quantum communication outperforms classical communication, and explore links with fundamental physics issues like the role of entanglement and Bell-inequality violations.

3. Classical applications. Apply the newly developed mathematical tools of quantum computing to analyze problems in other areas, as we recently did for linear programs for the traveling salesman problem. This
third workpackage will have impact regardless of progress in building a quantum computer.

The PI is one of the world&#226;&#128;&#153;s top researchers in each of these three areas."</Summary><Max_ERC_funding>1,453,700</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="QUCC"><Rcn>111489</Rcn><Nid>11946</Nid><HI>Weizmann Institute Of Science, Israel</HI><Name>Chemistry of the Quantum Kind</Name><PI>Edvardas Narevicius</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>There has been a long-standing quest to observe chemical reactions at low temperatures where reaction rates and pathways are governed by quantum mechanical effects. So far this field of Quantum Chemistry has been dominated by theory. The difficulty has been to realize in the laboratory low enough collisional velocities between neutral reactants, such that the quantum wave nature could be observed. Recently we have demonstrated a new way of studying cold reactive collisions by magnetically merging two fast neutral supersonic beams. After 40 years where the reactive scattering temperature was limited to above 5 K we were able to continuously tune collision energies from hundreds of Kelvin down to 10 mK temperature, a reduction of almost three orders of magnitude [A. B. Henson et. al, Science 338, 234, 2012]. Importantly, we were able to show that at low temperatures quantum effects start dominating reactive dynamics with the first observation of orbiting resonances in a reactive collision. We propose to extend our novel method to study chemical reactions in the regime of Cold Chemistry where the reactants&#226;&#128;&#153;s de Broglie wavelength becomes larger compared to the characteristic interaction range. Theoretical predictions at low temperatures are extremely sensitive to the parameters used, routinely differing by orders of magnitude leading to contradictions waiting to be settled by experiment.
Our ability to reach low enough collision energies and resolve scattering resonances will be used to bring a radical change to transient species spectroscopy. We believe that our work will not only test the central tenets of Quantum Chemistry, but will also provide valuable information to other fields, such as Astrochemistry helping to understand the synthesis of various molecules in interstellar space at temperatures 10 K and below.</Summary><Max_ERC_funding>1,982,908</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="QuantStro"><Rcn>185575</Rcn><Nid>12010</Nid><HI>Universiteit Van Amsterdam, Netherlands</HI><Name>Quantum-Degenerate Strontium: Mixtures, Molecules, and Many-Body Physics</Name><PI>Florian Schreck</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>In 2009 my research team created the first Bose-Einstein condensate of strontium. This breakthrough is the foundation of my research program, which will investigate quantum many-body phenomena with a focus on quantum magnetism and physics related to the quantum Hall effect. We are especially interested in studying unusual, strongly correlated quantum states, among them states with topological order.

The unique properties of strontium make it ideally suited to follow four different approaches to this physics.

1) We will immerse our quantum gas into artificial gauge fields, which e.g. let neutral atoms behave as if they were charged particles in a strong magnetic field. These fields will allow us to study quantum Hall states or topological insulators.

2) We will study SU(N) magnetism, which is an unusual form of magnetism not found in condensed matter, but of high interest for theory. A high degree of frustration can lead to spin liquid behaviour.

3) We will use sympathetic Pomeranchuk cooling of a potassium spin mixture by fermionic strontium to reach low entropy quantum phases. Our goal is to study magnetically ordered states and frustrated antiferromagnetism.

4) We will create RbSr ground-state molecules, which are polar, open-shell molecules. They will allow us to engineer unique quantum-many body systems with long-range interactions, e.g. lattice-spin models that can support topological states.

We will pursue this research not only on our existing Rb/Sr quantum gas mixture apparatus, but we will construct a new K/Sr quantum gas microscope. This machine will be very valuable to explore exotic quantum states. The properties of strontium will enable an innovative single-atom detection method based on shelving in a metastable state and quench cooling, which will allow us to take internal state-resolved, 3D, or super-resolution images of the lattice gas.</Summary><Max_ERC_funding>1,799,148</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="REINS"><Rcn>192408</Rcn><Nid>13474</Nid><HI>Universiteit Utrecht, Netherlands</HI><Name>Responsible Intelligent Systems</Name><PI>Johannes Maria Broersen</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>I propose to develop a formal framework for automating responsibility, liability and risk checking for intelligent systems. The computational checking mechanisms have models of an intelligent system, an environment and a normative system (e.g., a system of law) as inputs; the outputs are answers to decision problems concerning responsibilities, liabilities and risks. The goal is to answer three central questions, corresponding to three sub-projects of the proposal: (1) What are suitable formal logical representation formalisms for knowledge of agentive responsibility in action, interaction and joint action? (2) How can we formally reason about the evaluation of grades of responsibility and risks relative to normative systems? (3) How can we perform computational checks of responsibilities in complex intelligent systems interacting with human agents? To answer the first two questions, we will design logical specification languages for collective responsibilities and for probability-based graded responsibilities, relative to normative systems. To answer the third question, we will design suitable translations to related logical formalisms, for which optimized model checkers and theorem provers exist. Success of the project will hinge on combining insights from three disciplines: philosophy, legal theory and computer science.</Summary><Max_ERC_funding>1,968,057</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="RIGIDITY"><Rcn>188647</Rcn><Nid>11363</Nid><HI>Katholieke Universiteit Leuven, Belgium</HI><Name>Rigidity and classification of von Neumann algebras</Name><PI>Stefaan Vaes</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>"Sorin Popa's deformation/rigidity theory has lead to an enormous progress in our understanding of von Neumann algebras coming from discrete groups and their actions on probability spaces. In a five year long collaboration with Sorin Popa, we solved many long-standing open problems in this area, including superrigidity theorems for group measure space II_1 factors, results on the possible fundamental groups of II_1 factors, and uniqueness theorems for Cartan subalgebras.

In the first part of the project, we want to establish new unique Cartan decomposition theorems for II_1 factors coming from hitherto intractable groups. Using methods coming from Lie groups, ergodic theory and geometric group theory, we want to reach such results for lattices in higher rank simple Lie groups, and for countable groups with nonvanishing L^2-Betti numbers. An important intermediate step will be the unique Cartan decomposition of Bernoulli crossed products.

Secondly we want to prove classification theorems for type III factors that are equally strong as the existing results for the type II_1 case. This includes a complete classification of the noncommutative Bernoulli shifts of the free groups and will require an intricate combination of Tomita/Takesaki and deformation/rigidity theory.

The methods developed so far bring within reach an attack on two of the most important open problems in operator algebras and functional analysis: the free group factor problem and Connes's rigidity conjecture. The exact progress on these problems is of course unforeseeable, but it is sure that the research on these problems will lead to an even deeper interaction between diverse areas of mathematics as operator algebras, group theory, functional analysis, ergodic theory, and descriptive set theory. Intermediate goals are the classification of natural classes of group von Neumann algebras, including those coming from Baumslag-Solitar groups, wreath product groups, and other families of discrete groups."</Summary><Max_ERC_funding>1,446,660</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="SCALPEL"><Rcn>192338</Rcn><Nid>13450</Nid><HI>Interuniversitair Micro-Electronicacentrum Imec Vzw, Belgium</HI><Name>A Single Cell AnaLysis and Sorting Platform based on Lensfree digital imaging techniques applied to Rapid Detection of Cancer</Name><PI>Liesbet Lagae</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"Metastasis is responsible for &gt; 90% of cancer-related deaths. Billions of dollars have been spent trying to cure primary tumors but very little was spent in trying to detect or kill the highly aggressive tumor cells that cause disease spreading.  One of the reasons is that single cell studies of rare cells in blood still present a large challenge.  Single cell analysis remains tedious with many different instruments and protocols, typically taking a few days of hands-on work.  This slows down research, but also hinders the translation to application in future clinical practice.  In SCALPEL, we envisage a high-content, high-throughput cell imaging and sorting platform, more compact and easier to use than any existing single cell analyzer.   The high content results from lensfree digital imaging of single cells on a high speed CMOS active optical pixel matrix to analyze the morphology of cells.  The high throughput results from a highly parallelized fluidic matrix that steers cells at high speed over the CMOS imaging blocks.  Lensfree cell sorters can be realized in a cheap and compact platform, as all optomechanical components (lenses, detectors, nozzles,...) are replaced by nanoelectronics, advanced imaging and signal processing technology.

SCALPEL aims to perform a full feasibility study of this concept and will require to investigate the ultimate limits in:  1) maximizing image resolution and sensitivity to single cell morphological features obtained via lensfree holographic imaging; 2) maximizing cell manipulation speed in microfluidic systems via a high degree of parallelization; and 3) digital image signal processing with extremely low latency at reasonable power consumption. If this multidisciplinary complexity can be understood, we will have built the components for different versions of compact cytometers that can be used at hand of pathologist, surgeons, and nurses for improving the individualized follow-up and survival rate of cancer patients."</Summary><Max_ERC_funding>1,999,840</Max_ERC_funding><Duration><Start_date> 2014-11-01, </Start_date><End_date> 2019-10-31</End_date></Duration></Project><Project acronym="SCION"><Rcn>111378</Rcn><Nid>11834</Nid><HI>Eidgenoessische Technische Hochschule Zuerich, Switzerland</HI><Name>"Scalability, Control, Isolation on Next-generation Networks"</Name><PI>Adrian Markus Perrig</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"The Internet has been successful beyond even the most optimistic expectations. It permeates and is intertwined with almost all aspects of our government, economy, and society.

From a security perspective, we observe is the tremendous dependency on communication that is being created. Many of the processes we describe above would grind to a halt should communication become unavailable. Although we cannot conclusively
answer what the impact of a 1-minute, 1-hour, 1-day, or 1-week lack of Internet communication on our society would be, but anecdotal evidence
indicates that even short outages have a profound negative impact on governmental, economic, and societal processes. We can only surmise
what the impact of a week-long Internet outage would look like after witnessing the almost complete halt in productivity of a major institution that lost email connectivity for 2 days.

Unfortunately, the current Internet is quite brittle, and has not been designed for high availability in the face of malicious adversaries. Recent patches to
improve Internet security and availability have been constrained by the current Internet architecture and business processes.
Consequently, the current state of safety and availability of the Internet is not commensurate with its importance. Numerous aspects of our society depend on a brittle network that runs with a relatively
small investment compared to its importance.

The goal of this project is to follow a methodological scientific approach to design, analyze, and implement a prototype of a next-generation Internet that is secure, available, and private by design, that provides appropriate incentives for a transition to the new architecture, and that considers economic and policy issues at the design stage."</Summary><Max_ERC_funding>1,889,684</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="SCPs"><Rcn>185577</Rcn><Nid>11512</Nid><HI>The University Of Warwick, United Kingdom</HI><Name>Developing sequence controlled polymers for organization, templation and recognition</Name><PI>Rachel Kerry O'reilly</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>Nature&#226;&#128;&#152;s toolbox for replication uses DNA and RNA which are nucleic acids capable of templating new copies of themselves. Nature&#226;&#128;&#152;s ability to replicate has led to the evolution of a wide variety of forms and functions for biological materials which cannot be achieved using current synthetic approaches. It seems likely that if we were able to teach plastics or other polymers how to template new copies of themselves that we would similarly be able to make new, impossible materials and hence further expand the potential function and properties of these materials. These new materials would provide enhanced properties and function (such as replication and evolution) that are not currently available to material chemists. This would allow for a best-of-both-worlds scenario with the development of robust synthetic materials, with tuneable properties including crystallinity, thermal properties, shape memory, and self-healing. Most importantly, by developing an empirical and perhaps even model-based connection between polymer sequence / composition and polymer properties it would be possible to begin to design new materials in a rational and knowledge-based way. Indeed, it could be argued that this advance would ultimately solve one of the major problems in materials science, multiscale modelling of polymer properties. It seems certain that achieving even a portion of these goals would open up a completely new area of material science. Hence, following the model of DNA, we propose developing a number of new routes for the preparation of sequence controlled polymers (SCPs) and specifically a new class of SCPs which are capable of replication and ultimately evolution. This will produce polymers and self-assembled structures with unprecedented physical properties and the ability to functionally interact and communicate with biological materials. Realizing this goal will allow us to bring new function to chemistry, through expanding chemical space to access new precision polymers</Summary><Max_ERC_funding>2,324,271</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2020-01-31</End_date></Duration></Project><Project acronym="SEARCHLIGHT"><Rcn>185672</Rcn><Nid>10725</Nid><HI>Fundacion Imdea Networks, Spain</HI><Name>A new communication paradigm for future very high speed wireless networks</Name><PI>Joerg Carsten Widmer</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"Due to the tremendous growth in mobile devices such as smartphones, tablet PCs, and laptops over the past years, a larger and larger fraction of Internet traffic is delivered wirelessly. Dealing with this vast increase in traffic is one of the most important challenges for future wireless networks. State-of-the-art wireless communication already operates close to Shannon capacity. The only viable option to further increase data rates is to use high bandwidth channels in the very high frequency part of the radio spectrum. However, this spectrum suffers from high attenuation and signal absorption, restricting communication primarily to line-of-sight (LOS) scenarios. This in turn requires a radical rethinking of wireless networking. We envision that future wireless networks will consist of many highly directional LOS channels for communication between access points (APs) and end devices. Such an environment is extremely dynamic, in particular for mobile devices. At the same time, such channels experience very little interference and resources that would otherwise be used to handle interference can now be used to further increase achievable data rates.

We propose to build a wireless network architecture that maintains directional LOS channels between several APs and (mobile) end devices. Data is transmitted via all of these channels and end device uses multiple antennas to receive and decode several such data streams simultaneously. The main complexity of the design lies in the selection of APs as well as the beamforming directions of their antennas, given the large number of end devices that future wireless networks will have to support. To speed up this decision process, the system maintains a map of the radio environment and learns likely sequences of beamforming patterns and APs. This further allows to intelligently switch off APs to improve energy efficiency. We believe that such a design is the key element for the scalability of future wireless networks."</Summary><Max_ERC_funding>1,719,960</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="SLIDEQUAKE"><Rcn>111555</Rcn><Nid>11825</Nid><HI>Institut De Physique Du Globe De Paris, France</HI><Name>Detection and understanding of landslides by observing and modelling gravitational flows and generated earthquakes</Name><PI>Anne Mangeney</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>The goal of the project is to take a major step in improving the detection and understanding of landslides and their modelling at the field scale through the analysis of generated seismic waves. The seismic signal generated by landslides (i. e. landquakes) provides a unique tool to estimate the properties of the flow and its dynamics. Indeed, the stress applied by the landslide to the ground, which generates seismic waves, is highly sensitive to the flow history and therefore to the physical properties during mass emplacement. The strategy will be to combine a very accurate description of the landslide source, and the simulation and measurements of landquakes from the laboratory to the natural scale, by leading an ambitious interdisciplinary project involving numerical modelling, laboratory experiments and observation. The methodology will be to (1) develop thin layer models for granular flows over a complex 3D topography to alleviate the high computational costs related to the description of the real topography, taking into account the static/flowing transition and the fluid/grains mixture, both playing a key role in natural flows; (2) simulate the generated seismic waves by coupling landslide models to state-of-the-art wave propagation models. An ambitious objective will be to develop efficient coupling methods; (3) develop laboratory experiments of seismic emissions generated by granular flows to test the models and understand the physical processes at work; (4) analyse, simulate and invert natural landquakes making use of underexploited high-quality seismic and geomorphological data, in particular on volcanoes.
An ultimate objective will be to design a new generation of landslides models, reliable methods and operational tools for detection of gravitational flows, and interpretation of seismic data in terms of landslide properties. This tools will be transferred to the scientific community and to the observatories in charge of monitoring landslide activity.</Summary><Max_ERC_funding>1,999,241</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="SPCND"><Rcn>185612</Rcn><Nid>10738</Nid><HI>University Of Southampton, United Kingdom</HI><Name>Supernovae: Physics and Cosmology in the Next Decade</Name><PI>Mark Sullivan</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"Exploding stars, or supernovae, impact upon many diverse areas of astrophysics, from galaxy formation, to stellar evolution, to cosmology and studies of dark energy. I am playing a leading role in new, wide-field, high-cadence optical surveys that are revolutionising the study of supernovae, searching vast volumes of space, locating hundreds of events to study their demographics in detail, and uncovering new and bizarre types of explosions. In concert with a major European Southern Observatory public spectroscopic survey, PESSTO, these imaging surveys will provide an extraordinary dataset for understanding all facets of the supernova and explosive transient population. My work will perform several tests of the progenitors and physics of the classical type Ia supernovae in an attempt to understand how these crucial standard candles depend on their progenitor stellar populations. I will use these results to inform a new generation of models of type Ia supernovae. I will this distill these results to make a detailed measurement of the dark energy that powers the accelerating universe in which we live, greatly improving upon existing measurements of the variation of dark energy over the last ten billion years. A final aspect of my research is an innovative search for superluminous supernovae: a new class of supernova explosion a hundred times brighter than traditional supernovae, capable of being studied in the very distant universe. These objects may become cosmology's new standard candle, visible far beyond the reach of type Ia supernovae. My new search will significantly increase both the quantity and quality of superluminous supernova observations, allowing us to further our understanding of these enigmatic objects and use them in a cosmological setting for the first time."</Summary><Max_ERC_funding>1,970,745</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="SPIN"><Rcn>185591</Rcn><Nid>12007</Nid><HI>University Of Durham, United Kingdom</HI><Name>Symmetry Principles in Nature</Name><PI>Mukund Rangamani</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>Symmetries have traditionally played a very important role in our understanding of physics, both classical and quantum. As we move towards the next frontier of defining a quantum theory of gravity, it is clear that they will continue to play a predominant role. The current project is aimed at obtaining a comprehensive  understanding of the dynamics of strongly coupled quantum systems, exploiting various symmetry properties that one expects on physical grounds. Specifically, the aim is to come up with effective descriptions of a wide class of quantum dynamics in gravitational and non-gravitational theories using the holographic gauge/gravity correspondence.

One of the primary strands of the proposed research involves a critical examination of gravitational theories with higher spin symmetry. We will investigate the phase structure of such theories, the nature of gravitational solutions and notions of classical geometry in the presence of the enlarged gauge symmetry. Using appropriate generalizations of the gauge/gravity correspondence we will try to give gauge invariant characterizations of these concepts and further explore how such higher spin theories can be realized in string theory. A related strand of research concerns a deeper understanding of the gauge/gravity correspondence itself,  with focus on figuring out how collective behaviour of strongly coupled field theories leads to the emergence of extra symmetries, such as local diffeomorphisms in the dual description. Along the way we will also develop effective descriptions for collective dynamics of strongly coupled quantum degrees of freedom, both in and out of equilibrium.</Summary><Max_ERC_funding>1,400,758</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="SSS"><Rcn>185547</Rcn><Nid>11972</Nid><HI>It University Of Copenhagen, Denmark</HI><Name>Scalable Similarity Search</Name><PI>Rasmus Pagh</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>"Similarity search is the task of identifying, in a collection of items, the ones that are &#226;&#128;&#156;similar&#226;&#128;&#157; to a given
query item. This task has a range of important applications (e.g. in information retrieval, pattern
recognition, statistics, and machine learning) where data sets are often big, high dimensional, and
possibly noisy. State-of-the-art methods for similarity search offer only weak guarantees when faced with
big data. Either the space overhead is excessive (1000s of times larger than the space for the data itself),
or the work needed to report the similar items may be comparable to the work needed to go through all
items (even if just a tiny fraction of the items are similar). As a result, many applications have to resort to
the use of ad-hoc solutions with only weak theoretical guarantees.

This proposal aims at strengthening the theoretical foundation of scalable similarity search, and
developing novel practical similarity search methods backed by theory. In particular we will:

- Leverage new types of embeddings that are kernelized, asymmetric, and complex-valued.

- Consider statistical models of noise in data, and design similarity search data structures whose
performance guarantees are phrased in statistical terms.

- Build a new theory of the communication complexity of distributed, dynamic similarity search,
emphasizing the communication bottleneck present in modern computing infrastructures.

The objective is to produce new methods for similarity search that are: 1) Provably robust, 2) scalable
to large and high-dimensional data sets, 3) substantially more resource efficient than current state-ofthe-
art solutions, and 4) able to provide statistical guarantees on query answers.

The study of similarity search has been an incubator for techniques (e.g. locality-sensitive hashing and
random projections) that have wide-ranging applications. The new techniques developed in this project
are likely to have significant impacts beyond similarity search."</Summary><Max_ERC_funding>1,889,712</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="STARKEY"><Rcn>185599</Rcn><Nid>11989</Nid><HI>Universita Degli Studi Di Padova, Italy</HI><Name>Solving the TP-AGB STAR Conundrum: a KEY to Galaxy Evolution</Name><PI>Paola Marigo</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>"Models of the Thermally Pulsing Asymptotic Giant Branch (TP-AGB) stellar evolutionary phase play a critical role across astrophysics, from the chemical composition of meteorites belonging to the pre-solar nebula up to galaxy evolution in the high-redshift Universe. In spite of its importance, the modelling of TP-AGB  is still affected by large uncertainties that propagate into the field of extragalactic astronomy, degrading the predicting power of current population synthesis models of galaxies. The major goal of this proposal is to remedy this persistent condition of uncertainty and controversy. The solution to the TP-AGB star conundrum will be provided by a new approach, which stands on the optimised integration of a) state-of-the-art theoretical tools to account for the complex physics of TP-AGB stars (evolution, nucleosynthesis, pulsation, winds, dust formation, etc.), and b) exceptionally high-quality observations of resolved TP-AGB stellar populations in stars clusters and nearby galaxies (Magellanic Clouds, M31, dwarf galaxies up to 4 Mpc) with reliable measurements of their star formation histories. We will adopt a global calibration method, in which TP-AGB evolution models are required to simultaneously reproduce a set of well-defined observational constraints (distributions of luminosities, colours, pulsation periods, dust mass-loss rates, expansion velocities of dusty envelopes, etc.). This project will deepen our understanding of TP-AGB physics profoundly, and provide wide-spread community benefits as well. We will publicly release well-tested and reliable ``TP-AGB products'', including stellar tracks, isochrones in all photometric systems, and chemical yields for both gas and dust. Eventually these products will be embedded in the stellar population synthesis models that are routinely used to analyse the integrated galaxy observables that probe the extragalactic Universe."</Summary><Max_ERC_funding>1,930,628</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="STRUBA"><Rcn>185680</Rcn><Nid>12017</Nid><HI>Technische Universiteit Delft, Netherlands</HI><Name>Computational modelling of structural batteries</Name><PI>Angelo Simone</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>Competition in consumer electronics has pushed the boundaries of technological development towards miniaturization, with weight/size limitations and increasing power demands being the two most stringent requirements. Although almost all the components of any portable device become smaller, lighter and more powerful by the months, electrochemical technology is far from presenting us with the ideal battery. From a different perspective, the equation mobile device = casing + electronics + battery could be simplified by merging the structural function of the casing with that of the energy source of the battery into a structural battery. This approach would immediately reduce weight and size of our mobile devices.

This project aims at investigating the effect of electrochemical-mechanical interactions on the mechanical performance of structural batteries. Understanding and controlling mechanical degradation in structural batteries is of prime importance given the dual structural-electrical function of these devices. In fact, the main concern when dealing with structural batteries is whether the internal stresses caused by external loads will influence the performance of the battery, and, conversely, whether the functioning of the battery will have a detrimental effect on its mechanical properties.  The complexity of these processes can only be addressed with dedicated computational techniques. This project offers a unique opportunity for the design and implementation of the first multiphysics and multiscale computational framework for the analysis of structural batteries. Macroscale processes originating at the level of a basic components will be elucidated through physically-based constitutive laws.

The overall impact of this project will be felt across many research communities. Apart from the energy storage community, the developed tools and procedures will influence research and development related to many fibre-reinforced composites.</Summary><Max_ERC_funding>1,968,053</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="Soft Wetting"><Rcn>111551</Rcn><Nid>10066</Nid><HI>Universiteit Twente, Netherlands</HI><Name>Soft Wetting</Name><PI>Jacobus Hendrikus Snoeijer</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>The physics of wetting, where a thin layer of fluid covers a solid substrate, finds numerous applications both in nature and industry. While one usually considers the substrate to be perfectly rigid, in many practically important circumstances the surface exhibits strong elastic deformations. Examples of such &#226;&#128;&#156;Soft Wetting&#226;&#128;&#157; phenomena are drops spreading on a gel, or roller bearings under heavy loads. Given the increasing technology to control and tune properties of soft matter, there is a strong need for better understanding of: (i) interaction of surface forces (capillarity) and elasticity, and (ii) coupling between fluid flow and visco-elastic dissipation in the solid. The central objective of the proposed research is to establish the governing principles for Soft Wetting and to develop tools for describing practically relevant situations.

The current approach to elastocapillary interactions is almost exclusively based on macroscopic descriptions, leading to contradictory results. I propose to change this by employing truly microscopic methods, namely Molecular Dynamics simulations and (simplified) Density Functional Theory. This will reveal how elastic stresses &#226;&#128;&#147; induced by liquid interactions on a molecular level &#226;&#128;&#147; are transmitted in the superficial layers of the solid. From a macroscopic perspective, there is mounting evidence that the visco-elastic rheology of the solid is very important for the dynamics of Soft Wetting: for example, drops spread much more slowly than expected on soft elastomeric surfaces. My goal is to reveal the connection between macroscopic motion and the rheology of the substrate. Experimentally, we combine high-speed visualization of drop spreading with a complete characterization of the substrate rheology. These experiments are complemented by Lattice Boltzmann simulations that account explicitly for visco-elastic substrates. As a whole, the project will provide basic knowledge and methods for a broad class of Soft Wetting phenomena.</Summary><Max_ERC_funding>1,782,000</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="SpecMAT"><Rcn>189840</Rcn><Nid>11812</Nid><HI>Katholieke Universiteit Leuven, Belgium</HI><Name>Spectroscopy of exotic nuclei in a Magnetic Active Target</Name><PI>Riccardo Raabe</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>SpecMAT aims at providing crucial experimental information to answer key questions about the structure of atomic nuclei:

- What are the forces driving the shell structure in nuclei and how do they change in nuclei far from stability?
- What remains of the Z = 28 and N = 50 &#226;&#128;&#156;magic numbers&#226;&#128;&#157; in 78Ni?
- Do we understand shape coexistence in nuclei, and what are the mechanisms controlling its appearance?

The position of natural and &#226;&#128;&#156;intruder&#226;&#128;&#157; shells will be mapped in two critical regions, the neutron-rich nuclei around Z = 28 and the neutron-deficient nuclei around Z = 82. The centroids of the shell strength are derived from the complete spectroscopy of those systems in nucleon-transfer measurements. This method will be applied for the first time in the region of neutron-deficient Pb nuclei.

In SpecMAT (Spectroscopy of exotic nuclei in a Magnetic Active Target) a novel instrument will overcome the present challenges in performing such measurements with very weak beams of unstable nuclei. It combines high luminosity, high efficiency and a very large dynamic range and allows detection of both charged-particle and gamma-ray radiation. The instrument owns its remarkable performances to a number of advanced technologies concerning the use of electronics, gaseous detectors and gamma-ray detectors in a magnetic field.

The SpecMAT detector will be coupled to the HIE-ISOLDE facility for the production and post-acceleration of radioactive ion beams in construction at CERN in Geneva. HIE-ISOLDE will provide world-unique beams thanks to the use of the proton injector of the CERN complex.

If successful, SpecMAT at HIE-ISOLDE will produce specific results in nuclear structure which cannot be reached by other programmes elsewhere. Such results will have a significant impact on the present theories and models of the atomic nucleus.</Summary><Max_ERC_funding>1,944,900</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="StrucLim"><Rcn>192415</Rcn><Nid>13457</Nid><HI>Magyar Tudomanyos Akademia Renyi Alfred Matematikai Kutatointezet, Hungary</HI><Name>Limits of discrete structures</Name><PI>Balazs Szegedy</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>Built on decades of deep research in ergodic theory, Szemeredi's regularity theory and statistical physics, a new subject is emerging whose goal is to study convergence and limits of various structures.
The main idea is to regard very large structures in combinatorics and algebra as approximations of infinite analytic objects. This viewpoint brings new tools from analysis and topology into these subjects. The success of this branch of mathematics has already been demonstrated through numerous applications in computer science, extremal combinatorics, probability theory and group theory. The present research plan addresses a number of open problems in additive combinatorics, ergodic theory, higher order Fourier analysis, extremal combinatorics and random graph theory. These subjects are all interrelated through the limit approach.</Summary><Max_ERC_funding>1,175,200</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="SunCatChem"><Rcn>192412</Rcn><Nid>13455</Nid><HI>Rheinisch-Westfaelische Technische Hochschule Aachen, Germany</HI><Name>Sustainable Light- Driven Catalytic Chemistry</Name><PI>Magnus Rueping</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>Innovative fundamental research is key to facing challenges posed by our current societal, environmental and economic needs. Catalysis is a vital component of many potential solutions to contemporary global issues and breakthroughs in catalysis would inevitably bring about change.
Among the most prominent challenges of the 21st century is the functionalization of abundant but unreactive C-H bonds as development of these transformations would enable the sustainable formation of new carbon-carbon or carbon-heteroatom bonds, needed for the construction of vitally important complex molecules. Even more challenging is the direct, enantioselective functionalization of unreactive C-H and C-C double bonds which would lead to valuable, optically active products which are highly desirable for the pharmaceutical, agrochemical and fine chemical industries.
The general objective of this proposal is to redefine the synthetic methodology for obtaining highly valuable, optically active products, used in life science applications, by using novel strategies, involving three unprecedented concepts which employ visible light available from the sun.
Successful validation of our three innovative, light-driven, catalysis concepts will have great impact on catalysis, organic synthesis and fundamental science in general. As a key enabling technology, we will also devise unprecedented reaction concepts which will allow fast and autonomous self-optimization without the need for any manual interaction, resulting in increased practicability and high acceptance from the scientific community.
By both designing and matching synthetic methodology with innovative technology we aim to enhance the environmental credentials and improved economic feasibility of the resulting reactions and systems, leading to wide acceptance and implementation and, thus, make a significant contribution towards the paradigm shift to sustainable chemistry.</Summary><Max_ERC_funding>1,997,982</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="TERAMICROSYS"><Rcn>185641</Rcn><Nid>12323</Nid><HI>Kungliga Tekniska Hoegskolan, Sweden</HI><Name>Terahertz microsystems- Enabling the large-scale exploitation of the terahertz gap</Name><PI>Joachim Oberhammer</PI><Call_Details>Consolidator Grants (CoG), PE7, ERC-2013-CoG</Call_Details><Summary>"This project envisions the wide-spread use of THz technology in various applications in our society, which is enabled by the proposed THz microsystems, providing an unprecedented way of creating highly-integrated, volume-manufacturable, cost and energy-efficient, reconfigurable and thus adaptive submillimeter-wave and THz systems. Advanced three-dimensional micromachining is used as the key enabling fabrication technology. In connection with the technology convergence of advancing microwave semiconductor technology according to international technology programmes and roadmaps, the findings of this project are expected to comprise a significant contribution towards the large-scale exploitation of the heavily sought-after frequency space between 100 GHz and 1 THz, the so-called &#226;&#128;&#152;terahertz gap&#226;&#128;&#153;.
Primary application fields with high impact of the proposed technology are wireless short-range communication links to interconnect future small-cell clouds replacing the current macro-basestation radio access network, and submillimeter-wave/THz sensing with application fields including medical diagnosis, food quality control, agriculture and industrial sensors.
The proposed THz microsystems are based on rectangular waveguide-technology integrated into a multi-wafer stacked silicon substrate, which integrates all passive components needed for completing a submillimeter-wave/THz system around the monolithic-microwave integrated circuits (MMIC). Novel key building blocks investigated in this proposal include platform-integrated sensor and antenna interfaces, micro-electromechanically tuneable filters, phase-shifters, impedance-matching networks and non-galvanic microsystem-to-IC interfaces. The micro-mechanical reconfigurability enables unprecedented adaptive THz systems.
Key outcomes of this project are proof-of-concept prototypes of all key building blocks up to 650 GHz, and of complete THz microsystems implemented for the two key applications telecom links and medical sensors."</Summary><Max_ERC_funding>1,727,189</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="TOPCHARM"><Rcn>185564</Rcn><Nid>11583</Nid><HI>Weizmann Institute Of Science, Israel</HI><Name>The LHC Battle for Naturalness on the Top Charm Front</Name><PI>Gilad Perez</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>Now that a Higgs-like particle has been discovered naturalness becomes the most pressing and fundamental question within the reach of the Large Hadron Collider (LHC).  The main contribution that destabilises the electroweak scale comes from a top-quark loop. The key for addressing the naturalness problem is thus identifying the top partners that are stabilizing the weak scale.
We consider the following two general possibilities in which the partners have escaped detection:
(I) the top partners are light but elusive, this calls for a theoretical explanation as well as for new innovative experimental techniques for signal exhumation;
(II) the partners are  relatively heavy and the signal would consist of energetic (boosted) top from the decay of its partner. I plan to carry out a comprehensive research program designed to attack these challenges, and I believe that I am uniquely prepared to do this.  Regarding (I), as proven below, current searches have not considered the impact of non-trivial flavor physics, e.g. splitting between the first two generation partner masses, as well as the mixing between the top-partners and other flavors. The consequences are: (i) significantly weaker mass bounds on some of the partners (e.g. the scharm, charm-supersymmetric-partner);  (ii) improved naturalness as even the stops (or fermion partners) can be lighter; and (iii) modified Higgs rates in composite models.
Regarding (II), with collaborators I have been the first one to understand the difficulties of dealing with highly boosted top jets, and since then I was intensively involved in developing theoretical as well as novel techniques to study them, including coauthoring two important papers with the CDF and ATLAS collaborations.
To uncover these new possibilities, expertise in collider phenomenology and flavor physics is required. I have a proven record in these frontiers and thus, given the required support, am well positioned to pursue this quest to save naturalness.</Summary><Max_ERC_funding>1,434,154</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="TOPOTRONICS"><Rcn>111578</Rcn><Nid>10062</Nid><HI>Universiteit Twente, Netherlands</HI><Name>Topological Josephson devices as a novel platform for creating and controlling non-Abelian anyons</Name><PI>Alexander Brinkman</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"Surprisingly, in two-dimensional systems quasi-particles may exist that are neither fermions nor bosons. When these particles are interchanged, their joint quantum mechanical wave function is predicted to pick up any phase in between 0 (as for bosons) and pi (as for fermions), hence the name anyons.

Even more intriguing is the class of non-Abelian anyons where interchange of particles completely changes the ground state of the system. This phenomenon lays at the heart of a wealth of theoretical proposals for new types of quantum statistics and topological quantum computation that is robust against decoherence. While theory has well advanced, experimental realizations possess their own challenges and are seriously lacking behind.

It is the objective of this proposal to experimentally realize a platform to detect and control non-Abelian anyons. We propose to combine the particle-hole symmetry of a superconductor with the spin-momentum locking at the surface of a topological insulator. Topological Josephson junctions are predicted to host Majorana type bound states at vortices. We propose to artificially create Josephson vortices at the junction of three phase-biased superconducting islands and to control and braid multiple Majorana states to prove their non-Abelian anyon character.

In preliminary experiments we have shown, as one of the first groups in the world, to be able to induce superconductivity in a topological insulator by the proximity effect. This puts our group in a unique position to open up the field of topological Josephson physics. The great technological challenges of the present proposal lay in the development of topological insulator materials with higher surface mobility and their integration into Josephson electronic circuitry with multiple phase biased superconducting islands. For the phase biasing as well as the read-out of the Majorana states after braiding on-chip SQUID based current amplifiers will be developed."</Summary><Max_ERC_funding>1,999,200</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="TRANS-NANO"><Rcn>111543</Rcn><Nid>11830</Nid><HI>Fondazione Istituto Italiano Di Tecnologia, Italy</HI><Name>"Advancing the Study of Chemical, Structural and Surface Transformations in Colloidal Nanocrystals"</Name><PI>Liberato Manna</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>"Colloidal inorganic nanocrystals (NCs) are among the most investigated nanomaterials in Nanoscience due to their high versatility. Research on NCs went through much advancement lately, especially on synthesis, assembly and on the study of their transformations, most notably via cation exchange (all fields in which the PI has contributed already). However, the integration of NCs with fabrication tools that employ conditions such as irradiation, etching and annealing is at a very early stage since we do not have a systematic knowledge of what transformations are triggered in the NCs under those conditions. Also, an issue related to the incorporation of NCs in materials/devices is whether, over time, the NCs will remain as they are, or they will transform into other structures. Plus, these transformations in NCs are poorly studied as they require fast recording techniques. This proposal will embark on an ambitious investigation of post-synthetic transformations in solution-grown NCs: by advancing the understanding of various aspects of chemical, structural and surface transformation of NCs, we will uncover new fabrication techniques that will employ such nanostructures as the key ingredients. This in turn will have a strong impact in opto-electronics, as several electronic components entirely made of NCs will be delivered. Four objectives are targeted: i) developing radically new sets of experimental tools for the investigation of chemical transformations in NCs, above all the ability to monitor in real time these transformations; ii) developing solution-grown nanostructures able to undergo programmed transformations under a defined stimulus; iii) understanding the role of irradiation on the fate of surface ligands and on cation exchange reactions in NCs; iv) combining chemical, structural and surface transformations towards NC-based opto-electronics. The success of the proposal hinges on the proven capabilities of the PI, with ample support from the host Institution."</Summary><Max_ERC_funding>2,430,720</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="TRANSITION"><Rcn>185639</Rcn><Nid>12020</Nid><HI>Centre National De La Recherche Scientifique, France</HI><Name>"Large Deviations and Non Equilibrium Phase Transitions for Turbulent Flows, Climate, and the Solar System"</Name><PI>Freddy Bouchet</PI><Call_Details>Consolidator Grants (CoG), PE3, ERC-2013-CoG</Call_Details><Summary>"The aim of this project is to predict and compute extremely rare but essential trajectories in complex physical systems. We will compute rare transitions trajectories, first between two different turbulent attractors in models of planetary jet dynamics, and second between two configurations of ocean currents for a model of the thermohaline circulation. We will compute the dynamics and the probability for collisions between two planets in the solar system, on time scales of order of billions of years. We will evaluate rare events that lead to extremely large drags or torques on objects embedded in turbulent flows, directly from the dynamics. Because of the huge range of time scales, all those trajectories are not accessible through direct numerical simulations.

The project's unity stems from the methodology based on large-deviations theory. Large deviation rate functions generalize the concept of entropy or free energy in non-equilibrium extended systems: they provide a global characterization of their most probable state, their large fluctuations and their phase transitions. Impressive explicit computations of large deviation rate functions have been recently performed in simple non-equilibrium systems. The main aim of this project is to bridge the gap between those extremely interesting new concepts and algorithms, and complex dynamical systems such as turbulent flows, semi-realistic models of fluids related to climate dynamics, or the long time behavior of the solar system.

In order to achieve this goal, we will use macroscopic fluctuation theory, instanton theory, and other analytical methods in order to compute explicitly large deviation rate functions for essential macroscopic quantities (the velocity or density fields). We will also develop and use algorithms specifically dedicated at computing the statistics of extremely rare trajectories, based on the generalization of importance sampling implemented through cloning or multilevel splitting methods."</Summary><Max_ERC_funding>1,178,760</Max_ERC_funding><Duration><Start_date> 2014-03-01, </Start_date><End_date> 2019-02-28</End_date></Duration></Project><Project acronym="TRITOS"><Rcn>111427</Rcn><Nid>10095</Nid><HI>Kungliga Tekniska Hoegskolan, Sweden</HI><Name>TRansItions and Turbulence Of complex Suspensions</Name><PI>Luca Brandt</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>"The aim of this project is to forge a physical understanding of the transitions and of the turbulent flow of semi-dilute/dense non-colloidal suspensions, for different particle features and suspending fluids.
It is estimated that 10% of the world energy consumption is due to the transport and handling of granular materials of which particle suspensions are an important part. A deep understanding of the mechanisms underlying the flow of particle suspensions, the transition to turbulence and the turbulence characteristics is crucial for many important practical applications involving engineered complex fluids, such as pastes and paper pulp. A better prediction and control of the flow of suspensions will therefore have a huge impact.
Complex fluids are multiscale by nature where the physics at the microscale affects the macroscopic behaviour of the flow and vice versa giving rise to surprising and spectacular phenomena as well as making this one of the most important practical problem still to solve. Investigating the mechanisms by which the system microstructure determines the macroscopic flow properties and vice versa will not only give valuable insights into the nature of flowing suspensions but also will also lead to new ways to model and control it. Future generations of engineering CFD tools will have to contain models for complex suspensions. The fundamental approach proposed here, combined with challenging scientific and engineering examples backed up by experimental evidence, will make this possible and demonstrate it to a wider engineering community. The proposed project is based on highly accurate simulations of multiphase flow systems and state-of-the-art experiments. Such a holistic approach will enable us to understand the underlying mechanisms of instabilities and suspension turbulence and to develop accurate criteria for their prediction far in advance of what we could achieve with either approach separately."</Summary><Max_ERC_funding>1,998,350</Max_ERC_funding><Duration><Start_date> 2014-04-01, </Start_date><End_date> 2019-03-31</End_date></Duration></Project><Project acronym="TheMoDS"><Rcn>185671</Rcn><Nid>12315</Nid><HI>University Of Cyprus, Cyprus</HI><Name>Theories and Models of the Dark Sector: Dark Matter, Dark Energy and Gravity</Name><PI>Constantinos Skordis</PI><Call_Details>Consolidator Grants (CoG), PE9, ERC-2013-CoG</Call_Details><Summary>Modern cosmology assumes that General Relativity (GR) is the correct description of gravity on large scales. With this assumption and according to current data, the cosmological model needs in addition the existence of a Dark Sector: Dark Matter (DM) and Dark Energy (DE). We know very little about the nature of DM and it is yet to be detected experimentally. The simplest form of DE compatible with the data, a cosmological constant, has a value incompatible with our understanding of Quantum Field Theory. Given that the extrapolation of GR to cosmological scales has not been tested it is possible that the inference of the Dark Sector also needs to be revised.

I propose to (i) determine the nature of DM and DE to a level not achieved before, (ii) test gravity on cosmological scales and (iii) test the screening of new gravitational degrees of freedom in the solar system. The first two goals will require the use of my general framework to parameterize field equations [Skordis, PRD 79, 123527 (2008); Baker, Ferreira &amp; Skordis, PRD 87, 024015 (2013)]. My team will use this framework to construct simple models and observations to place limits on their parameters. We will employ the Cosmic Microwave Background (CMB) observations from ESA's Planck Surveyor and the Atacama Cosmology Telescope. We will determine the sensitivity of the CMB lensing to the properties of DM and theories of gravity. To break possible degeneracies these data will be supplemented with large-scale structure data, weak lensing and red-shift space distortions. We will also perform forecasting for ESA's EUCLID mission which will give us a handle on how well we will constrain GR with cosmology in the future. For the final goal (iii) we will employ the method of [Padilla &amp; Saffin, JHEP 1207, 122 (2012)] to construct a perturbative expansion of theories that exhibit screening, inside the screening radius. We will determine the compatibility of such theories with solar system and other strong-field data.</Summary><Max_ERC_funding>1,150,691</Max_ERC_funding><Duration><Start_date> 2014-08-01, </Start_date><End_date> 2019-07-31</End_date></Duration></Project><Project acronym="TopCoup"><Rcn>111222</Rcn><Nid>11836</Nid><HI>Rheinische Friedrich-Wilhelms-Universitat Bonn, Germany</HI><Name>Determination of top couplings in associated top pair events using ATLAS data</Name><PI>Markus Cristinziani</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>The discovery of a new particle, compatible with the Higgs boson, at the Large Hadron Collider, marked a major triumph of the Standard Model of particle physics. However, many fundamental questions remain and direct or indirect evidence of new physics can be probed with the large number of proton-proton collision data, collected in 2011 and 2012 at 7 and 8 TeV centre-of-mass energy.

With this proposal we plan to exploit the large sample of top-quark pair events that is already recorded, and the sample that will be collected from 2015 onwards, at the ultimate energy of 14 TeV. In particular we plan to study the coupling of top quarks to neutral bosons, by measuring the production of associated tt&#204;&#132;&#206;&#179;, tt&#204;&#132;Z and tt&#204;&#132;H. Anomalous electromagnetic or weak couplings could be uncovered by studying kinematic properties of the resulting photon or Z-boson, once the signal is established. By studying the tt&#204;&#132;H production in detail the mechanism of Yukawa coupling of the Higgs boson to fermions will be tested, possibly providing important confidence in the characterisation of the new boson.

In all measurements we plan to include the tt&#204;&#132; dilepton channel, that, despite the smaller branching fraction has typically superior signal-to-noise ratios. An essential part of the programme will be the calibration of the b-tagging algorithms, where we plan to use tt&#204;&#132; events. For associated Higgs production we will explore the decays H&#226;&#134;&#146; bb&#204;&#132; and H&#226;&#134;&#146; &#206;&#179;&#206;&#179;.</Summary><Max_ERC_funding>1,964,088</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="UCHEM"><Rcn>185534</Rcn><Nid>11509</Nid><HI>The University Of Manchester, United Kingdom</HI><Name>Frontier Non-Aqueous Uranium Chemistry: Structure, Bonding, Reactivity, and Nanomagnetism</Name><PI>Stephen Taylor Liddle</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>The Applicant has an outstanding track record of achievement and an international reputation for independent research in non-aqueous uranium chemistry. This high-impact, challenging CoG Proposal integrates four innovative ideas in uranium chemistry into a single overarching inter-/multi-disciplinary project to open up new horizons across molecular, catalysis, materials, magnetism and energy research. The Applicant&#226;&#128;&#153;s ERC StG has been very successful and opened new doors to several new avenues of pioneering research that were not even conceivable before the work was done. This work extends out from the knowledge achievements of the StG into new, exciting research areas that are completely different. This is a strategically vital to understand yet poorly developed area due to legacy nuclear waste. This project will deliver innovation through studying: (i) uranium-nitrogen triple bonds as benchmarks for uranium bonding and for generating new small molecule activation and materials applications; (ii) homologation of CO to close the carbon cycle and sustainably remove reliance on dwindling oil; (iii) single molecule magnets that have applications in data storage, quantum computing, spintronics; (iv) uranium-metal bonds which act as exemplars for intermetalloids and bonding. This CoG will afford the freedom and impetus via consolidated funding to undertake fundamental, speculative research to deliver &#226;&#128;&#152;big-hits&#226;&#128;&#153;, whole new fields of actinide chemistry, and, based on this higher platform of understanding, new ways of thinking. This will induce previously impossible paradigm shifts in uranium chemistry and be included in future textbooks. This project addresses priority subjects in FP7 and the ERC, and, via an extensive network of international academic and industrial collaborations, will consolidate the PI&#226;&#128;&#153;s team in an exciting, curiosity-driven environment, reverse a strategic skills shortage, and deliver high calibre, cross-disciplinary scientists for the EU.</Summary><Max_ERC_funding>2,122,596</Max_ERC_funding><Duration><Start_date> 2014-10-01, </Start_date><End_date> 2019-09-30</End_date></Duration></Project><Project acronym="UpFermi"><Rcn>111577</Rcn><Nid>11823</Nid><HI>Rheinische Friedrich-Wilhelms-Universitat Bonn, Germany</HI><Name>Unconventional pairing in ultracold Fermi gases</Name><PI>Michael Karl K&#195;&#182;hl</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>We explore unconventional ways how ultracold fermions pair and form collective quantum phases exhibiting long-range order, such as superfluidity and magnetically order. Specifically, we plan to realize and study pairing with orbital angular momentum and pairing induced by long-range interaction. Besides the fundamental interest in unravelling unconventional pairing mechanisms and the interplay between superfluidity and quantum magnetism, our project will also lead to gaining experimental control over topologically protected quantum states. This will pave the way for future topological quantum computers, which are particularly robust to environmental decoherence.
Our project addresses three different aspects: (1) We plan to realize p-wave superfluids in two dimensions. This quantum phase exhibits topological excitations (vortices) with anyonic statistics and an isomorphism to the fractional quantum-Hall effect. We will investigate the unusual properties of p-wave superfluids, such as Majorana fermions, i.e. quasiparticles being their own anti-particles, which are predicted to be localized at vortices. This will boost the long-standing efforts in the cold atoms and condensed matter communities to understand topological states of matter. (2) We aim to realize d-wave pairing in optical lattices using a novel experimental approach. d-wave pairing is closely related to high-Tc superconductivity in the cuprates and we are interested in exploring its interplay with magnetic order. Superfluidity and magnetic order are antagonistic phenomena from a conventional BCS-theory point-of-view and hence several fundamental questions will be answered. (3) We plan to induce long-range interactions using a high-finesse optical cavity leading to a light-induced pairing mechanism. We will search for Cooper pairing in spin-polarized Fermi gases mediated by the interaction of Fermions with a quantized light field. This provides access to a new class of combined light-matter quantum states.</Summary><Max_ERC_funding>1,925,525</Max_ERC_funding><Duration><Start_date> 2014-10-01, </Start_date><End_date> 2019-09-30</End_date></Duration></Project><Project acronym="ViDa"><Rcn>189848</Rcn><Nid>8693</Nid><HI>Ecole Polytechnique Federale De Lausanne, Switzerland</HI><Name>Transforming Raw Data into Information through Virtualization</Name><PI>Anastasia Ailamaki</PI><Call_Details>Consolidator Grants (CoG), PE6, ERC-2013-CoG</Call_Details><Summary>The unprecedented evolution of computing power, combined with the decreasing costs of computation and storage infrastructure, has revolutionized all scientific fields and enterprises; at the heart of this revolution is the ability to collect unprecedented amounts of data. Real progress, however, depends on how efficiently we can &#226;&#128;&#152;extract value from chaos&#226;&#128;&#153;, i.e., process the collected data and transform it into useful information. Unfortunately, despite the impressive growth of data management technologies,  data analysis application efficiency is hindered by the increasing data growth. The typical business intelligence architecture is far too complex to yield answers productively, with businesses operating large numbers of specialized data processing systems, with data being repeatedly moved, copied or transformed between them. The reason is that, despite tremendous progress, data management tools are based on legacy designs whose requirements are no longer adequate. A novel approach is needed urgently, or users risk losing the ability to leverage their hard-earned data.
In this proposal, we identify assumptions that do not scale with today&#226;&#128;&#153;s massive data explosion, and design a comprehensive end-to-end solution that implements a novel form of data virtualization to vastly simplify data analysis. Our approach removes barriers to data handling and maximizes efficiency for science, businesses, and their users, by enabling new forms of data computation that are unrestrained by how data is collected or stored. This project constructs the building blocks for data-driven computing and the fourth paradigm of scientific discovery, thereby advancing our ability to automatically explore massive and complex datasets at sight, and dictate the new developments in sciences and the industry.</Summary><Max_ERC_funding>1,976,762</Max_ERC_funding><Duration><Start_date> 2014-05-01, </Start_date><End_date> 2019-04-30</End_date></Duration></Project><Project acronym="Vort3DEuler"><Rcn>189834</Rcn><Nid>11815</Nid><HI>The University Of Warwick, United Kingdom</HI><Name>3D Euler, Vortex Dynamics and PDE</Name><PI>Jose Luis Rodrigo</PI><Call_Details>Consolidator Grants (CoG), PE1, ERC-2013-CoG</Call_Details><Summary>This proposal deals with a collection of problems in PDE arising from fluid mechanics.The primary motivation is the understanding of the evolution of isolated vortex lines for 3D Euler. The importance of the evolution of vorticity in incompressible fluid mechanics is very well known.

To date, only nonrigorous approaches are known to try to obtain an evolution equation for isolated vortex lines. Two desingularization procedures are carried out (including a time renormalization) to obtain an evolution equation (the binormal equation). While an isolated vortex line does not fit any known concept of solution (given the singularity of the velocity), and there has been significant recent activity on the nonuniqueness of solutions of Euler (De Lellis &amp; Szekelyhidi, and recently Isett) it is expected that the geometric assumptions made about the solution will still make it possible to find a suitable concept of solution. In the proposal I describe an approach that should help to rigorously understand vortex lines. It is motivated by a programme developed for the Surface Quasi-Geostrophic (SQG) equation with C. Fefferman and for some related desingularized models with my student Zoe Atkins (Nov 2012 PhD).

SQG has been of great interest in the PDE community due to the striking similarities it exhibits with 3D Euler. In particular, the evolution of sharp fronts for SQG corresponds to the evolution of vortex lines. In recent years I have developed an approach  that overcomes the divergences known to exist for the velocity field (as in 3D Euler). The positive results obtained for SQG motivate the methodology and tools described in the proposal, including the construction of solutions with very large gradients and simple geometry and the use of a measure-theoretic approach to identify fundamental curves within these objects. Surprising connections with other equations motivate some other directions and linked projects, for example with Prandtl and boundary layer ther theory.</Summary><Max_ERC_funding>1,182,858</Max_ERC_funding><Duration><Start_date> 2014-07-01, </Start_date><End_date> 2019-06-30</End_date></Duration></Project><Project acronym="WII"><Rcn>188684</Rcn><Nid>9909</Nid><HI>Ecole Polytechnique Federale De Lausanne, Switzerland</HI><Name>"Water, Ions, Interfaces: Quantum effects, charge and cooperativity in water, aqueous solutions and interfaces"</Name><PI>Sylvie Roke</PI><Call_Details>Consolidator Grants (CoG), PE4, ERC-2013-CoG</Call_Details><Summary>"Sixty percent of the human body consists of water. Water provides the 3D-network for life&#226;&#128;&#153;s constituents. In a cell there are many interfaces: the average distance between two molecules or a molecule and a membrane interfaces is ~1 nm. Water and the interfaces it interacts with are of paramount importance for biological processes. The structural, dynamic, and biological properties of water, aqueous systems and aqueous interfaces are essential in understanding the complexity of life, and our ability to harness its features for novel technologies.
Waters&#226;&#128;&#153; 3D hydrogen bonded network is important for nearly all the macroscopic properties of water. The network is cooperative, yet it rearranges itself every few femtoseconds, and quantum level interactions determine its properties. Understanding the role water plays in living systems therefore requires information from the quantum level/femtosecond time scale up to the macroscopic level/time scale. Therefore, understanding water remains a considerable challenge.
I propose to investigate the structural, dynamic, and biological properties of water by probing the relationship between the properties of water on vastly different length and time scales. We will investigate quantum effects in water and on interfaces, and study long-range ordering (up from the femtosecond time scale). Furthermore, we will map how ions, hydrophilic, and hydrophobic solutes influence waters structural correlations and water-mediated interactions. Thus, we will use a worldwide unique multiscale toolbox that has for the most part been recently developed in my lab. We will map aqueous solutions by probing the structure of hydration shells, nanoscopic order and correlations between water molecules and viscosity. Interfacial structural and dynamical changes will be measured by mapping the surface chemical composition and conformation, the surface charge, and the electrokinetic mobility of nanodroplets."</Summary><Max_ERC_funding>1,999,984</Max_ERC_funding><Duration><Start_date> 2014-11-01, </Start_date><End_date> 2019-10-31</End_date></Duration></Project><Project acronym="X-MUSIC"><Rcn>111550</Rcn><Nid>11828</Nid><HI>Max-Planck-Gesellschaft Zur Forderung Der Wissenschaften Ev, Germany</HI><Name>XUV/X-ray Multidimensional Spectroscopy of Fundamental Electron Dynamics and Impulsive Control of X-ray Light</Name><PI>Thomas Pfeifer</PI><Call_Details>Consolidator Grants (CoG), PE2, ERC-2013-CoG</Call_Details><Summary>"Interaction of extreme&amp;controlled light fields with matter is driving an ongoing revolution in our understanding of quantum physics.  Controlled&#226;&#128;&#148;pulsed&#226;&#128;&#148;visible lasers have enabled time-dependent two-dimensional (2D) spectroscopy currently transforming chemistry, and led to key milestones such as frequency combs.

Despite progress on coherent soft- and hard-x-ray pulsed sources during the last 10 years&#226;&#128;&#148;e.g. x-ray free-electron lasers (FELs) or high-harmonic generation of laser light, nonlinear (e.g. 2D) spectroscopy or phase control of x-ray light remained a major challenge.

Here, I propose to experimentally realize
- (a) x-ray two- and multi-dimensional spectroscopy
- (b) resonant gain without inversion and spectral control of x rays
for the scientific goals
- (a) time- and quantum-state-resolved measurement of fundamental few- and many-electron dynamics
- (b) generation of soft-(electronic) and hard-x-ray (nuclear) frequency combs

For (a), a 4-quadrant x-ray time-delay unit will generate coherently-timed pulses out of one spatially coherent beam. For (b) a new physical mechanism relating Fano to Lorentz resonances and absorption to gain by a single temporal phase will be harvested.
Scientific impact:
(a): Site-specific 2D-x-ray spectroscopy will phase-sensitively test&amp;promote theory and allow to understand fundamental processes: excitation, ionization, and few-electron dynamics in atoms and molecular bonding orbitals.
(b): Impulsive phase control of resonant gain and absorption represents a disruptive key technology rivalling the LASER especially in the hard-x-ray domain, where long-lived population inversion in dense media seems impossible.  Frequency combs around a well-defined (5 neV) hard-x-ray M&#195;&#182;ssbauer Fe57 nuclear transition (14.4 keV) will be demonstrated.  Such combs (at &gt;10 keV), will in the future allow the most sensitive tests of fundamental physics, e.g. quantum-electrodynamics (QED) in highly-charged ions and the variation of physical 'constants'."</Summary><Max_ERC_funding>1,983,863</Max_ERC_funding><Duration><Start_date> 2014-01-01, </Start_date><End_date> 2018-12-31</End_date></Duration></Project><Project acronym="i-CaD"><Rcn>192403</Rcn><Nid>13458</Nid><HI>Universiteit Gent, Belgium</HI><Name>Innovative Catalyst Design for Large-Scale, Sustainable Processes</Name><PI>Joris Wilfried Maria Cornelius Thybaut</PI><Call_Details>Consolidator Grants (CoG), PE8, ERC-2013-CoG</Call_Details><Summary>A systematic and novel, multi-scale model based catalyst design methodology will be developed. The fundamental nature of the models used is unprecedented and will represent a breakthrough compared to the more commonly applied statistical, correlative relationships. The methodology will focus on the intrinsic kinetics of (potentially) large-scale processes for the conversion of renewable feeds into fuels and chemicals. Non-ideal behaviour, caused by mass and heat transfer limitations or particular reactor hydrodynamics, will be explicitly accounted for when simulating or optimizing industrial-scale applications. The selected model reactions are situated in the area of biomass upgrading to fuels and chemicals: fast pyrolysis oil stabilization, glycerol hydrogenolysis and selective oxidation of (bio)ethanol to acetaldehyde.

For the first time, a systematic microkinetic modelling methodology will be developed for oxygenates conversion. In particular, stereochemistry in catalysis will be assessed. Two types of descriptors will be quantified: kinetic descriptors that are catalyst independent and catalyst descriptors that specifically account for the effect of the catalyst properties on the reaction kinetics. The latter will be optimized in terms of reactant conversion, product yield or selectivity. Fundamental relationships will be established between the catalyst descriptors as determined by microkinetic modelling and independently measured catalyst properties or synthesis parameters. These innovative relationships allow providing the desired, rational feedback in from optimal descriptor values towards synthesis parameters for a new catalyst generation. Their fundamental character will guarantee adequate extrapolative properties that can be exploited for the identification of a groundbreaking next catalyst generation.</Summary><Max_ERC_funding>1,999,877</Max_ERC_funding><Duration><Start_date> 2014-06-01, </Start_date><End_date> 2019-05-31</End_date></Duration></Project><Project acronym="stardust2asteroids"><Rcn>192406</Rcn><Nid>13447</Nid><HI>Kobenhavns Universitet, Denmark</HI><Name>Stardust to asteroids: Unravelling the formation and earliest evolution of a habitable solar system</Name><PI>Martin Bizzarro</PI><Call_Details>Consolidator Grants (CoG), PE10, ERC-2013-CoG</Call_Details><Summary>As far as we know, our solar system is unique. It could, in principle, be the only planetary system in the Universe to harbor intelligent life or, indeed, life at all. As such, attempting to reconstruct its history is one of the most fundamental pursuits in the natural sciences. Whereas astronomical observations of star- forming regions provide a framework for understanding the formation of low-mass stars and the early evolution of planetary systems in general, direct information about the earliest solar system can only come from primitive meteorites and their components and some differentiated meteorites that record the birth of the solar system. The main objective of this proposal is to investigate the timescales and processes &#226;&#128;&#147; including the role of supernovas &#226;&#128;&#147; leading to the formation of the solar system by measurement of isotopic variations in meteorites. To achieve our objectives, we will integrate long-lived and short-lived radioisotope chronometers with the presence/absence of nucleosynthetic anomalies in various meteorites and meteoritic components. Our isotopic measurements will be obtained using state-of-the-art technologies such as second-generation mass spectrometers housed in laboratories directed by the PI and fully dedicated to cosmochemistry. This will allow us to: 1) define the mechanism and timescale for the collapse of the protosolar molecular cloud and emergence of the protoplanetary disk, 2) constrain the source and locale of chondrule-forming event(s) as well as the nature of the mechanism(s) required to transport chondrules to the accretion regions of chondrites, and 3) provide robust estimates of the timing and mechanism of asteroidal differentiation. We aim to understand how the variable initial conditions imposed by the range of possible stellar environments and protoplanetary disk properties regulated the formation and assemblage of disk solids into asteroidal and planetary bodies comprising our solar system.</Summary><Max_ERC_funding>1,910,889</Max_ERC_funding><Duration><Start_date> 2014-02-01, </Start_date><End_date> 2019-01-31</End_date></Duration></Project><Project acronym="synMICs"><Rcn>185602</Rcn><Nid>11992</Nid><HI>Universitaet Bern, Switzerland</HI><Name>Exploiting Synergistic Properties of Mesoionic Carbene Complexes: Teaching Rusty Metals Challenging Catalysis</Name><PI>Martin Albrecht</PI><Call_Details>Consolidator Grants (CoG), PE5, ERC-2013-CoG</Call_Details><Summary>The non-innocence of specific ligands in transition metal complexes is well-documented. For example, mesoionic carbenes engage in bond activation processes via reversible hydrogen capture. Such cooperativity between the metal center and the ligand flattens the potential energy surface of a catalytic reaction and hence rises the competence of the catalyst, thus entailing higher turnover numbers as well as the conversion of more challenging substrates. Likewise, such cooperativity is expected to enhance the catalytic activity of metal centers that are typically not considered to be catalytically very active, such as the &#226;&#128;&#152;rusty&#226;&#128;&#153; first row transition metals (Mn, Fe, Ni). Surprisingly, however, this concept has largely been overlooked when designing catalytic transformations based on these earth-abundant and low-cost transition metals. This project will exploit the synergistic potential of mesoionic carbenes as synthetically highly versatile and actively supporting ligands to access a new generation of sustainable high-performance catalysts based on Me, Fe, and Ni for challenging redox transformations such as dehydrogenative oxidations. Specificlly, 1,2,3-triazolylidenes, which support ligand-metal cooperativity through their mesoionic character, will be utilized for (transient) storage/release of protons and electrons. Apart from enabling challenging transformations &#226;&#128;&#148; with obvious impact on synthetic methodology, energy conversion, and molecular electronics &#226;&#128;&#148; this project will break into new grounds in catalyst design that will be widely applicable as a new paradigm. Furthermore, this project will capitalize on the unique synthetic versatility of triazolylidene precursors and the opportunity to combine different functional entities such as carbohydrates, surfactants, or dyes with an organometallic entity, thus providing a straightforward approach to new classes of multifunctional materials for application in therapeutics and diagnostics, or as smart surfaces.</Summary><Max_ERC_funding>2,111,111</Max_ERC_funding><Duration><Start_date> 2015-02-01, </Start_date><End_date> 2020-01-31</End_date></Duration></Project></Projects>